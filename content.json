{"pages":[],"posts":[{"title":"EdgeX的使用","text":"EdgeX的使用演示功能需要包含设备数据采集，数据分析，数据分析后的设备控制命令发送，以及云端的数据导出和远程数据访问显示。 设备目前可以使用edgeX 的虚拟设备。 以虚拟设备为例：edgex自带的虚拟设备应该不会自己时刻产生数据，只有当edgex请求或者用户通过api请求其中的方法时，才会返回数据。在devices.toml文件中，对每个设备配置了DeviceList/DeviceList.AutoEvents，也就是自动事件，以此完成每个interval从虚拟设备收集数据发送到核心数据。 下面的步骤通过postman操作： 数据采集1192.168.0.107:59882/api/v2/device/name/Random-Integer-Device/Int8 数据分析以及数据分析后设备控制命令发送通过eKuiper 分析来自 EdgeX消息总线的数据 第一步：创建流post http://192.168.0.107:59720/streams body {&quot;sql&quot;: &quot;create stream demo() WITH (FORMAT=\\&quot;JSON\\&quot;, TYPE=\\&quot;edgex\\&quot;)&quot;} 创建规则第一条规则： 监视来自Random-UnsignedInteger-Device设备的事件，如果uint8发现读数值大于20事件中的值，则向Random-Boolean-Device设备发送命令以开始生成随机数（将随机生成 bool 设置为 true）。 12#posthttp://192.168.0.107:59720/rules 123456789101112131415161718#body{ &quot;id&quot;: &quot;rule1&quot;, &quot;sql&quot;: &quot;SELECT uint8 FROM demo WHERE uint8 &gt; 20&quot;, &quot;actions&quot;: [ { &quot;rest&quot;: { &quot;url&quot;: &quot;http://edgex-core-command:59882/api/v2/device/name/Random-Boolean-Device/WriteBoolValue&quot;, &quot;method&quot;: &quot;put&quot;, &quot;dataTemplate&quot;: &quot;{\\&quot;Bool\\&quot;:\\&quot;true\\&quot;, \\&quot;EnableRandomization_Bool\\&quot;: \\&quot;true\\&quot;}&quot;, &quot;sendSingle&quot;: true } }, { &quot;log&quot;:{} } ]} 第二条规则： 监视来自Random-Integer-Device设备的事件，如果int8读取值的平均值（20 秒内）大于 0，则向Random-Boolean-Device设备发送命令以停止生成随机数字（将随机生成 bool 设置为 false）。 12#posthttp://192.168.0.107:59720/rules 1234567891011121314151617{ &quot;id&quot;: &quot;rule2&quot;, &quot;sql&quot;: &quot;SELECT avg(int8) AS avg_int8 FROM demo WHERE int8 != nil GROUP BY TUMBLINGWINDOW(ss, 20) HAVING avg(int8) &gt; 0&quot;, &quot;actions&quot;: [ { &quot;rest&quot;: { &quot;url&quot;: &quot;http://edgex-core-command:59882/api/v2/device/name/Random-Boolean-Device/WriteBoolValue&quot;, &quot;method&quot;: &quot;put&quot;, &quot;dataTemplate&quot;: &quot;{\\&quot;Bool\\&quot;:\\&quot;false\\&quot;, \\&quot;EnableRandomization_Bool\\&quot;: \\&quot;false\\&quot;}&quot;, &quot;sendSingle&quot;: true } }, { &quot;log&quot;:{} } ]} 打印eKuiper日志docker logs edgex-kuiper 测试完成 换个例子 删除刚刚创建的两条规则，只创建一条规则，作用是监视来自Random-Integer-Device设备的事件，如果int8读取值的平均值（20 秒内）小于30，则向Random-Boolean-Device设备发送命令以开始生成随机数字，如果int8读取值的平均值（20 秒内）大于等于30，则向Random-Boolean-Device设备发送命令以停止生成随机数字。 12#posthttp://192.168.0.107:59720/rules 123456789101112131415161718#body{ &quot;id&quot;: &quot;rule2&quot;, &quot;sql&quot;: &quot;SELECT avg(int8) AS avg_int8 FROM demo WHERE int8 != nil GROUP BY TUMBLINGWINDOW(ss, 20)&quot;, &quot;actions&quot;: [ { &quot;rest&quot;: { &quot;url&quot;: &quot;http://edgex-core-command:59882/api/v2/device/name/Random-Boolean-Device/WriteBoolValue&quot;, &quot;method&quot;: &quot;put&quot;, &quot;dataTemplate&quot;: &quot;{\\&quot;Bool\\&quot;:\\&quot;{{if lt .avg_int8 30.0}}true\\&quot;{{else if ge .avg_int8 30.0}}false\\&quot;{{end}},\\&quot;EnableRandomization_Bool\\&quot;: \\&quot;{{if lt .avg_int8 30.0}}true\\&quot;{{else if ge .avg_int8 30.0}}false\\&quot;{{end}}}&quot;, &quot;sendSingle&quot;: true } }, { &quot;log&quot;:{} } ]} 这里面需要用到go template模板，看到Stack Overflow中有提到现在依然不是非常完善，因此在使用的时候比较麻烦。比如这边的30必须写出30.0，不然就会报错。 测试成功 云端的数据导出和远程数据访问显示首先将将应用程序服务添加到 docker-compose.yml文件中，设置如下： 运行docker-compose up -d 更新服务，之后在浏览器中打开http://www.hivemq.com/demos/websocket-client connect之后订阅主题Cxdtest，即可得到发送至EdgeX核心数据的相关数据。","link":"/EdgeX/edgex%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"edgex Makefile 解析","text":"edgex Makefile 解析直接上代码！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231## Copyright (c) 2018 Cavium## SPDX-License-Identifier: Apache-2.0##不去关注当前目录下是否存在以下文件，直接执行后面的命令，中文直译就是假的，伪造的.PHONY: build clean unittest hadolint lint test docker run#是否使用CGO编译器GO=CGO_ENABLED=0 GO111MODULE=on goGOCGO=CGO_ENABLED=1 GO111MODULE=on go#定义变量DOCKERS= \\ docker_core_data \\ docker_core_metadata \\ docker_core_command \\ docker_support_notifications \\ docker_sys_mgmt_agent \\ docker_support_scheduler \\ docker_security_proxy_setup \\ docker_security_secretstore_setup \\ docker_security_bootstrapper.PHONY: $(DOCKERS)#定义变量MICROSERVICES= \\ cmd/core-data/core-data \\ cmd/core-metadata/core-metadata \\ cmd/core-command/core-command \\ cmd/support-notifications/support-notifications \\ cmd/sys-mgmt-executor/sys-mgmt-executor \\ cmd/sys-mgmt-agent/sys-mgmt-agent \\ cmd/support-scheduler/support-scheduler \\ cmd/security-proxy-setup/security-proxy-setup \\ cmd/security-secretstore-setup/security-secretstore-setup \\ cmd/security-file-token-provider/security-file-token-provider \\ cmd/secrets-config/secrets-config \\ cmd/security-bootstrapper/security-bootstrapper.PHONY: $(MICROSERVICES)VERSION=$(shell cat ./VERSION 2&gt;/dev/null || echo 0.0.0)DOCKER_TAG=$(VERSION)-dev#设置包中的变量值GOFLAGS=-ldflags &quot;-X github.com/edgexfoundry/edgex-go.Version=$(VERSION)&quot;GOTESTFLAGS?=-race#获取git的commit的IDGIT_SHA=$(shell git rev-parse HEAD)#显示电脑架构ARCH=$(shell uname -m)#如何在当前目录下执行make bulid 则会执行下面这行命令 这行命令又会执行MICROSERVICES定义的各个命令build: $(MICROSERVICES)tidy: go mod tidy#将构建的可执行文件写入到目标目录中，比如./cmd/core-metadatacmd/core-metadata/core-metadata: $(GO) build $(GOFLAGS) -o $@ ./cmd/core-metadatacmd/core-data/core-data: $(GOCGO) build $(GOFLAGS) -o $@ ./cmd/core-datacmd/core-command/core-command: $(GO) build $(GOFLAGS) -o $@ ./cmd/core-commandcmd/support-notifications/support-notifications: $(GO) build $(GOFLAGS) -o $@ ./cmd/support-notificationscmd/sys-mgmt-executor/sys-mgmt-executor: $(GO) build $(GOFLAGS) -o $@ ./cmd/sys-mgmt-executorcmd/sys-mgmt-agent/sys-mgmt-agent: $(GO) build $(GOFLAGS) -o $@ ./cmd/sys-mgmt-agentcmd/support-scheduler/support-scheduler: $(GO) build $(GOFLAGS) -o $@ ./cmd/support-schedulercmd/security-proxy-setup/security-proxy-setup: $(GO) build $(GOFLAGS) -o ./cmd/security-proxy-setup/security-proxy-setup ./cmd/security-proxy-setupcmd/security-secretstore-setup/security-secretstore-setup: $(GO) build $(GOFLAGS) -o ./cmd/security-secretstore-setup/security-secretstore-setup ./cmd/security-secretstore-setupcmd/security-file-token-provider/security-file-token-provider: $(GO) build $(GOFLAGS) -o ./cmd/security-file-token-provider/security-file-token-provider ./cmd/security-file-token-providercmd/secrets-config/secrets-config: $(GO) build $(GOFLAGS) -o ./cmd/secrets-config ./cmd/secrets-configcmd/security-bootstrapper/security-bootstrapper: $(GO) build $(GOFLAGS) -o ./cmd/security-bootstrapper/security-bootstrapper ./cmd/security-bootstrapperclean: rm -f $(MICROSERVICES)unittest: go mod tidy GO111MODULE=on go test $(GOTESTFLAGS) -coverprofile=coverage.out ./...#使用hadolint帮助构建docker镜像#当前目录下的.hadolint.yaml文件有以下内容#忽略如下规则#ignored:# - DL3006# - DL3018# - DL3059#受信任的仓库#trustedRegistries:# - docker.iohadolint: if which hadolint &gt; /dev/null ; then hadolint --config .hadolint.yml `find * -type f -name 'Dockerfile*' -print` ; elif test &quot;${ARCH}&quot; = &quot;x86_64&quot; &amp;&amp; which docker &gt; /dev/null ; then docker run --rm -v `pwd`:/host:ro,z --entrypoint /bin/hadolint hadolint/hadolint:latest --config /host/.hadolint.yml `find * -type f -name 'Dockerfile*' | xargs -i echo '/host/{}'` ; fi lint: @which golangci-lint &gt;/dev/null || echo &quot;WARNING: go linter not installed. To install, run\\n curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b \\$$(go env GOPATH)/bin v1.42.1&quot; @if [ &quot;z${ARCH}&quot; = &quot;zx86_64&quot; ] &amp;&amp; which golangci-lint &gt;/dev/null ; then golangci-lint run --config .golangci.yml ; else echo &quot;WARNING: Linting skipped (not on x86_64 or linter not installed)&quot;; fitest: unittest hadolint lint GO111MODULE=on go vet ./... gofmt -l $$(find . -type f -name '*.go'| grep -v &quot;/vendor/&quot;) [ &quot;`gofmt -l $$(find . -type f -name '*.go'| grep -v &quot;/vendor/&quot;)`&quot; = &quot;&quot; ] ./bin/test-attribution-txt.sh#构建docker镜像docker: $(DOCKERS)#--bulid-arg 设置构建时候的参数#-f 构建时使用的Dockerfile文件#--label 将元数据添加到镜像，键值对形式#-t 设置镜像的tag#. 当前目录docker_core_metadata: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/core-metadata/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/core-metadata:$(GIT_SHA) \\ -t edgexfoundry/core-metadata:$(DOCKER_TAG) \\ .docker_core_data: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/core-data/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/core-data:$(GIT_SHA) \\ -t edgexfoundry/core-data:$(DOCKER_TAG) \\ .docker_core_command: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/core-command/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/core-command:$(GIT_SHA) \\ -t edgexfoundry/core-command:$(DOCKER_TAG) \\ .docker_support_notifications: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/support-notifications/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/support-notifications:$(GIT_SHA) \\ -t edgexfoundry/support-notifications:$(DOCKER_TAG) \\ .docker_support_scheduler: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/support-scheduler/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/support-scheduler:$(GIT_SHA) \\ -t edgexfoundry/support-scheduler:$(DOCKER_TAG) \\ .docker_sys_mgmt_agent: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/sys-mgmt-agent/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/sys-mgmt-agent:$(GIT_SHA) \\ -t edgexfoundry/sys-mgmt-agent:$(DOCKER_TAG) \\ .docker_security_proxy_setup: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/security-proxy-setup/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/security-proxy-setup:$(GIT_SHA) \\ -t edgexfoundry/security-proxy-setup:$(DOCKER_TAG) \\ .docker_security_secretstore_setup: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/security-secretstore-setup/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/security-secretstore-setup:$(GIT_SHA) \\ -t edgexfoundry/security-secretstore-setup:$(DOCKER_TAG) \\ .docker_security_bootstrapper: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f cmd/security-bootstrapper/Dockerfile \\ --label &quot;git_sha=$(GIT_SHA)&quot; \\ -t edgexfoundry/security-bootstrapper:$(GIT_SHA) \\ -t edgexfoundry/security-bootstrapper:$(DOCKER_TAG) \\ .vendor: $(GO) mod vendor","link":"/EdgeX/edgex-makefile-%E8%A7%A3%E6%9E%90/"},{"title":"edgex部署机器学习模型","text":"总体上分为三个部分： 设置EdgeX触发器，当有图片事件的时候，触发触发器，触发器将图片数据发送给监听程序 监听程序：对图片数据进行解析，比如这次是将图像的base64编码解析成RGB数据，并且转换成张量数据发送给推理模型 推理端：对收到的数据进行推理，返回推理结果，利用tensorflow serving进行部署，具体参考https://tensorflow.google.cn/tfx/guide/serving 发送图片数据，利用虚拟设备sample-image: edgex 打印log 显示接收到数据，触发器触发，之后便会发送数据到监听端，然后发送给推理端进行推理，最后返回结果","link":"/EdgeX/edgex%E9%83%A8%E7%BD%B2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/"},{"title":"K3s的安装","text":"k3s安装k3s的安装步骤极为简单，只需一步就可以完成安装： 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 但其实在k3s-install.sh文件中做了许多的配置工作。 将工作节点添加到集群，执行下面的步骤： 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh - k3s比k8s好在哪些地方 其二进制文件只有60MB左右，并且需要的内存比k8s小得多，可以在 512MB 内存以上的任何机器上运行集群，这意味着我们可以允许 Pod 运行在主节点和节点上。 适合边缘计算（单主节点） 简单的安装方式/并且可以快速启动集群 缩减了外部依赖项，并且所有的依赖项都在应该单一的二进制文件中","link":"/EdgeX/k3s%E7%9A%84%E5%AE%89%E8%A3%85/"},{"title":"k8s+EdgeX部署","text":"基于Ubuntu18.04 需要两个CPU核心 第1步：主机名解析好处就是节点之间可以通过主机名直接访问 1$ vim /etc/hosts 添加内容，这里面的ip和主机名需要以自己的为准，比如：192.168.0.200 master192.168.0.201 node1192.168.0.202 node2 第2步：时间同步123$ sudo apt install chrony$ systemctl start chronyd$ systemctl enable chronyd 查看是否工作 12$ date #返回时间$ systemctl is-enabled chronyd.service #应该返回enable 第3步：关闭交换区123$ swapoff -a #这时临时的#永久关闭,把里面swapfile那一行注释掉$ vim /etc/fstab 第4步:禁用Iptables和firewalld(我的系统并没有这预装这两个服务)12345678910$ systemctl stop firewalld#输出：Failed to stop firewalld.service: Unit firewalld.service not loaded. 说明防火墙没启动 不用管$ systemctl disable firewalld#输出：Failed to disable unit: Unit file firewalld.service does not exist. 说明防火墙根本不存在 不用管#关闭系统iptables服务$ systemctl stop iptables$ systemctl disable iptables#输出:Failed to stop iptables.service: Unit iptables.service not loaded. 不用管#输出:Failed to disable unit: Unit file iptables.service does not exist. 不用管 第5步：禁用selinux1234#首先查看这个服务是否开启$ getenforce#如果输出：Command 'getenforce' not found, but can be installed with: apt install selinux-utils 如果是这样，那下面步骤不用做$ vim /etc/selinux/config #将文件里面的SELINUX=disabled 需要重启才生效，可以到最后进行重启 第6步：编辑linux内核参数1234567891011121314$ vim /etc/sysctl.d/kubernetes.conf#添加下面这些配置net.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1#重新加载配置$ sysctl -p#加载网桥过滤模块$ modprobe br_netfilter#查看是否加载成功$ lsmod | grep br_netfilter#系统重启$ reboot 第6步：配置ipvs1234567891011121314151617#安装ipset和ipvsadm$ apt install ipset$ apt install ipvsadm#加载需要的模块$ mkdir -p /etc/sysconfig/modules/cat &lt;&lt;EOF&gt; /etc/sysconfig/modules/ipvs.modules #!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shEOF#添加可执行权限$ chmod +x /etc/sysconfig/modules/ipvs.modules$ bash /etc/sysconfig/modules/ipvs.modules#查看是否加载成功$ lsmod | grep -e ip_vs 第7步：安装docker手动安装步骤省略，可以直接使用脚本安装 1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 安装完之后执行以下命令 123456789#创建 /etc/docker 目录$ mkdir /etc/docker#配置镜像源以及cgroupcat &gt; /etc/docker/daemon.json &lt;&lt;EOF{&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],&quot;registry-mirrors&quot;: [&quot;https://fsmye2b3.mirror.aliyuncs.com&quot;]}EOF 重启docker服务 123$ systemctl daemon-reload $ systemctl restart docker $ systemctl enable docker 第8步：安装kubernetes组件123456789101112131415#添加apt-key和源$ sudo apt update &amp;&amp; sudo apt install -y apt-transport-https curl$ curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -$ echo &quot;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&quot; &gt;&gt;/etc/apt/sources.list.d/kubernetes.list#安装$ sudo apt update$ sudo apt-get install -y kubelet=1.22.1-00 kubeadm=1.22.1-00 kubectl=1.22.1-00$ sudo apt-mark hold kubelet=1.22.1-00 kubeadm=1.22.1-00 kubectl=1.22.1-00#配置kubelet的cgroup$ vim /etc/sysconfig/kubelet#添加如下内容KUBELET_CGROUP_ARGS=&quot;--cgroup-driver=systemd&quot;KUBE_PROXY_MODE=&quot;ipvs&quot;#设置开机自启$ systemctl enable kubelet 第9步：准备集群环境相关镜像编写脚本，设置镜像仓库 1$ vim pull_k8s_images.sh 下面的内容粘贴进去 12345678910111213141516171819202122232425262728set -o errexitset -o nounsetset -o pipefail##定义版本KUBE_VERSION=v1.22.1KUBE_PAUSE_VERSION=3.5ETCD_VERSION=3.5.0-0DNS_VERSION=v1.8.4GCR_URL=k8s.gcr.io##使用的镜像仓库DOCKERHUB_URL=k8simage##镜像列表images=(kube-proxy:${KUBE_VERSION}kube-scheduler:${KUBE_VERSION}kube-controller-manager:${KUBE_VERSION}kube-apiserver:${KUBE_VERSION}pause:${KUBE_PAUSE_VERSION}etcd:${ETCD_VERSION}coredns:${DNS_VERSION})##拉取并改名for imageName in ${images[@]} ; do docker pull $DOCKERHUB_URL/$imageName docker tag $DOCKERHUB_URL/$imageName $GCR_URL/$imageName docker rmi $DOCKERHUB_URL/$imageNamedone 1234#授予执行权限$ chmod +x ./pull_k8s_images.sh#执行脚本$ ./pull_k8s_images.sh 这个时候使用docker images查看拉取镜像是否成功，应该唯独没有coredns 因为这个仓库里面没有接下来单独拉取coredns 123$ docker pull coredns/coredns:1.8.4$ docker tag coredns/coredns:1.8.4 k8s.gcr.io/coredns/coredns:v1.8.4$ docker rmi coredns/coredns:1.8.4 这个时候使用docker images检查一遍，应该都有了 如果部署多个结点，上面的步骤需要在每个节点上都运行一遍 第10步:集群初始化（在master节点操作）123456789#这边的--apiserver-advertise-address=192.168.0.150需要根据自己master节点的ip进行修改$ sudo kubeadm init --apiserver-advertise-address=192.168.0.150 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --kubernetes-version=v1.22.1#创建配置文件夹$ mkdir -p $HOME/.kube$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$ sudo chown $(id -u):$(id -g) $HOME/.kube/config#子节点加入集群，在子节点操作，下面的命令会在master 执行init操作之后终端会有输出（每个人不一样，需要用自己的），直接复制即可，比如：kubeadm join 192.168.0.150:6443 --token b0oxg7.zxc5etvu2412etn1 \\ --discovery-token-ca-cert-hash sha256:a507d34b2f40d931edf35f0dac6b95ca3f68cf529d30557b3f7258cd955fa75e 第11步：部署网络（在master节点操作）由于raw.githubusercontent.com被墙，先配置host这边需要在https://www.ipaddress.com/查询raw.githubusercontent.com的ip地址 12345$ vim /etc/hosts#添加如下内容185.199.108.133 raw.githubusercontent.com#执行（如果网络还是不行，可以下载这个文件传到虚拟机上）$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 使用kubectl get nodes命令查看，节点应该都是ready状态 1$ kubectl get nodes 部署edgex，可以用1.x版本也可以用2.0 1$ vim k8s-redis-no-secty-with-ui.yaml 粘贴内容，文件群里有，如果用1.x版本的，官网有，地址如下：https://github.com/edgexfoundry/edgex-examples/blob/main/deployment/kubernetes/k8s-hanoi-redis-no-secty.yml 1234#允许master节点部署pod,这边如果只创建了一个master节点，没有工作节点，则需要设置；如果有工作节点，则跳过此步骤$ kubectl taint nodes --all node-role.kubernetes.io/master-#部署（第一次耗时会比较长）$ kubectl apply -f k8s-redis-no-secty-with-ui.yaml 最后可以通过kubectl get pods,svc 查看状态结束","link":"/EdgeX/k8s-edgex%E9%83%A8%E7%BD%B2/"},{"title":"k8s的学习","text":"k8s的管理功能体现在什么地方？ ​ 早期应用程序的部署会直接部署在物理机上，较为简单，但不同的应用程序之间会产生影响。之后产生了虚拟化部署，虽然保证了程序间的隔离，但极大地耗费资源。于是容器化部署出现了，容器化部署可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等，运行应用程序所需要的资源都被容器包装，并与底层基础架构解耦等。 ​ 具体来说，容器化部署有如下这些优点（来自k8s官方文档）： 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像， 从而将应用程序与基础架构分离。 可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。 但是容器化部署的方式也会遇到一些问题，比如： 一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器 当并发访问量变大的时候，怎么样做到横向扩展容器数量 这样的问题便是容器编排问题，由此也产生了一系列的容器编排管理工具，比如Swarm，Kubernetes。 总的来说，k8s的管理功能包括如下几个方面： 自我修复：一旦某一个容器崩溃，能够迅速启动新的容器（秒级） 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整 服务发现：服务可以通过自动发现的形式找到它所依赖的服务 负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡并分配网络流量 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本 存储编排：可以根据容器自身的需求自动创建挂载存储卷。（持久化容器内数据） Edgex2.0爱尔兰版本部署 yaml文件需要注意的问题：全局环境变量和局部环境变量需要全部大写（目前是这样的） kuiper挂载的目录问题：目前还不知道具体的挂载目录是哪个（暂时不实现数据持久化），用/kuiper/data会出现问题 找不到对应的kv表 一主一从： 部署： 查看pods是否工作正常： 通过ui页面： 虚拟设备自动事件工作正常：","link":"/EdgeX/k8s%E7%9A%84%E5%AD%A6%E4%B9%A0/"},{"title":"EdgeX基本概念及问题","text":"基本概念及概念 设备服务层（Device Services）设备服务层主要负责采集设备的数据，以及根据数据分析结果向设备发送控制命令。 EdgeX设备服务层是如何实现对一个特定设备的数据采集的。例如，现在有一个新的设备，我们希望EdgeX来采集这个设备的数据，该如何操作。 （1）是不是需要先把这个设备在EdgeX中注册，让EdgeX知道有这个设备？ 《edgex-device-service-requirements-v11》 ​ 由设备服务来完成，DS 至少需要在 Core Metadata 中定义一个 DeviceProfile 来表示它管理的一类设备，该配置文件可以在启动时通过导入 YAML 文件创建，或者在将第一个设备添加到 DS 之前按需创建。 DS 使用设备配置文件在 Core Data 中创建一个或多个 ValueDescriptor。 DS 可以使用从核心元数据读取的预先存在的 DeviceProfile 实例和/或在启动时创建一个或多个新的 DeviceProfile 实例。 ​ ​ 换句话说，设备服务“包装”了协议通信代码、设备驱动程序/固件和实际设备。 （2）然后呢？如何操作，是EdgeX发送命令给设备，设备收到命令后，就开始发送数据，还是设备和EdgeX注册关联后，就直接开始发送数据？ ​ 这个问题关键取决于EdgeX想不想要，比如边缘传感器设备它是实时工作的，它只要在工作都会有数据产生，这个时候这些数据最后还是却决于EdgeX需不需要，如果需要我就可以发送命令，也可以设置时间间隔，每隔多长时间我需要一次数据。 （3）设备发送的数据需要是何种格式，是不是需要定义一种数据格式协议？设备按照这个格式协议对数据进行封装，EdgeX收到这些数据后，再按照同样的格式协议对数据包进行解析，这样才能正确理解设备发送过来的数据。那么，这些协议格式是使用现有的，还是要自定义。如果是现有的，那EdgeX支持哪些现有的协议？如果可以自定义，那是不是还要在设备端也开发这种协议的发送端代码？ ​ 当它摄取传感器数据时，设备服务将“事物”产生和通信的数据转换为通用的 EdgeX Foundry 数据结构，并将转换后的数据发送到核心服务层，以及 EdgeX 其他层的其他微服务。设备发送的数据是什么格式，采用什么协议，应该是由设备生产商负责的，EdgeX只需要知道它采用的什么协议，然后将得到的数据转换为通用的 EdgeX Foundry 数据。如果你是那个设备生产商，现在你采用的是应该全新的协议，显然这些都需要你自己负责。但即使这样设备服务依然不知道你发过来的信息代表着什么，需要在设备配置文件中进行配置。有关于设备类型、设备提供的数据以及如何命令设备都需要在设备配置文件中提供。 （4）如果EdgeX不支持某种设备协议，需要新增该协议，该如何自定义开发，在图中，EdgeX最底层设备服务层的最右边，有个SDK和additional device service，这个是什么功能？是不是用于协议扩展的。 核心服务层（Core Services）核心层的主要功能是什么？ （1）核心服务层中有Core Data和Meta Data，这些是不是数据库。EdgeX使用的是哪种数据库，为什么要使用数据库对数据进行存储？ ​ 这些不是数据库，是微服务，通过对数据库的管理服务，现在使用redis，为了数据本地持久化，比如由于网络原因，云端或者企业无法知道现在和过去的温度，通过数据库存储，在网络恢复后，可以知道过去的温度变化。如果不需要持久化，可以直接移除。 （2）核心服务层中有command，这个应该是EdgeX对收到的数据进行分析后，发送的设备控制命令。设备控制命令该用什么格式？将这个格式的命令发送给终端设备后，终端设备就能够理解这个command命令的含义吗？是不是一个设备要想接入EdgeX，还得在这个设备上开发很多协议，像数据发送格式协议，command接受解析协议等，从而使这些终端能够与EdgeX顺利交互。但如何这样的话，每个设备要接入到EdgeX，都需要在该设备上开发一种新的协议，那EdgeX用起来岂不是很麻烦？还是Command命令帧使用的也是现有的一种常见协议定义的格式，而大多数设备都是默认支持该协议功能的，因此，EdgeX发送的command能够直接被设备理解。 ​ edgex提供了很多API，可以通过API发送相关命令。 （3）核心服务层除了上面的数据库存储以及command命令下发发送，还有什么功能？Registry &amp; Config模块是什么作用？ ​ 比如metadata可以负责和设备服务的通信 ​ Registry &amp; Config模块应该是负责配置微服务的相关属性（比如位置和状态） 支撑服务层（Supporting Services）支撑服务层主要是什么功能？ （1）支撑服务层中有Rules engine，就是规则引擎，大概就是运行各式数据处理规则。那么，EdgeX支持哪些规则引擎方法，除了Kuiper规则引擎外，还支持哪些？是不是还支持Drools、Foghorn等？这些规则引擎具体能够执行什么数据处理任务？ ​ 还支持哪些不清楚 ​ 现在2.0使用eKuiper规则引擎：https://docs.edgexfoundry.org/2.0/microservices/support/eKuiper/Ch-eKuiper/ ​ 能够执行什么任务？比如数据过滤，通过SQL来过滤数据管道中的数据，获得想要的一些信息。 （2）支撑服务层中还有Scheduling模块，这个调度是调度什么，有什么作用？ ​ 提供一个内部EdgeX时钟，可以启动EdgeX服务中的操作，配置的时候可以配置时间间隔，就是每个多长时间做一次什么事情，比如定期进行数据清理 应用服务层（1）应用服务层是什么功能？ （2）EdgeX与云端的交互，也即将数据发送到云端的操作，是不是由应用服务层来实现？ （3）EdgeX是如何与云端交互的，数据用什么样的协议格式发送给云端？ ​ 监听数据通道，触发器触发（可以监听一些数据主题），过滤好数据之后（比如要求信息来自于什么设备，需要这个设备的哪些信息），数据转换成json或者XML格式，之后可以调用api特定端口，完成与云端的交互（这是其中的一种方案）。 ​ 或者就是经过一系列自定义函数，之后返回给数据通道，执行一些内部操作。 （4）如何指定要接受数据的云端目的对象？ ​ 管道函数内如果调用api接口，可以通过端口指定。 （5）对云端有什么要求，云端是不是要运行一个接受EdgeX数据的程序？支持哪些云服务？华为云，阿里云，还是只能支持指定的几种云？ 微服务容器化在EdgeX架构图的右上方，还存在一个Container deployment，也即容器。 （1）EdgeX是通过docker来实现容器功能的。什么是Docker和容器？Docker和虚拟机又有什么区别？ ​ docker pull镜像，然后docker run可以生成一个容器，可以这么理解，容器就是镜像的实例化，docker的文件管理是分层的。 ​ docker是安全隔离，而虚拟机是完全隔离的。 （2）为什么EdgeX中要使用容器和docker？有什么好处？什么目的？ ​ 速度快，迁移性强，便于部署","link":"/EdgeX/edgex%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E9%97%AE%E9%A2%98/"},{"title":"本地docker镜像仓库部署","text":"1.运行本地注册表使用如下命令启动注册表容器： 1$ docker run -d -p 5000:5000 --restart=always --name registry registry:2 警告:仅适用于测试的注册表配置。生产就绪的注册表必须受 TLS 保护，并且最好使用访问控制机制。继续阅读并继续阅读配置指南以部署生产就绪注册表。 2.从dockerhub上拉取镜像后标记并且推送到本地注册表从 Docker Hub 拉取镜像并将其推送到注册表。以下示例nginx:latest从 Docker Hub拉取映像并将其重新标记为nginx:test，然后将其推送到本地注册表。最后， 移除nginx:latest和nginx:test并且从本地拉取nginx:test。 nginx:latest从 Docker Hub拉取镜像。 1$ docker pull nginx:latest 将图像标记为localhost:5000/my-ubuntu。这会为现有图像创建一个附加标签。当标签的第一部分是主机名和端口时，Docker 在推送时将其解释为注册表的位置。 1$ docker tag nginx:latest localhost:5000/nginx:test 将映像推送到在以下位置运行的本地注册表localhost:5000： 1$ docker push localhost:5000/nginx:test 删除本地缓存ubuntu:16.04和localhost:5000/my-ubuntu 图像，以便您可以测试从注册表中拉取图像。这不会localhost:5000/my-ubuntu从您的注册表中删除图像。 12$ docker image remove nginx:latest$ docker image remove localhost:5000/nginx:test localhost:5000/my-ubuntu从本地注册表中拉取映像。 1$ docker pull localhost:5000/nginx:test 这个步骤可能会出现 docker registry push 遇到 “Get https://xxx:5000/v2/: http: server gave HTTP response to HTTPS client ”的问题 解决方案a.修改docker配置文件12345vi /etc/docker/daemon.json#添加 insecure-registries{ &quot;insecure-registries&quot;: [&quot;http://xxx.xxx.xxx.xxx:5000&quot;]} b.重新加载并且重启docker12systemctl daemon-reloadsystemctl restart docker 3.K3S私有镜像仓库配置需要在每个节点上配置每个节点上配置/etc/rancher/k3s/registries.yaml 不使用 TLS并且不认证1234mirrors: docker.io: endpoint: - &quot;http://mycustomreg.com:5000&quot;","link":"/EdgeX/%E6%9C%AC%E5%9C%B0docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E9%83%A8%E7%BD%B2/"},{"title":"树莓派EdgeX+TensorflowLite实现机器学习推理","text":"安装 TensorFlow Lite 解释器需要根据平台以及python版本选择安装，下面是linux(arm64)平台的，python版本为3.7 1pip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_aarch64.whl 具体参考https://tensorflow.google.cn/lite/guide/python 使用 tflite_runtime 运行推理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#监听8888端口，对收到的图片base64编码解析后进行推理from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport base64import ioimport jsonimport jsonpathimport numpy as npimport timeimport argparsefrom PIL import Imagefrom tflite_runtime.interpreter import Interpreterfrom flask import Flask,requestapp = Flask(__name__)#测试@app.route(&quot;/hello/&quot;, methods=['POST', 'GET'])def hello(): return &quot;hello&quot;#监听并且推理@app.route(&quot;/flask_api/&quot;, methods=['POST', 'GET'])def flask_api(): parser = argparse.ArgumentParser( formatter_class=argparse.ArgumentDefaultsHelpFormatter) parser.add_argument( '--model', default='lite-model_imagenet_mobilenet_v3_large_075_224_classification_5_metadata_1.tflite', required=False) args = parser.parse_args() interpreter = Interpreter(args.model) interpreter.allocate_tensors() _, height, width, _ = interpreter.get_input_details()[0]['shape'] # 获取请求数据 data2 = json.loads(request.data) res = jsonpath.jsonpath(data2, '$..binaryValue') res = &quot;&quot;.join(res) # 解析图片数据 imgdata = base64.b64decode(res) input_image = Image.open(io.BytesIO(imgdata)) input_image = np.array(Image.open(io.BytesIO(imgdata)).resize([width, height]), dtype=np.float32) input_image = np.expand_dims(input_image / 255.0, 0) # 计算推理延迟时间 start_time = time.time() results = classify_image(interpreter, input_image) elapsed_ms = (time.time() - start_time) # 加载标签数据 strlabel = load_labels('labels.txt') result = 'Prediction class: {}, avg latency: {} ms'.format( strlabel[results], (elapsed_ms * 1000) ) # 打印推理结果 print(result) # 返回推理结果 return str(results)def load_labels(path): with open(path, 'r') as f: return {i: line.strip() for i, line in enumerate(f.readlines())} def set_input_tensor(interpreter, image): interpreter.set_tensor(interpreter.get_input_details()[0][&quot;index&quot;], image)def classify_image(interpreter, image, top_k=1): &quot;&quot;&quot;Returns a sorted array of classification results.&quot;&quot;&quot; set_input_tensor(interpreter, image) interpreter.invoke() result = interpreter.tensor(interpreter.get_output_details()[0][&quot;index&quot;])() return np.argmax(result)if __name__ == '__main__': app.run('0.0.0.0', 8888) 构建机器学习推理环境镜像Dockerfile 12345678910111213#基于的基础镜像FROM python:3.7-slim# 设置code文件夹是工作目录WORKDIR /code#代码添加到code文件夹COPY . .# 安装依赖环境RUN pip install -r requirements.txtRUN pip3 install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_aarch64.whl#暴露端口 也是flask监听端口EXPOSE 8888#运行python项目CMD [&quot;python&quot;, &quot;app.py&quot;] 构建EdgeX-AppService镜像Dockerfile 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152## Copyright (c) 2021 Intel Corporation## Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#FROM golang:1.16-alpine AS builderLABEL license='SPDX-License-Identifier: Apache-2.0' \\ copyright='Copyright (c) 2019: Intel'# add git for go modulesRUN apk update &amp;&amp; apk add --no-cache make git gcc libc-dev libsodium-dev zeromq-devWORKDIR /post-and-cmdCOPY go.mod .RUN go env -w GO111MODULE=onRUN go env -w GOPROXY=https://goproxy.cn,directRUN go mod downloadCOPY . .RUN apk info -a zeromq-devRUN make build# Next image - Copy built Go binary into new workspaceFROM alpineLABEL license='SPDX-License-Identifier: Apache-2.0' \\ copyright='Copyright (c) 2019: Intel'RUN apk --no-cache add zeromq# Turn off secure mode for examples. Not recommended for productionENV EDGEX_SECURITY_SECRET_STORE=falseCOPY --from=builder /post-and-cmd/res /resCOPY --from=builder /post-and-cmd/app-service /post-and-cmdCMD [ &quot;/post-and-cmd&quot;, &quot;-cp=consul.http://edgex-core-consul:8500&quot;, &quot;--registry&quot;,&quot;--confdir=/res&quot;] makefile 12345678910111213141516171819.PHONY: build cleanGO=CGO_ENABLED=1 GO111MODULE=on gobuild: go mod tidy $(GO) build -o app-service docker: docker build \\ --build-arg http_proxy \\ --build-arg https_proxy \\ -f Dockerfile \\ -t caixindi/edgex-app-service-simple-image-classification-http:3.0.1 \\ --platform linux/arm64 \\ --push \\ .clean: rm -f app-service make docker执行镜像构建任务 树莓派部署(使用K3S).yaml文件，以下只是新增内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798... - apiVersion: v1 kind: Service metadata: name: tf-listener spec: type: NodePort selector: app: tf-listener ports: - name: tcp-8888 port: 8888 protocol: TCP targetPort: 8888 nodePort: 30888 - apiVersion: v1 kind: Service metadata: name: edgex-app-service-simple-image-classification-http spec: type: NodePort selector: app: edgex-app-service-simple-image-classification-http ports: - name: tcp-58780 port: 58786 protocol: TCP targetPort: 58786... - apiVersion: apps/v1 kind: Deployment metadata: name: edgex-app-service-simple-image-classification-http spec: selector: matchLabels: app: edgex-app-service-simple-image-classification-http template: metadata: labels: app: edgex-app-service-simple-image-classification-http spec: hostname: edgex-app-service-simple-image-classification-http containers: - name: edgex-app-service-simple-image-classification-http image: caixindi/edgex-app-service-simple-image-classification-http:3.0 imagePullPolicy: IfNotPresent ports: - name: http protocol: TCP containerPort: 58786 env: - name: SERVICE_HOST value: &quot;edgex-app-service-simple-image-classification-http&quot; - name: TRIGGER_EDGEXMESSAGEBUS_PUBLISHHOST_HOST value: &quot;edgex-redis&quot; - name: TRIGGER_EDGEXMESSAGEBUS_SUBSCRIBEHOST_HOST value: &quot;edgex-redis&quot; - name: DATABASE_HOST value: &quot;edgex-redis&quot; - name: SREVICE_SERVERBINDADDR value: &quot;0.0.0.0&quot; - name: CLIENTS_CORE_METADATA_HOST value: &quot;edgex-core-metadata&quot; - name: REGISTRY_HOST value: &quot;edgex-core-consul&quot; - name: APPLICATIONSETTINGS_HTTPEXPORTURL value: &quot;http://192.168.137.100:30888/object detection&quot; - name: TRIGGER_EDGEXMESSAGEBUS_SUBSCRIBEHOST_SUBSCRIBETOPICS value: &quot;edgex/events/#&quot; - name: APPLICATIONSETTINGS_DEVICENAMES value: &quot;sample-image&quot; - name: CLIENTS_CORE_COMMAND_HOST value: &quot;edgex-core-command&quot; - apiVersion: apps/v1 kind: Deployment metadata: name: tf-listener spec: replicas: 3 selector: matchLabels: app: tf-listener template: metadata: labels: app: tf-listener spec: containers: - image: caixindi/tf-listener:3.0.0 name: tf-listener imagePullPolicy: IfNotPresent ports: - name: http containerPort: 8888 protocol: TCP 部署 kubectl apply -f ... 发送图片 查看appservice log 查看高温预警值 数值208（从0开始）代表第209类，识别结果为golden retriever. 整个项目的逻辑是（虽然并没有意义）：appservice设置触发器，当有图片数据传入时，触发器触发响应事件，向推理程序的监听端口发送图片数据，程序收到图片数据后进行推理，返回推理结果，appservice再将推理结果，也就是最终推理的是第几类别，通过给设备发送命令的方式，将温湿度传感器设置成相应的数值。 附：python生成requirements.txt的两种方法第一种 适用于单虚拟环境的情况：1pip freeze &gt; requirements.txt 这种方式，会将环境中的依赖包全都加入，如果使用的全局环境，则下载的所有包都会在里面，不管是不是当前项目依赖的。 当然这种情况并不是我们想要的，当我们使用的是全局环境时，可以使用第二种方法。 第二种 使用pipreqs 安装 1pip install pipreqs 在当前目录执行 1pipreqs . --encoding=utf8 --force --encoding=utf8表示使用 utf8 编码，不然可能会报 UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xae in position 406: illegal multibyte sequence 的错误。--force 强制执行，当生成目录下的 requirements.txt 存在时覆盖。 使用 requirements.txt 安装依赖的方式： 1pip install -r requirements.txt","link":"/EdgeX/%E6%A0%91%E8%8E%93%E6%B4%BEedgex-tensorflowlite%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86/"},{"title":"树莓派系统部署k3s有关操作","text":"开启Wifi模块123#开启wifi模块rfkill unblock wifisudo iwlist scan | grep ESSID 配置host123192.168.137.100 master192.168.137.101 agent01192.168.137.102 agent02 配置wifi以及静态ip123456789101112131415sudo nano /etc/wpa_supplicant/wpa_supplicant.confctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdevupdate_config=1#在结尾处添加network={ ssid=&quot;TestWifi&quot; psk=&quot;12345678&quot;}sudo nano /etc/dhcpcd.conf#结尾处添加interface wlan0static ip_address=192.168.137.100/24 #需要重新配置static routers=192.168.137.1static domain_name_servers=114.114.114.114 在 Raspbian Buster 上启用旧版的 iptables#Raspbian Buster 默认使用nftables而不是iptables。 K3S 网络功能需要使用iptables，而不能使用nftables。 按照以下步骤切换配置Buster使用legacy iptables： 123sudo iptables -Fsudo update-alternatives --set iptables /usr/sbin/iptables-legacysudo update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy 为 Raspbian Buster 启用 cgroup#标准的 Raspbian Buster 安装没有启用 cgroups。K3S 需要cgroups来启动 systemd 服务。在/boot/cmdline.txt中添加cgroup_memory=1 cgroup_enable=memory就可以启用cgroups。 1reboot server节点设置K3S_URL参数会使 K3s 以 worker 模式运行。K3s agent 将在所提供的 URL 上向监听的 K3s 服务器注册。K3S_TOKEN使用的值存储在你的服务器节点上的/var/lib/rancher/k3s/server/node-token路径下。 1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_NODE_NAME=master sh - 获取tokenK3S_TOKEN使用的值存储在服务器节点上的/var/lib/rancher/k3s/server/node-token路径下 agent节点1curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://master:6443 K3S_TOKEN=K10742df0412ea48b58f29a8a0ece0e2aea625e306853ba92c47ba86870a57a25df::server:9dbe384cf66d9da0504cd79f6a644db6 K3S_NODE_NAME=agent02 sh - 禁止调度server1kubectl cordon server 由于是arm64架构，需要更改yaml文件镜像拉取源 给节点打标签1kubectl label node agent01 disktype=node1","link":"/EdgeX/%E6%A0%91%E8%8E%93%E6%B4%BE%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2k3s%E6%9C%89%E5%85%B3%E6%93%8D%E4%BD%9C/"},{"title":"EdgeX实现温湿度数据读取","text":"在linux环境中进行测试 ​ 起初在win环境下可以通过使用商家提供的软件进行连接获取数据，但是在linux环境下不能连接。 ​ 之后通过设置树莓派eth0为静态ip，再ping 192.168.0.88 则可以发现该设备。 ​ 静态ip配置如下： 1234interface eth0static ip_address=192.168.0.2/24static routers=192.168.0.1static domain_name_servers=114.114.114.114 利用java编写master端代码，测试连接 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import com.intelligt.modbus.jlibmodbus.Modbus;import com.intelligt.modbus.jlibmodbus.exception.ModbusIOException;import com.intelligt.modbus.jlibmodbus.master.ModbusMaster;import com.intelligt.modbus.jlibmodbus.master.ModbusMasterFactory;import com.intelligt.modbus.jlibmodbus.tcp.TcpParameters;import java.net.InetAddress;import java.net.UnknownHostException;public class ModBusConnection { public final static TcpParameters tcpParameters = new TcpParameters(); public static ModbusMaster master; static { try { InetAddress adress = InetAddress.getByName(&quot;192.168.0.88&quot;); // TCP参数设置ip地址 tcpParameters.setHost(adress); // TCP设置长连接 tcpParameters.setKeepAlive(true); // TCP设置端口，这里设置是默认端口502 tcpParameters.setPort(502); // 创建一个主机 master = ModbusMasterFactory.createModbusMasterTCP(tcpParameters); Modbus.setAutoIncrementTransactionId(true); } catch (UnknownHostException e) { e.printStackTrace(); } } /** * 获取ModbusMaster * @return */ public static ModbusMaster getModbusMaster(){ return master; } /** * 关闭ModbusMaster */ public static void destoryModbusMaster(){ if(master.isConnected()){ try { master.disconnect(); } catch (ModbusIOException e) { e.printStackTrace(); } } }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import com.intelligt.modbus.jlibmodbus.Modbus;import com.intelligt.modbus.jlibmodbus.exception.ModbusIOException;import com.intelligt.modbus.jlibmodbus.master.ModbusMaster;import com.intelligt.modbus.jlibmodbus.master.ModbusMasterFactory;import com.intelligt.modbus.jlibmodbus.tcp.TcpParameters;import java.net.InetAddress;import java.net.UnknownHostException;public class ModBusConnection { public final static TcpParameters tcpParameters = new TcpParameters(); public static ModbusMaster master; static { try { InetAddress adress = InetAddress.getByName(&quot;192.168.0.88&quot;); // TCP参数设置ip地址 tcpParameters.setHost(adress); // TCP设置长连接 tcpParameters.setKeepAlive(true); // TCP设置端口，这里设置是默认端口502 tcpParameters.setPort(502); // 创建一个主机 master = ModbusMasterFactory.createModbusMasterTCP(tcpParameters); Modbus.setAutoIncrementTransactionId(true); } catch (UnknownHostException e) { e.printStackTrace(); } } /** * 获取ModbusMaster * @return */ public static ModbusMaster getModbusMaster(){ return master; } /** * 关闭ModbusMaster */ public static void destoryModbusMaster(){ if(master.isConnected()){ try { master.disconnect(); } catch (ModbusIOException e) { e.printStackTrace(); } } }} 输出如下： 这是两个十六进制数，转为为十进制表示：101H=257D，也就是表示25.7摄氏度 248H=584D，也就表示湿度为58.4% 利用EdgeX获取数据 针对温湿度设备进行kuiper规则引擎测试 首先测试是否能获取温度数据： 12#get192.168.137.100:30082/api/v2/device/name/TCP-5900/Temperature 第一步：创建流post http://192.168.137.100:30720/streams body {&quot;sql&quot;: &quot;create stream demo() WITH (FORMAT=\\&quot;JSON\\&quot;, TYPE=\\&quot;edgex\\&quot;)&quot;} 第二步：创建规则监视来自TCP-5900设备的事件，如果Temperature读取值的平均值（20 秒内）大于 20，则向Random-Boolean-Device设备发送命令以停止生成随机数字（将随机生成 bool 设置为 false）。 12#posthttp://192.168.137.100:30720/rules 1234567891011121314151617{ &quot;id&quot;: &quot;rule1&quot;, &quot;sql&quot;: &quot;SELECT avg(temperature) AS avg_temperature FROM demo WHERE temperature != nil and meta(deviceName)= \\&quot;TCP-5900\\&quot; GROUP BY TUMBLINGWINDOW(ss, 5) HAVING avg(temperature) &gt; 20.0&quot;, &quot;actions&quot;: [ { &quot;rest&quot;: { &quot;url&quot;: &quot;http://edgex-core-command:59882/api/v2/device/name/Random-Boolean-Device/WriteBoolValue&quot;, &quot;method&quot;: &quot;put&quot;, &quot;dataTemplate&quot;: &quot;{\\&quot;Bool\\&quot;:\\&quot;false\\&quot;, \\&quot;EnableRandomization_Bool\\&quot;: \\&quot;false\\&quot;}&quot;, &quot;sendSingle&quot;: true } }, { &quot;log&quot;:{} } ]} 查看kuiper的log以及布尔型虚拟设备的值，规则生效 下面测试触发规则引擎后设置温湿度设备的高温预警值： 1234567891011121314151617{ &quot;id&quot;: &quot;rule2&quot;, &quot;sql&quot;: &quot;SELECT avg(temperature) AS avg_temperature FROM demo WHERE temperature != nil and meta(deviceName)= \\&quot;TCP-5900\\&quot; GROUP BY TUMBLINGWINDOW(ss, 5) HAVING avg(temperature) &gt; 20.0 &quot;, &quot;actions&quot;: [ { &quot;rest&quot;: { &quot;url&quot;: &quot;http://edgex-core-command:59882/api/v2/device/name/TCP-5900/HighTemperatureAlarm&quot;, &quot;method&quot;: &quot;put&quot;, &quot;dataTemplate&quot;: &quot;{\\&quot;HighTemperatureAlarm\\&quot;:\\&quot;66\\&quot;}&quot;, &quot;sendSingle&quot;: true } }, { &quot;log&quot;:{} } ]} rule2触发并且生效 下面测试当10秒内平均温度大于高温预警值的时候，发送数据给云端，规则如下： 1234567891011121314151617{ &quot;id&quot;: &quot;rule3&quot;, &quot;sql&quot;: &quot;SELECT avg(temperature) AS avg_temperature , avg(HighTemperatureAlarm) AS avg_hightemperaturealarm FROM event WHERE temperature != nil and meta(deviceName)= \\&quot;TCP-5900\\&quot; and meta(sourceName)=\\&quot;Data\\&quot; GROUP BY TUMBLINGWINDOW(ss, 10) HAVING avg(temperature) &gt; avg(hightemperaturealarm) &quot;, &quot;actions&quot;: [ { &quot;rest&quot;: { &quot;url&quot;: &quot;http://10.116.169.252:8888/kuiper&quot;, &quot;method&quot;: &quot;post&quot;, &quot;dataTemplate&quot;: &quot;{\\&quot;Temperature\\&quot;: \\&quot;{{.avg_temperature}}\\&quot;,\\&quot;HighTemperatureAlarm\\&quot;: \\&quot;{{.avg_hightemperaturealarm}}\\&quot;}&quot;, &quot;sendSingle&quot;: true } }, { &quot;log&quot;:{} } ]} kuiper日志如下： 云端收到消息：","link":"/EdgeX/edgex%E5%AE%9E%E7%8E%B0%E6%B8%A9%E6%B9%BF%E5%BA%A6%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96/"},{"title":"EdgeX联邦推理结果展示","text":"联邦推理 部署EdgeX环境 kubectl apply -f test.yaml 启动云端推理服务 python detect.py 使用postman 发送图片至EdgeX http://39.104.160.208:30086/api/v2/resource/sample-image/jpeg 使用k3s 查看容器日志 kubectl logs -f edgex-app-service-simple-image-classification-http-75c66b5vh4f5 查看推理结果图片（图片保存在挂载目录下）","link":"/EdgeX/edgex%E8%81%94%E9%82%A6%E6%8E%A8%E7%90%86%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA/"},{"title":"跨平台镜像制作","text":"首先需要对官方文档的Dockerfile进行配置，配置goproxy代理，其次需要更改依赖的golang版本，改为1.16版本以上（官方example的要求，后续自己的镜像可以自己选择）。 跨平台镜像制作需要使用bulidx，具体参考https://docs.docker.com/buildx/working-with-buildx/ 并且需要配置docker engine的环境变量 以及创建自己的bulider 1export DOCKER_CLI_EXPERIMENTAL=enabled","link":"/EdgeX/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/"},{"title":"回调函数","text":"GC垃圾回收基本的实现思路是，从每个包级的变量和每个当前运行函数的每一个局部变量开始，通过指针或引用的访问路径遍历，是否可以找到该变量。如果不存在这样的访问路径，那么说明该变量是不可达的，也就是说它是否存在并不会影响程序后续的计算结果。 因为一个变量的有效周期只取决于是否可达，因此一个循环迭代内部的局部变量的生命周期可能超出其局部作用域。同时，局部变量可能在函数返回之后依然存在。 编译器会自动选择在栈上还是在堆上分配局部变量的存储空间，但是这个选择并不是由用var还是new声明变量的方式决定的。如同下面这段代码： 123456789101112var global *intfunc f() { var x int x = 1 global = &amp;x}func g() { y := new(int) *y = 1} f函数里的变量必须在堆上分配，虽然它在函数的内部定义，但是因为它在f函数结束调用后，依然可以通过包一级的global变量找到，也就是局部变量从函数f中逃逸了。而对于g函数，当它结束调用的时，变量*y将不可达，也就是说可以马上把被回收，因此编译器可以选择在栈上分配*y的存储空间。(当然也可以选择在堆上分配)","link":"/Golang/%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/"},{"title":"回调函数","text":"什么是回调函数？在维基百科中，给出了这么一个定义：在计算机程序设计中，回调函数，或简称回调（Callback 即call then back 被主函数调用运算后会返回主函数），是指通过参数将函数传递到其它代码的，某一块可执行代码的引用。这一设计允许了底层代码调用在高层定义的子程序。 从图中可以这么理解，主程序在调用软件库的时候同时传入了一个回调函数，用来告诉这个库函数在执行完成后需要回调的函数，也就是主函数在调用库函数的同时也指定了回调函数，这样整个程序的灵活性会大大增强，通过传入不同的回调函数，就可以实现各种不同的功能。 在device-sdk-go中，以restrouter.go举例，在添加路由的时候，设置了如下的回调函数： 12345678c.addReservedRoute(common.ApiDeviceCallbackRoute, c.AddDevice).Methods(http.MethodPost)c.addReservedRoute(common.ApiDeviceCallbackRoute, c.UpdateDevice).Methods(http.MethodPut)c.addReservedRoute(common.ApiDeviceCallbackNameRoute, c.DeleteDevice).Methods(http.MethodDelete)c.addReservedRoute(common.ApiProfileCallbackRoute, c.UpdateProfile).Methods(http.MethodPut)c.addReservedRoute(common.ApiWatcherCallbackRoute, c.AddProvisionWatcher).Methods(http.MethodPost)c.addReservedRoute(common.ApiWatcherCallbackRoute, c.UpdateProvisionWatcher).Methods(http.MethodPut)c.addReservedRoute(common.ApiWatcherCallbackNameRoute, c.DeleteProvisionWatcher).Methods(http.MethodDelete)c.addReservedRoute(common.ApiServiceCallbackRoute, c.UpdateDeviceService).Methods(http.MethodPut) 先进入addReservedRoute()方法 12345678910111213141516171819202122func (c *RestController) addReservedRoute(route string, handler func(http.ResponseWriter, *http.Request)) *mux.Route { c.reservedRoutes[route] = true return c.router.HandleFunc(route, handler)}// HandleFunc registers a new route with a matcher for the URL path.func (r *Router) HandleFunc(path string, f func(http.ResponseWriter, *http.Request)) *Route { return r.NewRoute().Path(path).HandlerFunc(f)}// 设置路由func (r *Route) Path(tpl string) *Route { r.err = r.addRegexpMatcher(tpl, regexpTypePath) return r}// 为路由设置处理程序func (r *Route) HandlerFunc(f func(http.ResponseWriter, *http.Request)) *Route { return r.Handler(http.HandlerFunc(f))} 这个意思就是设置route路径，并且设置了回调函数handler，比如设置的是c.AddDevice，那么回调函数就是AddDevice()方法，如果设置的是c.UpdateDevice，那么回调函数就是UpdateDevice()方法。继续看底层， 123456789type Handler interface { ServeHTTP(ResponseWriter, *Request)}type HandlerFunc func(ResponseWriter, *Request)// ServeHTTP calls f(w, r).func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r)} 由此可以看出Handler是一个接口，ServeHTTP是一个方法，而HandlerFunc通过实现ServeHTTP方法从而实现了Handler接口，它的类型就是外面传入的函数。","link":"/Golang/%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/"},{"title":"接口详解","text":"什么是接口在Go语言中还存在着另外一种类型：接口类型。接口类型是一种抽象的类型。它不会暴露出它所代表的对象的内部值的结构和这个对象支持的基础操作的集合；它们只会展示出它们自己的方法。也就是说当你有看到一个接口类型的值时，你不知道它是什么，唯一知道的就是可以通过它的方法来做什么。 先通过Java程序来举个例子: 12345/* 文件名 : Animal.java */interface Animal { public void eat(); public void travel();} 1234567891011121314151617/* 文件名 : Dog.java */public class Dog implements Animal{ public void eat(){ System.out.println(&quot;Dog eats&quot;); } public void sleep(){ System.out.println(&quot;Dog sleep&quot;); } public static void main(String args[]){ Dog d = new Dog(); d.eat(); d.sleep(); }} 在Java中实现接口的方式是显示的，关键词为implements 但是在Golang中，接口的实现不需要显示声明，只要实现了接口的所有方法，则默认实现了该接口。Golang中声明一个接口类型，可以这么写： 1234type Animal interface { eat() sleep()} Golang interface 的理解因为Go本身并没有类和继承的概念，Go就是借助接口来实现多态，一个类型可以实现多个接口，一个接口也可以被多个类型实现。Go 接口是一组方法的集合，可以理解为抽象的类型。它提供了一种非侵入式的接口。任何类型，只要实现了该接口中方法集，那么就属于这个类型。需要注意的是，虽然接口解除了类型依赖，有助于减少用户的可视方法，屏蔽了内部结构和实现细节，但是接口不能滥用，不能说定义的所有接口，每个都仅仅只有一个实现，那么这大可不必，这样做反而会增加运行时损耗。 简单接口的实现1234567891011121314151617181920212223242526package maintype Animal interface { eat() sleep()}type Dog struct { name string}func (dog *Dog) eat() { println(dog.name + &quot; is eating&quot;)}func (dog *Dog) sleep() { println(dog.name + &quot; is sleeping&quot;)}func main() { var a Animal d := &amp;Dog{name: &quot;qiqi&quot;} //由于Dog实现了Animal接口，所以可以直接赋值 a = d a.eat() //输出 qiqi is eating a.sleep() //输出 qiqi is sleeping}","link":"/Golang/%E6%8E%A5%E5%8F%A3%E8%AF%A6%E8%A7%A3/"},{"title":"Linux踩不完的坑","text":"linux 创建用户123456789101112131415161718192021$ useradd -d /home/jason -g root -m -s /bin/bash jason# 把jason用户添加到sudo和admin用户组里面。这里要注意的是系统里面的admin的用户组的名字是&quot;adm&quot;$ usermod -a -G sudo jason$ usermod -a -G adm jason# 设置用户密码$ passwd jason#将用户移除组#id用来查看用户属性$ id root# uid=0(root) gid=0(root) groups=0(root),1000(gl)$ gpasswd -d root gl# Removing user root from group gl$ id root# uid=0(root) gid=0(root) groups=0(root)# sudo 无需输入密码#在/etc/sudoers中添加如下语句#语句位于root ALL=(ALL:ALL) ALL下面#userName ALL=(ALL:ALL) NOPASSWD:ALL 12345678910111213-c&lt;备注&gt; 加上备注文字。备注文字会保存在passwd的备注栏位中。-d&lt;登入目录&gt; 指定用户登入时的起始目录。-D 变更预设值．-e&lt;有效期限&gt; 指定帐号的有效期限。-f&lt;缓冲天数&gt; 指定在密码过期后多少天即关闭该帐号。-g&lt;群组&gt; 指定用户所属的群组。-G&lt;群组&gt; 指定用户所属的附加群组。-m 自动建立用户的登入目录。-M 不要自动建立用户的登入目录。-n 取消建立以用户名称为名的群组．-r 建立系统帐号。-s&lt;shell&gt; 指定用户登入后所使用的shell。-u&lt;uid&gt; 指定用户ID linux 配置密钥登录 创建密钥对 将公钥放入服务端authorized_keys 1$ cat 公钥.pub &gt; ~/.ssh/authorized_keys 使用xshell选择私钥文件登录 ssh命令行登录方式为 ssh -i 文件位置.pem username@ip","link":"/Linux/linux%E8%B8%A9%E4%B8%8D%E5%AE%8C%E7%9A%84%E5%9D%91/"},{"title":"Java面经（持续更新）","text":"抽象类和接口类的区别 抽象类要被子类继承，接口要被类实现； 抽象类只用做方法声明和实现，而接口只能做方法声明； 抽象类中的变量可以是普通变量，而接口中定义的变量必须是公共的静态常量； 抽象类是重构的结果，接口是设计的结果； 抽象类和接口都是用来抽象具体对象的，但是接口的抽象级别更高； 抽象类可以由具体的方法和属性，接口只能由抽象方法和静态常量。 为什么HashMap线程不安全https://www.zhihu.com/question/28516433 值传递和引用传递(java)以及深拷贝和浅拷贝hashmap的数组长度为什么是2的幂次方https://blog.csdn.net/wohaqiyi/article/details/81161735","link":"/Java/java%E9%9D%A2%E7%BB%8F%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"},{"title":"关于hashcode的理解","text":"关于hashcode的理解 什么是hash ​ hash其实就是一个函数，其中实现了计算hash值的方法，用来得到hash值的算法有许多种，常见的就有:直接取余法，乘法取整法，平方取中法。 位运算符 12345678&lt;&lt; : 左移运算符，num &lt;&lt; 1,相当于num乘以2 低位补0&gt;&gt; : 右移运算符，num &gt;&gt; 1,相当于num除以2 高位补0&gt;&gt;&gt; : 无符号右移，忽略符号位，空位都以0补齐 % : 模运算 取余^ : 位异或 第一个操作数的的第n位于第二个操作数的第n位相反，那么结果的第n为也为1，否则为0 &amp; : 与运算 第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0 | : 或运算 第一个操作数的的第n位于第二个操作数的第n位 只要有一个是1，那么结果的第n为也为1，否则为0 ~ : 非运算 操作数的第n位为1，那么结果的第n位为0，反之，也就是取反运算（一元操作符：只操作一个数） hashCode是否存储的是对象地址 显然不是，这是String类下的hashCode方法 1234567891011121314151617181920212223242526272829303132333435363738public int hashCode() { // The hash or hashIsZero fields are subject to a benign data race, // making it crucial to ensure that any observable result of the // calculation in this method stays correct under any possible read of // these fields. Necessary restrictions to allow this to be correct // without explicit memory fences or similar concurrency primitives is // that we can ever only write to one of these two fields for a given // String instance, and that the computation is idempotent and derived // from immutable state int h = hash; if (h == 0 &amp;&amp; !hashIsZero) { h = isLatin1() ? StringLatin1.hashCode(value) : StringUTF16.hashCode(value); if (h == 0) { hashIsZero = true; } else { hash = h; } } return h;}//StringUTF16.javapublic static int hashCode(byte[] value) { int h = 0; int length = value.length &gt;&gt; 1; for (int i = 0; i &lt; length; i++) { h = 31 * h + getChar(value, i); } return h;}//StringLatin1.javapublic static int hashCode(byte[] value) { int h = 0; for (byte v : value) { h = 31 * h + (v &amp; 0xff); } return h;} 这是Integer类下的hashCode方法，直接返回了value的值 这是Float类下的hashCode方法，返回了浮点数IEEE754的表示形式 12345678910//测试Float f=2.5f;System.out.println(f.hashCode());/*输出1075838976因为是十进制，转化为32位二进制数0 10000000 01000000000000000000000根据IEEE754标准，表示：1.01*2=10.1B=1*2+1*1/2=2+0.5=2.5D*/ 于是可以知道，hashcode一样的两个对象不一定是一样的，但hashcode不一样的两个对象一定是不一样的。当两个不同的对象的hashcode相同时，就发生了冲突，这个时候就需要相应的处理冲突方法。 hashCode方法和equals方法的关系 ​ hashcode在什么时候会大有用处呢？Java中的两个容器类分别为Collection和Map，其中的Map和Set不允许存放重复的元素，为了存取效率，它们的底层实现都会用到散列结构。 ​ 这个时候就会碰到这么一个问题，该如何保证存入的元素不重复，如果使用equals方法，那么就需要依此比较已经存储在map中的所有元素对象，这时候的时间复杂度为O(n)。但有了hashcode在散列表的基础上，一切就要简单许多，在新加入元素的时候，只需要将其哈希值与相应位置进行比较，查看是否已经存在，如果存在则会产生冲突，那么就需要调用equals方法来比较两个对象是否相同，如果相同则覆盖掉原来的元素，如果不同，则需要处理冲突，具体过程可以参考源码，java是用链表的方法解决的。 下面是是hashmap put方法的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*Implements Map.put and related methods.Params:hash – hash for keykey – the keyvalue – the value to putonlyIfAbsent – if true, don't change existing valueevict – if false, the table is in creation mode.Returns:previous value, or null if none*/final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //((n - 1) &amp; hash)确定了要put的元素的位置, 如果要插入的地方为空，就直接插入. if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; //首先判断hash值是否相等，如果不相等，直接跳过，如果相等，会调用equals方法 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { //将新加入的元素插入链表 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash);//判断链表的长度，如果达到一定的值，则需要转化成红黑树 break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } 参考文章：https://www.cnblogs.com/tanshaoshenghao/p/10915055.html https://www.cnblogs.com/skywang12345/p/3324958.html","link":"/Java/%E5%85%B3%E4%BA%8Ehashcode%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"java动态代理","text":"java动态代理实现方式jdk动态代理 cglib动态代理","link":"/Java/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"title":"java反射","text":"","link":"/Java/java%E5%8F%8D%E5%B0%84/"},{"title":"Java核心技术卷一-第五章","text":"getClass()返回运行时类的一个对象 1234567891011121314151617import java.util.GregorianCalendar;public class ObjectDemo { public static void main(String[] args) { // create a new ObjectDemo object GregorianCalendar cal = new GregorianCalendar(); // print current time System.out.println(&quot;&quot; + cal.getTime()); // print the class of cal System.out.println(&quot;&quot; + cal.getClass()); // create a new Integer Integer i = new Integer(5); // print i System.out.println(&quot;&quot; + i); // print the class of i System.out.println(&quot;&quot; + i.getClass()); }} 执行结果： 1234Mon Oct 11 09:30:37 UTC 2021class java.util.GregorianCalendar5class java.lang.Integer ArrayList数组列表管理着对象引用的一个内部数组，可以使用add方法向其中添加新的对象，当内部数组满了的时候，数组列表会自动创建一个更大的数组，并且将所有的对象从较小数组拷贝到较大数组中去。可以调用ensureCapacity(int minCapacity)方法来设置数组中可能或者已经确定要存储的对象数，这样将会给数组列表分配一个指定大小minCapacity的内部数组(只是一个潜力，还可以扩容)，这样在之后调用add方法的时候不需要重新分配空间，因为数组扩容的非常耗费时间和内存。也可以在初始化的时候将初始容量直接传递给构造器，比如ArrayList arrayList =new ArrayList&lt;&gt;(100)，这个方法也可以用来进行扩容。 注意数组列表和数组的区别 123456789101112131415ArrayList&lt;Person&gt; arrayList =new ArrayList&lt;&gt;();arrayList.ensureCapacity(100);/*这个时候只是赋予数组列表存储100个对象的潜力,也就是底层数组的长度这个size和数组的length不同，ArrayList的length就是底层数组长度，但这个长度对用户的意义不大，一般用户所需要的都是当前实际存储的对象数，因此ArrayList中一个私有成员变量size可以通过size()方法获得，它返回了数组列表中实际存储的对象数*/System.out.println(arrayList.size());Person[] people=new Person[100];//这是真的给数组分配了100个元素的存储空间，有100个空位置可以用System.out.println(people.length);/*输出0100*/ 初始化容量对性能的影响 如果用户在构造一个ArrayList的时候没有指定容量大小，那么将会调用ArrayList的无参构造函数，默认容量为10。接下来看ArrayList的无参构造函数： 123456/** * Constructs an empty list with an initial capacity of ten. */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 事实上在构造完成的时候，它的底层数组是空的，并不是10，只有在调用了add方法之后，才会将底层数组扩容到10，看源码： 1234567891011121314151617181920212223 /** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return {@code true} (as specified by {@link Collection#add}) */ public boolean add(E e) { modCount++; add(e, elementData, size); return true; } /** * This helper method split out from add(E) to keep method * bytecode size under 35 (the -XX:MaxInlineSize default value), * which helps when add(E) is called in a C1-compiled loop. */ private void add(E e, Object[] elementData, int s) { if (s == elementData.length) elementData = grow(); elementData[s] = e; size = s + 1; } add方法就是先比较ArrayList的实际大小和底层数组的长度，如果已经相等则需要扩容，调用grow方法，来看grow方法： 这边包括上边的代码有一个需要注意的地方就是size在构造函数中并没有赋值，但其实它有一个初始值为0，虽然在定义成员变量的时候没有给出，但编译器会给它一个初始值，int类型的变量初值为0，但是在方法体内的局部变量如果不赋予初值，则会编译报错。 12345678910111213141516171819202122232425262728private Object[] grow() { return grow(size + 1);}/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity * @throws OutOfMemoryError if minCapacity is less than zero */private Object[] grow(int minCapacity) { //记录当前底层数组的长度 int oldCapacity = elementData.length; //如果底层数组的长度大于0或者是底层数组并不是空数组，那么就执行扩容操作 if (oldCapacity &gt; 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { //将newCapacity设置为minCapacity和1.5*oldCapacity中的最大值 int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, /* minimum growth */ oldCapacity &gt;&gt; 1 /* preferred growth */); //生成了新的数组对象，将原数组中的内容拷贝到新的数组中 return elementData = Arrays.copyOf(elementData, newCapacity); } else { //底层数组长度为小于等于0或者底层数组为空，那么就将底层数组变成一个容量最小为10的空数组（可以看到下图minCapacity=1，也就是初始化之后如果调用add方法，是会将arraylist扩容为10） return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)]; }} 但是如果在初始化的时候给了容量大小，那么会执行有参构造函数，如下，这个时候会生成一个大小为给定容量的数组，将其引用地址赋给elementData，这个时候调用add方法，在实际大小不超过底层数组大小的时候就不需要进行扩容。 1234567891011121314151617/** * Constructs an empty list with the specified initial capacity. * * @param initialCapacity the initial capacity of the list * @throws IllegalArgumentException if the specified initial capacity * is negative */public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); }} 于是现在设想这么一种情况，如果不给的初始容量，并且后面也不调用ensureCapacity方法，那么在实际容量(调用add方法)达到（0-&gt;10-&gt;15-&gt;22-&gt;33-&gt;49-&gt;73）的时候都会进行扩容操作，如果最终的元素个数为100个，那么总计执行了7次扩容（grow）操作，但如果在一开始就给定了初始容量100，将会直接给底层数组将直接变成长度为100的数组，也就相当于只执行了一次扩容操作。并且这两种“扩容“操作的代价并不是一样的，前者的扩容操作在后面的阶段还包括了数据的移动，所以是相当耗费时间和内存的，如果在数据量比较大的情况下，结果就可想而知了。 123456789101112131415161718192021222324252627282930313233 public void ensureCapacity(int minCapacity) { //初始化容量必须大于底层数组的长度并且m底层数组不为空或者初始化容量大于默认容量10 if (minCapacity &gt; elementData.length &amp;&amp; !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA &amp;&amp; minCapacity &lt;= DEFAULT_CAPACITY)) { modCount++; grow(minCapacity); } } /** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity * @throws OutOfMemoryError if minCapacity is less than zero *///真正实现扩容的函数 private Object[] grow(int minCapacity) { //获得当前的实际容量 int oldCapacity = elementData.length; if (oldCapacity &gt; 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { //将newCapacity设置为minCapacity和1.5*oldCapacity中的最大值 int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, /* minimum growth */ oldCapacity &gt;&gt; 1 /* preferred growth */); //生成了新的数组对象，将原数组中的内容拷贝到新的数组中 return elementData = Arrays.copyOf(elementData, newCapacity); } else { //初始化为默认容量 return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)]; } }","link":"/Java/java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8D%B7%E4%B8%80-%E7%AC%AC%E4%BA%94%E7%AB%A0/"},{"title":"一致性哈希的理解","text":"","link":"/Java/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"三色灯控制实现","text":"三色灯场景搭建​ 树莓派3B+以及三色灯 工作流程​ 通过将使用mapperSdk编写gpio的程序运行在树莓派上，用户可以通过restful接口来控制三色灯的状态。（例程只实现了对三种颜色灯的简单控制，开发者可以根据场景需求实现相应的逻辑）。用户可以按设定的时间间隔收到mqtt消息以此来监控三色灯的实时状态。 效果演示 ​ 启动gpio程序 查看mqtt 订阅消息 通过restful接口改变三色灯状态 黄色灯亮 绿色灯亮 红色灯亮","link":"/kubeedge/%E4%B8%89%E8%89%B2%E7%81%AF%E6%8E%A7%E5%88%B6%E5%AE%9E%E7%8E%B0/"},{"title":"kubeedge环境搭建","text":"仅介绍使用keadm进行部署 先决条件云端：需要搭建K8S集群环境，参考K8S搭建EdgeX环境 边端：需要安装docker，参考docker安装 使用 Keadm 进行部署Keadm 用于安装 KubeEdge 的云和边缘组件。它不负责安装 K8s 和运行时。 请参考kubernetes-compatibility以确认Kubernetes 兼容性并确定要安装的 Kubernetes 版本。 局限性 目前支持keadmUbuntu 和 CentOS 操作系统。RaspberryPi 支持正在进行中。 需要超级用户权限（或 root 权限）才能运行。 安装 keadm运行以下命令一键安装keadm。 云端和边端都需要安装 1docker run --rm kubeedge/installation-package:v1.10.0 cat /usr/local/bin/keadm &gt; /usr/local/bin/keadm &amp;&amp; chmod +x /usr/local/bin/keadm cloudcore安装1keadm init --kubeedge-version=1.9.2 --advertise-address=&quot;THE-EXPOSED-IP&quot; --kube-config=/root/.kube/config edgecore安装首先在云端获取token 1keadm gettoken 获取token之后，在边端执行 1keadm join --cloudcore-ipport=&quot;THE-EXPOSED-IP&quot;:10000 --token=27a37ef16159f7d3be8fae95d588b79b3adaaf92727b72659eb89758c66ffda2.eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1OTAyMTYwNzd9.JBj8LLYWXwbbvHKffJBpPd5CyxqapRQYDIXtFZErgYE 云端和边端的kubeedge安装过程都需要访问github，如果待部署环境不能访问github或者速度较慢，可以依靠科学手段从github上下载安装文件至/etc/kubeedge下，下载链接。 故障解决K8S安装tips使用如下命令可以查看创建集群需要的镜像版本 123kubeadm config images list## 可以使用国内镜像仓库拉取 比如阿里云镜像仓库kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.21.3 解决error: system validation failed - Following Cgroup subsystem not mounted: [memory]12345678910111213#上面加入kubeedge集群管理, 报错: Failed to start container manager, err: system validation failed - Following Cgroup subsystem not mounted: [memory]E0125 16:42:09.131414 1655 edged.go:291] initialize module error: system validation failed - Following Cgroup subsystem not mounted: [memory]#解决问题#修改/boot/cmdline.txtsudo vim /boot/cmdline.txt#或者sudo vim /boot/firmware/btcmd.txtcgroup_enable=memory cgroup_memory=1#添加在同一行的最后面,接着内容后空格后添加, 注意:不要换行添加#重启机器配置生效reboot 解决failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: “cgroupfs” is different from docker cgroup driver: “systemd”失败的原因是你的dock 运行时的cgroup driver 和 kubelet 的 cgroup driver 运行方式是不一样的，需要将两者该为一致，此处修改docker： 123/etc/docker/daemon.json#只需要更改如下字段即可&quot;exec-opts&quot;: [&quot;native.cgroupdriver=cgroupfs&quot;] 阿里云ECS error：Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused”. Reconnecting…阿里云ECS安装需要使用私网IP","link":"/kubeedge/kubeedge%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"Anatomy of High-Performance Matrix Multiplication","text":"Anatomy of High-Performance Matrix Multiplication​ 现在我们进行机器学习训练，通常都会使用一些机器学习库，比如TensorFlow这样的库，并且在训练机器学习模型时，通常这些库对性能的提升是数量级的提升。以下以卷积计算为例，去剖析高性能矩阵计算。 123456789101112131415'''Convolve `input` with `kernel` to generate `output` input.shape = [input_channels, input_height, input_width] kernel.shape = [num_filters, input_channels, kernel_height, kernel_width] output.shape = [num_filters, output_height, output_width]'''for filter in 0..num_filters for channel in 0..input_channels for out_h in 0..output_height for out_w in 0..output_width for k_h in 0..kernel_height for k_w in 0..kernel_width output[filter, out_h, out_w] += kernel[filter, channel, k_h, k_w] * input[channel, out_h + k_h, out_w + k_w] ​ ​ 这是一个六层嵌套的for循环，也是通常我们能想到的卷积计算代码，但是它的执行效率非常低。主要原因就是嵌套for循环使得数据访问非常困难，这使得缓存利用率极低，缓存中的数据经常被换入换出。 ​ 在逻辑上我们将矩阵/图像/张量看出是多维数据，而事实上不管你逻辑上几维的数据，都将存储在线性的一维计算机内存中。为此，如何将这些高维数据按照一定的次序展开到内存中非常重要。 ​ 大部分现代dl库使用行主序存储，所以同一行的连续元素将被相邻存储，这也意味在访问内存时，第一维度（行）变化速度最慢。对于四维张量，我们知道有NCHW,NHWC等存储顺序，N代表数量， C代表channel，H代表高度，W代表宽度。比如下图所示，现有N块H×W图像的C通道，那么相同通道图像都是重叠的，同一通道C的所有像素也是重叠的。 ​ 上面描述的只是一个很简单的卷积，但其执行速度已经很慢了，随着步长，填充等参数增加只会变得更加复杂。 ​ 通用矩阵乘（GEMM，General Matrix Multiplication）可以用于实现卷积。将图像块放到一个矩阵中的操作成为im2col，im2col 是计算机视觉领域中将图片的不同通道（channel）转换成矩阵的列（column）的计算过程。Caffe 在计算卷积时，首先用 im2col 将输入的三维数据转换成二维矩阵，使得卷积计算可表示成两个二维矩阵相乘，从而充分利用已经优化好的 GEMM 库来为各个平台加速卷积计算。如下图所示： ​ 这是一个3×3卷积，下面通过im2col，随着卷积过滤器在输入上滑动，将被计算的那部分输入展开成一行大小的向量。在滑动结束后，则会得到特征矩阵(K²C×HW)，将过滤器展开成N×K²C的矩阵，最后卷积的结果就可以表示为两个矩阵相乘的结果。 ​ im2col 计算卷积使用 GEMM 的代价是额外的内存开销，因为不同的图像块之间往往存在一定的重叠，因此im2col会产生一定的内存重复。当卷积核尺寸是 1×1 时，由于不需要重排输入，GEMM 可以直接在原始输入上运行，并且不需要使用额外的内存。 ​ 通过im2col已经将卷积运算转化为了矩阵乘法，现在需要做的就是如何实现矩阵乘运算加速（GEMM）。通常矩阵乘算法描述如下： 1234for i in 0..M: for j in 0..N: for k in 0..K: C[i, j] += A[i, k] * B[k, j] 最内部执行两个浮点运算（乘法和加法），总共执行M×N×K次，因此这个GEMM的FLOPs为2MNK。随着矩阵尺寸的增大，我们可以发现运算性能不断下降。虽然我们研究的是如何使得矩阵计算更快，但首先需要解决当是如何快速获取数据，因为缓存的容量有限，如果矩阵特征尺寸很大，以至于缓存无法容纳矩阵，性能会急剧下降。我们都知道存取速度CPU&gt;Cache&gt;RAM。CPU每次从主存中获取数据时，都会将其相邻的数据加载到缓存中，期望利用局部性原理以提高效率。但是在矩阵运算中，例如A×B的矩阵运算，我们在A上按行遍历，在B上按列遍历，在A上我们很好地利用了局部性，可是在B上会发现（在B尺寸大的情况下）cache总是会miss，因为cache放入的是B中同一行的其他元素，而我们需要的是B的其他行的元素，所以每次放入缓存的都是我们下一次不需要的元素，这就极大地影响了效率。因此需要重新排列循环次序，从i,j,k到i,k,j，即： 1234for i in 0..M: for k in 0..K: for J in 0..N: C[i, j] += A[i, k] * B[k, j] 这是会发现矩阵计算效率得到极大的提升。这时我们会发现一个新的问题，当我们读取A的第一行，循环遍历B的每一列，用于计算结果矩阵的的第一行。当我们读取A的下一列，我们又会循环遍历B的每一列。这样同样数据就会在缓存中不断换入换出。通常我们并不能将整个矩阵都放入缓存，我们可以将原矩阵分解为若干个子矩阵，将矩阵乘法分解子矩阵上的矩阵乘法，就可以避免这样的现象。比如我们需要得到结果矩阵中一个小的m×n块，我们只需要A中的m行和B中的n列。 ​ 此外，我们可以通过矢量化，将标量数据矢量化，通过SIMD(单指令多数据流)实现在相同的时钟周期对多个值执行相同的操作，以此实现运算加速。另外我们可以设计专用硬件单元实现乘加运算，将两条指令合并为一条。并且我们可以通过线程优化实现加速，在多内核的CPU上，每个内核可以同时物理地执行多个指令。一个程序可以把自己分成多个线程，每个线程可以运行在一个单独的内核上。最后，我们可以通过循环展开的方法消除分支以及一些管理归纳变量的代码，以此摊销一些分支开销。","link":"/CS217/anatomy-of-high-performance-matrix-multiplication/"},{"title":"Coarse-Grained Reconfigurable Architectures and Plasticine","text":"Coarse-Grained Reconfigurable Architectures and Plasticine​ 本节课主要介绍了CGRA（粗粒度可重构计算阵列架构）和Plasticine架构。相较于FPGA（现场可编程逻辑门阵列）,它提供可重构阵列的粗粒度设计，可以认为是FPGA Overlay也是FPGA虚拟化的主流技术，可以克服FPGA中的弱重构、功耗高、速度慢等缺点。Plasticine是斯坦福基于CGRA提出的一种体系结构。 ​ 当今时代三种重要的趋势： 大数据，尤其是在机器学习和数据分析领域，这些都极大地增长了计算需求。如下图所示，在2000-2014年，结构性数据呈线性增长，非结构性数据和半结构性数据呈指数型增长。尤其是实时数据挖掘、搜索、分析的发展趋势给计算和存储带来了极大的需求。 摩尔定律，dennard缩放定律以及功耗墙和存储墙。这使得如何有效地使用晶体管，提高能耗比（性能/功耗）成为了设计专用硬件的关键。随着处理器的发展，单核处理器正向着多核不断发展，但是多核遇到了利用率墙的问题，芯片内可全频率工作的核数受到功率的限制，也就是一开始学习的“暗硅”现象。并且专用处理器无法兼得灵活性和效率，专用处理器效率提升的同时也牺牲了灵活性。 算法改变迅速，这使得ASIC的设计成本变得巨大，现在的机器学习算法发展的速度很快，每年的论文产量也是比摩尔定律快，一般硬件的设计周期大约两年，对于缺乏灵活性的硬件可能在它设计完成的时候便已经过时了，所以我们需要灵活性高的硬件。 ​ 一方面，硬件的灵活性是依靠指令集的，但是指令会增加开销，比图取址、译码、寄存器读写等。CPU中40%的数据通路能耗是指令开销，GPU中30%的动态能耗是指令开销。另一方面，可重构硬件也有较高的灵活性，因为它是静态编程没有指令开销，但是可重构的粒度很重要。 ​ 首先是FPGA，其中包含了大量的门级可重构逻辑单元，并且它们是静态互联的，灵活性高，能耗比高，拥有成熟的工具链。但是FPGA的效率并不高，主要原因是因为其中的互连结构，和专用硬件相比，它的面积、延迟和功耗都相对较高。从可编程性方面来看，细粒度架构导致了较长的布局和路由长度，并且对编译器也不友好。而CGRA则克服了FPGA的这些限制，引入了粗粒度架构，减少了互连，并且采用了新的编译技术。 ​ CGRA由计算、内存和互连三部分组成。计算模块由不同能力的ALU构成；内存模块由程序员可控的暂存器、Cache等构成；互连模块由静态可编程的通路或动态路由数据构成。CGRA采用拓扑结构，数据通路层次结构为ALU簇，通信粒度为字级，互连拓扑为网状和环状。编程模型支持软件抽象：线程、VLIW、空间可配置 ALU等，通过编译将高层应用程序映射到CGRA上。 ​ CGRA自上而下进行设计，首先我们需要抽象出软件的关键结构用于硬件加速，主要有数据嵌套和流水线并行以及数据局部性。然后是从软件抽象中获取并行模式，例如具有特殊属性的循环；映射、压缩、过滤、分组等；能够通过编译器优化来进行编译。最后设计一个CGRA来加速并行模式。 ​ 如图是一个点乘的示例，需要将A向量和B向量逐项相乘并相加，左侧是提取的关键计算过程，右侧是CGRA架构实现。 ​ 首先通过变量i将vecA和vecB加载到输入寄存器中，之后通过变量j来控制最内层的reduce，通过并行度为4的乘法运算后规约运算结果存入acc累加和寄存器，最后进行外层的规约运算，输出结果到out寄存器。 ​ 接下来是Plasticine Architecture,一种新的可重构架构，用于加速并行并行模式，相比于Altera的Stratix V FPGA拥有95倍的性能表现，功耗提升了75倍。 ​ Plasticine的关键特点是： 嵌套并行：多级数据通路和灵活的控制机制 局部性、内存库、缓冲：有片上暂存器和可配置的内存库以及地址划分的双缓冲 密集/稀疏 DRAM 访问：专用DRAM地址生成器/scatter-gather模块 标量和矢量通信：多级粒度互连 ​ 相较于之前的CGRA，Plasticine做到了对并行模式，便笺式暂存，分层互连，可编程性的全支持。 ​ Plasticine架构如图所示，主要由地址生成模块、访存合并模块、交换模块、存储模块和计算模块构成。 ​ 如图所示式PCU的架构，流水线式的SIMD架构，输入有标量、向量和控制信号，输出有标量、向量和控制信号。 ​ 如图是PCU的整体架构，五段流水线网络，支持前向传播、反向传播、规约运算以及移位操作。 ​ PMU模块支持片上地址生成、SRAM阵列块、地址交叉和地址划分；switch模块支持三种粒度的通信，包括标量、向量和控制信号，使用流水交换确保吞吐率；地址生成模块通过整数FU生成DRAM访问地址，支持猝发模式访存和地址流访存。访存合并模块主要有仲裁单元（负责仲裁多路地址流请求）和分散收集单元（负责合并cache的稀疏元数据请求维持cache一致性、合并多个请求为一个DRAM突发、允许大量未完成请求）。 ​ 应用映射到Plasticine架构的过程如下：首先通过spatial语言编程，循环展开；然后映射至虚拟PCU，包括资源分配，路由和位流生成；最后得到Plasticine位流。 ​ 参考文献： ​ Plasticine: A reconfigurable architecture for parallel patterns","link":"/CS217/coarse-grained-reconfigurable-architectures-and-plasticine/"},{"title":"Is Dark Silicon Useful","text":"暗硅（Dark Silicon）Is Dark silicon useful? ​ 暗硅的意思就是一个处理器，比如多核处理器，由于功耗的限制，其实同一时刻只有很少的一部分门电路能够工作，其余的大部分处于不工作的状态，这部分不工作的门电路就叫做”暗硅“。 ​ 如下图所示，可以很好地解释暗硅是怎么产生的。 对于一个65nm的4核处理器，假定在额定功率允许的情况下其四个核心能够同时全速工作。当工艺尺寸缩小到32nm的时候，之前4核处理器的面积就可以容纳16个核心。但现实是，这16个核心并不会都工作。能够同时工作的仍然只有四个核心。为什么？假设两代工艺之间缩放因子是S，那么S=65nm/32nm=2，芯片的晶体管数量将乘以$S^2$，即4倍；晶体管的切换频率可以乘以$S$，即2倍，因此总的计算能力将乘以$S^3$，即8倍。由于特征尺寸减小了一半，故晶体管的电容将减小S倍。由于总功耗与晶体管数量和切换频率成正比，和电容成反比，总功耗将变成之前的$S^2$倍，即4倍。为了保持总功耗不变，芯片的利用率只能变为原来的$\\frac{1}{S^2}$，即原来的1/4。所以即使有16个核，仍然只有4个核可以工作。 其中，工艺尺寸缩小分为两种，一种是Dennardian缩小，一种是PostDennardian缩小。两者的区别是Dennardian缩小随着工艺尺寸的缩小，芯片的供电电压等比例缩小。而PostDennardian缩小随着工艺尺寸的缩小，芯片的供电电压保持不变。对于Dennardian缩小，同样的面积能够容纳的晶体管数量增大了$S^2$倍，系统频率也增加$S$倍，而供电电压降低了$S^2$倍，电容也减少了$S$倍，总功耗保持不变。由此摩尔定律可以有$S^3$倍计算能力的提高，而PostDennardian缩小由于其供电电压不变，所以总功耗增大了$S^2$倍，为了保持总功耗不变，芯片利用率只能变为原来的$\\frac{1}{S^2}$，即原来的1/4，所以摩尔定律只能有$S$倍计算能力的提高。总结上述的情况，暗硅产生的原因就是随着现在芯片尺寸的不断减小，芯片的供电电压不能随着一起降低，为了保持总功耗不变，现在工业界常采用面积来换取能量效率，出现了多核芯片，但芯片中能同时满频率工作的面积依然越来越小，由此产生的暗硅。 ​ 文中指出了暗硅四骑手： （1）THE SHRINKING HORSEMAN 主要思想就是因为面积昂贵，所以希望制造更小的芯片而移除掉暗硅的部分。这是一个很乐观的结果，但前景并不被人看好。原因有：暗硅并不表示它没有用或者不会被用到，它只是不会在任何时候都工作，比如如x86处理器中的SIMD SSE单元；从经济学上考虑，硅片成本其实只占芯片成本很小的一部分，封装测试，营销销售，支持维护等其他费用才是大头；商家并不愿意为了减少芯片面积而去牺牲性能；功率密度提高带来的芯片散热问题。 （2）THE DIM HORSEMAN 主要思想是用”弱硅“来替代”暗硅“，就是使用仅在一部分时间内使用的逻辑来填充暗硅区域。其中的技术有： 近阈值电压（NTV）处理器：单个处理器性能下降比节省的能耗更多，但多个处理器并行可以弥补性能损失。任务并行量越大，收益越高。问题在于NTV技术下随机掺杂波动（RDF）导致晶体管阈值电压变化、工作频率变化，鲁棒性下降（如SIMD），以及大量低速处理器和SRAM间互连会增大功耗。 更大的Cache（缓存）：即将暗硅区域用于高速缓存即可以提升性能有节省能耗。但随着低功耗片外接口和3D集成存储器的出现，片上高速缓存的优势在下降。 粗粒度可重配置阵列（CGRA）：拥有针对字级操作的优化路径，比FPGA的长线路能耗更低。 计算冲刺和自动超频：临时升温但保持在温度极限以此提高性能；使用相变材料使得芯片在亚秒级的时间内可以超过温度限制。 （3）THE SPECIALIZED HORSEMAN 相对于功耗和能耗，硅面积已经成为更廉价的资源，用面积来购买能源效率，在暗硅上实现一系列的专用协处理器，这些专业协处理器/加速器可以提高能源效率和性能的数量级，尤其对于高并行计算。但是软硬件之间协调、兼容困难，且因标准更改而被淘汰。由此需要指定可扩展的硬件标准，满足低功耗高性能的要求，同时降低软硬件设计的复杂度；克服Amdahl定律的限制：对规则并行代码和非规则代码都进行专用化方法。 （4）THE DEUS EX MACHINA HORSEMAN 使用新的半导体器件：基于隧道效应的隧道场效应晶体管（TFETS），以及基于纳米机电开关（（Nano-Electro-Mechanical switch）），它们基于物理交换机。","link":"/CS217/is-dark-silicon-useful/"},{"title":"硬件加速器背景介绍（Lecture1）","text":"硬件加速器背景​ 如今计算能力限制了训练机器学习模型的工作，如果我们有更快的处理器我们可以运行更大的模型。 现有的机器学习加速器 CPU：线程、SIMD（单指令多数据流） GPU：大量线程、SIMD、HBM（高带宽存储器） FPGA：LUTs（查找表）、DSP、BRAM TPU：MM Unit、BRAM 关键问题 如何提高机器学习速度？ （1）摩尔定律减缓和能量墙 （2）提高性能/瓦数 （3）应用新的机器学习程序和能力 （4）使得机器学习易于使用 如何平衡性能和可编程性？ 比如ASIC(专用集成电路)的能效比和处理器一样的灵活性 需要全栈协同设计（机器学习算法、编译器、硬件） Scaling 技术登纳德系数（Dennard’s Factor）：$$\\alpha=a/b$$ 为两代特征尺寸之比。 耗散功率：$$Power Dissipation\\approx CV^2f=\\alpha^2(C/\\alpha(V/\\alpha)^2\\alpha f)$$其中$V$为供电电压，$f$为时钟频率。提升α可得到更多晶体管（ $\\alpha^2 $ ），更高性能（ $\\alpha f$ ）。 随着晶体管尺度缩小到达极限，供电电压V和时钟频率F无法继续等比缩小，$CV^2f=\\alpha^2(C/\\alpha V^2\\alpha f)=\\alpha CV^2f$， 造成耗散功率增加。","link":"/CS217/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E5%99%A8%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D%EF%BC%88lecture1%EF%BC%89/"},{"title":"机器学习背景介绍（Lecture2）","text":"机器学习简介​ 本节主要学习一些机器学习算法，部分算法研究在《智能计算系统》的学习中有所接触，还学习机器学习相关技术和常见的计算模式，从而帮助加速器设计人员高效地将这些模式应用于硬件。 机器学习算法 回归 求函数$f$使得对$\\forall(x,y)\\in(X,Y),f(x)\\backsimeq y$。 线性回归 求$w,b$使得$\\forall(x,y)\\in(X,Y),f(x)= wx+b\\backsimeq y$。通过最小化损失函数得到$w,b$。 损失函数：$$J（w,b）=\\frac{1}{2}\\sum_{i=1}^{m}(f(x^{(i)})-y^{(i)})^2$$ 逻辑回归 用于分类问题，将线性回归的结果通过激活函数比如sigmoid函数$\\sigma$:$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$即求$w,b$使得$\\forall(x,y)\\in(X,Y),f(x)= \\sigma(wx+b)\\backsimeq y$ 损失函数：$$J（w,b）=-\\sum_{i=1}^{m}(y^{(i)}\\lg(\\hat{y}^{(i)})+(1-y^{(i)})\\lg(1-\\hat{y}^{(i)}))$$ 支持向量机 找到一个超平面，以“最佳间隔”分隔数据。即：$$\\hat{y}=g(wx+b)=+1,wx+b\\geq0;-1,wx+b\\leq0$$使边距最大化问题转化为优化问题：最大化$\\frac{1}{\\Vert w\\Vert}$，也就是最小化$\\frac{1}{2}\\Vert w\\Vert^2$使得$\\forall i\\in[1,m],y^{(i)}(wx^{(i)}+b)\\geq1$,利用拉格朗日对偶得到最小化函数：$$J(w,b)=\\sum_{i=1}^{m}max(0,1-y^{(i)}(wx^{(i)}+b))+R(w)$$ 核技巧 当数据不是线性可分时，将其映射到更高的维度，然后找到一个超平面将其线性分离。 全连接网络 推断过程只需使用前向传播，训练过程需要同时使用前向传播和反向传播。反向传播代价很大因为涉及梯度计算。 机器学习常用模式 都是优化问题 都会存在一个需要最小化的损失函数 都可以使用梯度下降之类的迭代算法解决最优化问题 不是所有的机器学习算法都需要表示为优化问题，比如K-近邻算法。 在推理和训练期间主要涉及的计算：算术运算（向量乘法、加法运算）和激活函数（ReLu、sigmoid 等）计算。以及训练时额外需要在迭代中计算梯度。","link":"/CS217/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D%EF%BC%88lecture2%EF%BC%89/"},{"title":"Roofline and TPU Performance","text":"Roofline and TPU Performance​ 任何模型都必须依赖具体的计算平台才能展示出自己真正的实力。从前，许多的性能模型和模拟器都是通过追踪延迟来预测性能，近二十年也诞生了一些隐藏延迟的技术，例如：乱序执行（硬件发现并行性以隐藏延迟）；硬件流预取（硬件推测加载数据）；大规模线程并行。这些技术有效地隐藏了延迟，但同时也使得计算平台从延迟受限转变为了吞吐量受限。 ​ Roofline模型是一个吞吐量指向的性能模型，它追踪速度而不是时间。也可以这么说说Roof-line Model就是：模型在一个计算平台的限制下，到底能达到多快的浮点计算速度。通俗来讲是”计算量为A且访存量为B的模型在算力为C且带宽为D的计算平台所能达到的理论性能上限E是多少“这个问题。Roofline模型有两个关键部分：一个是机器参数，第二个是应用的理论编辑。 ​ 首先介绍计算平台的两个指标：算力$\\pi$和带宽$\\beta$ 算力$\\pi$：计算平台的性能上限，即一个计算平台每秒钟所能完成的浮点运算数的极限。单位是 FLOP/s。 带宽$\\beta$：计算平台的带宽上限，即一个计算平台每秒钟所能完成的内存交换量的极限。单位是 Byte/s。 计算强度上限$I_{max}$：即单位内存交换最多可进行多少次浮点预算，单位为 FLOPs/Byte。$$I{max}=\\frac{\\pi}{\\beta}$$其次介绍模型的两个指标：计算量与访存量 计算量：指的是输入单个样本，模型进行一次完整的前向传播需要的浮点运算数，也即模型的时间复杂度。单位是 FLOPs。 访存量：指的是输入单个样本，模型完成一次前向传播过程中所产生的内存交换总量，也即模型的空间复杂度。在理想情况下（即不考虑片上缓存），模型的访存量就是模型各层权重参数的内存占用（Kernel Mem）与每层所输出的特征图的内存占用（Output Mem）之和。单位是Byte。 模型的计算强度$I$：计算量除以访存量即模型的计算强度，它表示此模型在计算过程中，每Byte内存交换用于进行多少次浮点运算。单位是FLOPs/Byte。易知模型的计算强度越大，其内存使用效率越高。 模型的理论性能 $P$：即模型在计算平台上所能达到的每秒浮点运算次数（理论值）。单位是 FLOPS 。 ​ Roofline模型在DRAM上如下图所示： 机器算力决定“屋顶”的高度，峰值性能。 访存带宽决定“房檐”的斜率，DRAM的访问速度。 x轴表示计算强度，y轴表示可达到的计算性能。 绿色虚线和紫色实线包裹的三角形区域是应用是带宽受限的，如图所示，Kernel 1： 当模型的计算强度$I$小于计算平台的计算强度上限$I_{max}$时，此时模型位于“房檐”区间，模型理论性能$P$完全由计算平台的访存带宽上限$\\beta$（即“房檐”的斜率）以及模型自身的计算强度$I$决定，模型处于memory-bound状态。可见，在模型处于带宽瓶颈区间的前提下，计算平台的带宽$\\beta$越大（房檐越陡），或者模型的计算强度$I$越大，模型的理论性能$P$呈线性增长。 绿色虚线右侧区域是应用是计算受限的，如图Kernel 2。 不管模型的计算强度$I$有多大，它的理论性能$P$最大只能达到计算平台的算力$\\pi$。当模型的计算强度$I$大于计算平台的计算强度上限 $I_{max}$时，模型在当前计算平台处于compute-bound状态，即模型的理论性能$P$受到计算平台算力$\\pi$的限制，无法与计算强度$I$成正比。但这意味着此时模型100%利用了计算平台的全部算力。可见，计算平台的算力$\\pi$越高，模型进入计算受限区域后的理论性能$P$也就越大。 Roofline 根据内核的操作强度设置内核性能的上限。 如果我们将操作强度看作是一根撞到屋顶的柱子，它要么撞到屋顶的平坦部分，这意味着性能受计算限制，要么撞到屋顶的倾斜部分，这意味着性能最终受内存限制。更多时候我们无法达到理论性能峰值，因为局部性（数据复用）和访存带宽会限制性能。 示例1： 一般机器的计算强度在5-10flops/byte的范围。图中示例程序需要读x[i]和y[i]，写z[i]，每次循环需要2个浮点操作，需要24个字节内存访问，则AI（Arithmetic Intensity，计算强度）=2/24=0.083，故处于访存受限。 示例2： 图中示例程序需要7次浮点操作，需要8次浮点访问（7次读，1次存），则AI=7/64=0.11，使用Cache可以将程序变为1次读1次写，故AI=7/16=0.44，故处于访存受限。 ​ 下图是不同产品Roofline模型的比较，图 1a 是具有两个内核的 Opteron X2的Roofline模型，将其与其后代产品Opteron X4进行比较，设定他们具有相同的内存系统，Opteron X4具有四个内核，并且X4的每个内核的峰值浮点性能也翻了一番，X4内核每个时钟周期可以发出两条浮点SSE2指令，而X2内核可以每隔一个时钟周期发出两条SSE2指令，由于X4时钟频率稍快，X2为2.2GHz，而X4为2.3GHz，所以X4 的峰值浮点性能是X2的四倍多，具有相同的内存带宽。如图1b所示，脊点从Opteron X2的1.0向右移动到了Opteron X4的4.4。因此，要在X4中获得基于X2的性能提升，内核需要有高于1的计算强度或者或者工作集能匹配X4的2M大小的L3Cache。 ​ 由于处理器一般都包含了多级存储：寄存器、L1,L2,L3级cache、HBM或者MCDRAM（设备内存）、DDR和NVRAM。所以应用在每一个层级都有局部性，每一个层级都有独立的带宽，每一层级的数据搬移都有独立的计算强度。因此如下图所示，图中叠加了L2、MCDRAM和DDR的Roofline模型，性能是受最小层约束的。 ​ 获得理论性能峰值的前提有如下几点： 使用特殊指令（如融合MAC） 矢量化/SIMD 循环展开、乱序执行 多核执行 没有这些实现，理论峰值是无法达到的。所以在优化性能时，可以: 所以优化性能时，可以： 增加线程并行度 优化浮点性能，如增加超标量指令并行；使用SIMD指令；循环展开，软件流水线 优化内存使用，如软件预取，内存关联（NUMA，避免非本地数据访问） 优化“屋顶” 内核的操作强度决定了优化区域，从而决定了要尝试哪些优化，如下图所示： 例如，内核2位于右侧的蓝色梯形中，这表明只需要进行计算优化。 如果内核落在左下角的黄色三角形中，模型会建议仅尝试内存优化。 内核1位于中间的绿色平行四边形，模型会建议尝试两种类型的优化。需要注意的是，内核1垂直线低于浮点不平衡优化，因此可以跳过优化2。 ​ 下面介绍TPU，TPU架构如下图所示，矩阵单元是最重要的计算部件，使用了256x256个8位的乘加单元，用脉动阵列实现。 ​ 文中将不同神经网络模型在TPU,GPU,CPU中各自Roofline模型的位置作了描述，如下图所示。 可以看到，大部分模型在TPU中基本都是访存受限，并且绝大部分都逼近理论峰值，而CPU和GPU大部分都是计算受限，并且都无法靠近理论峰值，可见，TPU比GPU和CPU更加适合神经网络。 参考文献： “Roofline: An Insightful Visual Performance Model for Floating-Point Programs and Multicore Architectures” “In-Datacenter Performance Analysis of a Tensor Processing Unit TM”","link":"/CS217/roofline-and-tpu-performance/"},{"title":"Why Systolic Architectures?","text":"Why Systolic Architectures?为什么要设计脉动阵列这样的架构？ Simple and regular design（简单和规则的设计） ​ 首先就是成本效益一直是专用系统的关注点，由于一个专用系统的功能往往十分有限，所以就需要它的成本足够低来弥补这一劣势。而其成本又被分为设计成本和器件成本。由于集成电路技术的进步，器件成本正在迅速下降，所以关键因素还是设计成本。所以采用脉动阵列这个简单又规则的硬件架构，可以很快地完成芯片的设计和实现。 Concurrency and communication（并发和通信） ​ 基本上有两种方法可以构建一个快速的计算机系统。一种是使用快速器件，另一种是使用并发。随着器件速度增长放缓，现在计算系统速度的提高大都来自并发使用。在高并发的过程中，协调和通信也变得尤为重要。 Balancing computation with I/O（平衡计算和I/O） ​ 如图所示，图的上半部分是传统计算系统的模型，一个处理单元需要从存储器里读取数据，处理后再写回到存储器。而数据的存取速度往往大幅度低于数据处理的速度，这也就导致了整个计算系统的速度受限于存取（I/O）速度。所以脉动架构的思想就是希望如何将这来着不易的数据更加有用起来，实际上就是重复使用数据。如图的下半部分所示，第一个数据读出后首先进入第一个处理单元（PE），处理后传入下一个单元，同时第二个数据读出进入第一个处理单元，以此类推，这样数据就可以在处理单元在多流动一会，这样就可以在较小的内存带宽下实现高计算吞吐量。 ​ 当然，脉动架构还有很多其他的优势，比如模块化易于扩展，简单和规则的数据和控制流，使用简单和规则的单元，消除了全局广播、扇入和（可能）快速响应时间。 ​ ​ 不难看出，脉动阵列结构设计简单，成本低，但灵活性较差，所以只适合于特定运算。作者用了大量的篇幅介绍了脉动阵列实现卷积运算的方法。首先作者给出了卷积运算的定义，如下图所示：![image-20210605134721337](D:\\Typora笔记文件夹\\斯坦福CS217\\the convolution computation.png) 下面作者给出了使用脉动阵列实现卷积运算的几种方法，以下只介绍一种（xi’s are broadcast, wi’s stay, and yi’s move systolically）： X值广播到各个PE，W值预先存放在PE中并且保持不变，而部分结果Y通过脉动的方式在阵列间向右传递。具体过程就是： 显然，在第三个时刻就能得到卷积运算的第一个结果，此后依然会不断输出Y的值。文中还给出了其他实现卷积的方式，如broadcast inputs, move weights, results stay；fan-in results, move inputs, weights stay。这几种都属于“(Semi-) systolic convolution arrays with global data communication”。另外还有一大类是“(Pure-) systolic convolution arrays without global data communication”，包括results stay, inputs and weights move in opposite directions；results stay, inputs and weights move in the same direction but at different speeds；weights stay, inputs and results move in opposite direction；weights stay, inputs and results move in the same direction but at different speeds。 ​ 接下来介绍脉动阵列如何实现矩阵乘法，主要有两种做法。一种方法就是在脉动阵列中流动的是X值和W值，结果Y保存在每个PE中，如图所示。 ​ 在Harvey Mudd College Spring 2001 CS156中，讲解了如何从另一个角度（将相乘的矩阵的行和列看作两条相互滑过的条带）更改的理解脉动阵列实现矩阵乘法。另一种方法就是在脉动阵列中流动的数据是X值和Y值的中间结果，W值存储在每个PE中，以下不作阐述。需要注意的就是数据进入脉动阵列时需要调整好一定的顺序才能得到准确的矩阵运算结果。 ​ 总结起来，脉动架构有如下一些特征：（1）阵列由多个同构的PE构成，可以是一维或二维，串行、阵列或树的结构；（2） PE功能相对简单，系统通过实现大量PE并行来提高运算的效率；（3） PE只能向相邻的PE发送数据（在一些二维结构中，可以向对角线发送数据），数据采用流水线的方式向“下游”流动，直到流出最后的PE。","link":"/CS217/why-systolic-architectures/"},{"title":"《智能计算系统》第一章","text":"第一章 概述1.1 人工智能1.1.1 什么是人工智能人制造出来的机器表现出来的智能,就是人工智能。 人工智能大致分为两类：弱人工智能和强人工智能。 弱人工智能是能够完成某种特定任务的人工智能，而强人工智能是具备与人类同等智慧，或超越人类的人工智能，能表现出正常人所具有的所有智能行为。 1.1.2 人工智能的发展史1943年W.McCulloch和W.Pitts提出首个人工神经元模型； 1949年D.Hebb提出了Hebbian Learning 规则； 1956年的达特茅斯会议，人工智能概念正式诞生； 1957年，F.Rosenblatt提出了感知机模型； 1986年，反向传播算法提出； 1991年，五代机计划失败，AI算法复杂度高，进展缓慢，进入第二次寒冬； 2006年，Hinton提出深度学习； 2012年，A.Krizhevsky提出AlexNet网络，AI开启爆发式增长； 2016年，AlphaGo战胜人类选手； 2019年，AlphaStar在星际争霸中战胜人类选手； 1.1.3 人工智能的主要方法 行为主义 符号主义：用一种逻辑把所有的知识都表示出来。 连接主义：借鉴大脑中神经元细胞连接的计算模型，用人工神经网络来拟合智能行为。 1.2 智能计算系统1.2.1 什么是智能计算系统智能计算系统是智能的物质载体。现阶段的智能系统，硬件上通常采用通用CPU和智能芯片的异构系统，软件上通常包括一套面向开发者的智能计算编程环境（包括编程语言和编程框架）。 为什么采用异构系统？ 因为近些年来通用CPU的计算能力增长近乎缓慢，而智能计算能力的需求在不断以指数增长，并且CPU的计算能力较弱，所以智能计算系统需要继承智能芯片来获得强大的计算能力。 1.2.2 智能计算系统的发展1.2.2.1 第一代智能计算系统计算机分为五代，其中前四代为真空管计算机、晶体管计算机、集成电路计算机、超大规模集成电路计算机，而第五代计算机时人工智能计算机。 例如：Prolog机和LISP机 1.2.2.2 第二代智能计算系统面向连接主义（深度学习）处理的计算机或处理器。（课程主要内容） 1.2.2.3 第三代智能计算系统具有近乎无限的计算能力，不再是智能算法的加速工具，将是通用人工智能（强人工智能）发育的沙盒虚拟世界。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0/"},{"title":"《智能计算系统》第二章","text":"第2章 神经网络基础引：神经网络是一种机器学习算法 2.1 从机器学习到神经网络2.1.1 基本概念​ 人工智能、机器学习、神经网络、深度学习之间的关系： 机器学习：计算机通过不断地从经验或数据中学习来逐步提升智能处理能力。 典型的机器学习过程 常用符号说明： 定义 符号 输入数据 x 真实值 y 预测值 $\\hat{y}$ 模型函数 H(X) 激活函数 G(X) 损失函数 L(X) 标量 a、b、c 向量 a、b、c 矩阵 A、B、C 2.1.2 线性回归​ 线性回归是一种最简单的机器学习方法，线性回归不属于神经网络。 一元线性回归模型 $H_w(x_1)=w_0+w_1x_1$ 二元线性回归模型 $H_w(x_1,x_2)=w_0+w_1x_1+w_2x_2$ 多元线性回归模型 $H_w(x)=\\sum_{i=0}^{n}w_ix_i=\\hat{w}^Tx,x_0=1$ 方法：迭代法（梯度下降法）寻找参数 初始先给定一个$\\hat{w}$,如0向量或者随机向量，让其沿着梯度下降的方向进行迭代，使得更新后的损失函数$L(\\hat{w})$不断变小 $\\hat{w}=\\hat{w}-\\alpha\\frac{\\partial L(\\hat{w})}{\\partial{\\hat{w}}}$,其中$\\alpha$称为学习率或者步长 迭代至找到使得$L(\\hat{w})$最小的$\\hat{w}$停止，从而得到回归模型参数 2.1.3 感知机（Perceptron）模型​ 一个最简单的神经网络，可以完成简单的线性分类任务，感知机模型的训练目的是要找到一个超平面S($w^T+b=0$)，将线性可分的数据集T中的所有样本点正确地划分为两类。其中超平面是N维线性空间中维度为N-1的子空间，例如二维空间的超平面就是一条直线，三维空间的超平面就是一个二维平面。 2.1.4 多层感知机​ 多层感知机（Multi-Layer Perceptron，MLP），由一组输入、一个隐层和一个输出层组成。只有一个隐层的多层感知机是最经典的浅层神经网络。浅层神经网络的问题是结构太简单，对复杂函数的表示能力非常有限，虽然有理论可以证明只有一个隐层的神经网络足以拟合出任意的函数，但是只有一个隐层的神经网络拟合出的函数可能会有很大的误差并且每一层需要的神经元数量可能非常多。 2.1.5 深度学习（深层神经网络）​ 深层神经网络的隐层可以超过一层，现在的神经网络已经拥有上百层甚至上千层。深度学习的工作原理是通过对信息的多层抽取和加工来完成复杂的功能，其之所以能够成熟壮大得益于ABC三方面的影响：A是Algorithm（算法）,B是Big data（大数据）,C是Computing（算力）。 2.2 神经网络训练​ 神经网络训练是通过调整隐层和输出层的参数，使得神经网络计算出来的结果$\\hat{y}$与真实结果$y$尽量接近。神经网络的训练主要包括正向传播和反向传播两个过程。 2.2.1 正向传播​ 正向传播的基本原理是，基于训练好的神经网络模型，输入目标通过权重、偏置和激活函数计算出隐层，隐层通过下一层的权重、偏置和激活函数计算出下一个隐层，通过逐层迭代，将输入的特征向量从低级特征逐步提取为抽象特征，最终输入目标结果。 2.2.2 反向传播​ 反向传播的基本原理是，首先根据正向传播的结果和真实结果计算出损失函数$L(W)$，然后采用梯度下降法，通过链式求导法则计算出损失函数对每个权重和偏置的偏导，即权重或偏置对损失的影响，最后更新权重和偏置。总而言之，反向传播就是要将神经网络的输出误差，一级一级地传播到神经网络的输入，在这个过程中需要计算每一个参数$w$对总的损失函数的影响，即损失函数对每个$w$的偏导，通过不断迭代更新$w$的值，从而缩小输出值与真实值之间的误差。 2.3 神经网络设计原则2.3.1 网络的拓扑结构​ 神经网络的结构包括输入、隐层和输出层。通常情况下，当给定训练样本以后，输入层和输出层的结点个数就已经确定了，但是隐层的层数以及隐层神经元的个数是可以动态调整的。神经网络中的隐层是用来提取输入特征中的隐藏规律的，隐层的结点个数对信息的提取能力影响很大，结点个数少了则神经网络提取特征信息的能力会很差，结点多了，就会出现过拟合的现象，导致神经网络泛化能力变差。因此在实践中需要反复调节隐层神经元的个数以及隐层的数量。 2.3.2 激活函数​ 如果没有激活函数，神经元网络将无法解决非线性可分问题，因此激活函数对神经网络的影响很大，常见的激活函数有sigmoid函数、tanh函数、ReLU函数、PReLU/Leaky ReLU函数、ELU函数等。 2.3.2.1 sigmoid函数​ sigmoid函数也称S型生长曲线，可以将变量映射到0到1之间，其数学表达式为：$\\sigma(x)=\\frac{1}{1+e^{-x}}$ ​ 优点：平滑，易于求导。​ 缺点：输出的均值不是0，会导致下一层输入的均值产生偏移，可能会影响神经网络的收敛性；激活函数含有指数运算，计算量大，并且反向传播求误差梯度时，求导涉及除法；反向传播时，在趋向无穷的地方，函数值变化很小，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练。 2.3.2.2 tanh函数​ tanh函数的数学定义为：$$tanh(x)=\\frac{sinh(x)}{cosh(x)}=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}=2\\sigma(2x)-1$$​ tanh函数解决了sigmoid输出均值不为0的问题，其图像是中心对称的，但依然没有解决梯度消失的问题。 2.3.2.3 ReLU函数​ ReLU（Rectified Linear Unit，修正线性单元）函数首次应用于受限玻尔兹曼机。当输入是负数时，ReLU函数的输出为0；否则输出等于输入。其形式化定义为：$$f(x)=max(0,x)$$​ 优点：ReLU计算简单，没有上述两种函数中的指数运算，可以用一条计算机实现，并且，当x&gt;0时，ReLU函数可以保持梯度不衰减，从而缓解梯度消失的问题。 ​ 缺点：输出的均值不是0；对于某些训练样本，在训练的过程中会出现ReLU死掉的现象。在反向传播的过程中，如果学习率过大，可能会导致更新之后的偏置和权重是负数，进而导致下一轮正向传播的过程中ReLU的输入是负数，输出为0，在后续反向传播迭代的过程中，该处的梯度将会一直为0，相关参数的值也不会再改变，输出始终为0，出现ReLU死掉的现象；输出的范围是无限的，可能会导致神经网络的输出的幅值随着网络层数的增加而不断变大。 2.3.2.4 PReLU/Leaky ReLU函数​ PReLU/Leaky ReLU函数解决当x&lt;0时ReLU函数死掉的问题，Leaky ReLU函数的形式化定义为：$$f(x)=max(\\alpha x,x)$$​ 其中参数$\\alpha$是一个很小的常量，PReLU函数与Leaky ReLU函数类似，唯一的区别就是$\\alpha$是可变参数。 2.3.2.5 ELU函数​ ELU（Exponential Linear Unit，指数线性单元）函数结合了sigmoid和ReLU函数，其定义为：$$f(x)=\\begin{cases} x &amp; {x&gt;0}\\ \\alpha(e^{x}-1)&amp;x\\leqslant0 \\end{cases}$$​ 其中$\\alpha$为可调参数，ELU的输出均值接近0，加快了收敛速度，并且解决了梯度消失以及神经元死掉的问题，不足之处就是ELU函数涉及指数运算，计算复杂度比较高。 2.3.3 损失函数2.3.3.1 均方差损失函数​$$J(\\theta) = \\frac{1}{2m}\\sum_{i=0}^m(y^i - h_\\theta(x^i))^2$$​ 损失函数对各个参数$\\theta$的梯度：$$\\frac{\\partial J(\\theta)}{\\partial\\theta_j} = -\\frac1m\\sum_{i=0}^m(y^i - h_\\theta(x^i))x^i_j$$ 2.3.3.2 交叉熵损失函数​ 由于均方差损失函数和sigmoid函数的组合会出现梯度消失的现象，采用交叉熵损失函数与sigmoid函数组合可以避免这一现象。交叉熵损失函数的定义为：$$L=-\\frac{1}{m}\\sum_{x\\in D}\\sum_iy_i\\ln(\\hat{y_i})$$其中，m为训练集D中样本的总数量，i为分类类别。对于单标记分类问题，交叉熵可以简化为$L=-\\frac{1}{m}\\sum\\limits_{x\\in D}y_i\\ln(\\hat{y_i})$；对于多标记分类问题，可以转化为二分类问题，使用sigmoid激活函数时的交叉熵损失函数为$$L=-\\frac{1}{m}\\sum_{x\\in D}(y\\ln(\\hat{y})+(1-y)\\ln(1-\\hat{y}))$$ 2.4 过拟合与正则化2.4.1 过拟合​ 神经网络在学习的过程中，会出现在训练集中精度很高，在测试集中精度很差的情况，通常需要考虑神经网络是不是过拟合了，尤其是神经网络层数多、参数多时，此时神经网络泛化的能力比较差，可以使用许多不同形式的正则化方法，包括参数范数惩罚、稀疏化、Bagging集成、Dropout、提前终止、多任务学习、数据集增强、参数共享等。 2.4.2 正则化2.4.2.1 参数范数惩罚​ 在损失函数中增加对高次项的惩罚，可以避免过拟合，正则化就是在损失函数中对不想要的部分加入惩罚项：$$\\widetilde L(w;x,y)=L(w;x,y)+\\theta\\sum_{j=1}^kw_j^2$$其中$\\theta$为正则化参数，对于神经网络来说，模型参数包括权重$\\omega$和偏置值b，正则化过程一般对权重$\\omega$进行惩罚，记$\\Omega(\\omega)$为正则化项，目标函数记为：$$\\widetilde L(w;x,y)=L(w;x,y)+\\theta\\Omega(w)$$（1）$L^2$正则化 ​ $L^2$正则化后的目标函数：$$\\widetilde L(w;x,y)=L(w;x,y)+\\frac{\\theta}{2}|w|^2$$（2）$L^1$正则化 ​ $L^1$正则化后的目标函数：$$\\widetilde L(w;x,y)=L(w;x,y)+\\theta|w|_1,|w|_1=\\sum_i|w_i|$$ 2.4.2.2 稀疏化​ 由于GPU的性能的提高已经逐步地在逼近物理极限，未来可能计算能力无法满足需求，采用稀疏化训练时可以人神经网络中的90%权重或神经元为0，从而大幅度降低在正向传播中的计算量。 2.4.2.3 Bagging集成学习​ 通过训练不同的模型来共同决策测试样例的输出。 2.4.2.4 Dropout​ 在训练时随机删掉一些隐层的节点，在计算的时候忽略掉这些连接，从而降低神经网络的复杂度，避免过拟合。 2.5 交叉验证​ 交叉验证（cross-validation）是一种好的衡量机器学习模型的统计分析方法，可以有效避免划分训练集和测试集时的随机性对评价结果造成的影响。常用的有留一法交叉验证和K-折叠交叉验证。把原始数据集平均分为K组不重复的子集，每次选 K-1组子集作为训练集，剩下的一组子集作为验证集。这样可以进行K次试验并得到K个 模型，将这K个模型在各自验证集上的错误率的平均作为分类器的评价。相比留一法，其计算量更低，耗时更短。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0/"},{"title":"《智能计算系统》第三章","text":"第三章 深度学习3.1 卷积神经网络​ 在做图像处理时，如果采用全连接前馈神经网络来识别，会出现权重参数过多的现象，随着隐层神经元数量的增多，参数的规模也会急剧增加，从而导致整个神经网络训练效率非常低，也很容易出现过拟合。 ​ 而采用卷积神经网络可以很好地解决上述问题，卷积神经网络是一种具有局部连接、权重共享等特性的深层前馈神经网络。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性，从而使得卷积神经网络的参数更少。 3.1.1 卷积神经网络的组成​ 卷积神经网络一般由卷积层、池化层和全连接层组成，最后还会用softmax函数进行分类概率的凸显、抑制以及归一化。 3.1.2 卷积层​ 卷积层的作用是提取一个局部的特征，不同的卷积核相当于不同的特征提取器。浅层神经网络采用全连接方式，计算一个输出需要用到所有输入，而卷积神经网络计算卷积层的一个输出只需要用到$K_r\\times K_c$个输入，即卷积核的大小。此外，浅层神经网络中所有神经元的连接都采用不同的权重，因此一个$N_i$输入、$N_o$输出的全连接权重数为$N_i\\times N_o$个，而卷积神经网络一堆输入特征图和输出特征图共用一组权重，权重数仅为$K_r\\times K_c$个，也就大幅减少了权重的数量。 3.1.2.1 卷积运算​ 卷积神经网络的卷积运算即对输入子矩阵和卷积核做矩阵内积。 3.1.2.2 多输入输出特征图的卷积运算​ 图像中可能有很多种边缘特征，为了提取图像中的不同特征，神经网络需要有多个不同的卷积核去提取多个不同的特征，之后每一个神经网络层输出多个特征图，此时下一层的输入便是多个特征图，这时需要用多个卷积核分别和对应的特征图做卷积运算，最后共同计算出最后的特征图。 3.1.2.3 边界扩充和卷积步长​ 通常情况下，如果不做边界扩充，卷积之后的输出尺寸会被动地略微改变，如果要保证神经网络的输入特征图和输出特征图的尺寸相同，可以进行边界扩充。另外，因为扩充的点都是0，边界扩充还可以强化图像的边缘信息。 ​ 相反如果希望输出特征图的尺寸有明显变化，可以加大卷积步长，具体可以根据实际的应用需求来调整。 3.1.3 池化层​ 池化层（pooling layer），也称汇聚层和子采样层，可以主动减小图片的尺寸，从而减少参数的数量和计算量，抑制过拟合。常用的池化方法有：最大池化、平均池化、$L^2$池化。 ​ 最大池化法（Max Pooling）：对一个区域$R^d_m,_n$，选择这个区域内所有神经元的最大活性值作为这个区域的表示，即$$y^d_m,n=\\max{i\\in{R^d_m,_n}}x_i,$$其中$x_i$为区域$R_k^d$内每个神经元的活性值，通俗的讲，就是在池化窗口内找出最大值作为输出。 ​ 平均池化法（Mean Pooling）:一般是取区域内所有神经元活性值的平均值，即$$y^d_m,_n=\\frac{1}{|R^d_m,n|}\\sum{i\\in{R^d_m,_n}}x_i$$​ $L^2$池化法是在池化窗口内对所有的数计算平方并累加和后再开方。 3.1.4 全连接层​ 卷积层和池化层构成特征提取器，而全连接层是分类器，全连接层将特征提取得到的高维特征图映射成一维特征向量，最终转化为最终分类为各个类别的概率。 3.1.5 softmax层​ softmax层对输出进行归一化，输出分类概率，其计算公式为：$$f(z_j)=\\frac{e^{z_j}}{\\sum_{i=0}^{n}e^{z_i}}$$​ 可以看出，通过归一化计算，可以凸显较大的值并抑制较小的值，从而显著地抑制次要特征，决定分类概率。 3.2 基于卷积神经网络的图像分类算法3.2.1 AlexNet​ AlexNet是第一个现代深度卷积网络模型，相对于传统人工神经网络，其首次使用了很多现代深度卷积网络的技术方法： ​ （1）使用GPU进行并行训练 ​ （2）Dropout（随机失活）。在训练的过程中随机舍弃部分隐层结点，可以避免过拟合。 ​ （3）LRN（局部响应归一化）。LRN的输入是N个不同的特征图，在同一位置上如果包含多个特征，就需要对该位置上的点进行归一化，突出该位置上最显著的特征。后被证明没有实际效果，现在很少使用。 ​ （4）MaxPooling（最大池化）。最大池化可以避免特征被平均池化模糊，提高特征的鲁棒性。 ​ （5）ReLU激活函数。提高了训练时的收敛速度。 详细可参考论文：Krizhevsky A, Sutskever I, Hinton G E, 2012. ImageNet classification with deep convolutional neural networks[C] 3.2.2 VGG​ AlexNet使用了8层的神经网络，VGG则使用了更多层的神经网络（最大层数为19层）。 ​ VGG使用规则的多层小卷积替代大卷积，在相同视野下，有效减少了权重参数的数量，提高了训练速度；并且在神经网络中使用更多的卷积层及非线性激活函数，提高了图像分类的准确率；提出预训练策略，利用较浅层神经网络训练出来的权重参数来初始化更深神经网络的部分层。 3.2.3 Inception​ 在Inception网络中，一个卷积层包含多个不同大小的卷积操作，称为Inception模块。Inception网络是由有多个Inception模块和少量的池化层堆叠而成。Inception网络有多个版本，其中最著名的就是Inception v1版本，即GoogLeNet，它获得了2014年ImageNet比赛的冠军。其网络结构模型见https://nndl.github.io/v/cnn-googlenet。 ​ 相对于VGG，GoogLeNet网络层数更深、参数更少、分类精度更高，这主要得益于： ​ （1）$1\\times 1$卷积层：将多个输入特征图上相同位置的点做全连接处理，计算出输出特征图上对应位置的一个点，相当于先进行一次特征抽取，可以降低特征图的维度，减少参数数量和计算量。 ​ （2）softmax辅助分类器：可以观察训练的中间结果，提前反向传播，从而防止梯度消失。 ​ （3）Inception模块，通过引入非常灵活的Inception模块，能让每一层网络适应不同尺度的图像的特性。 ​ 在GoogLeNet的基础上，BN-Inception在训练中引入了批归一化（Batch Normalization），意思就是对一批数据做归一化，在BN出现之前，归一化操作一般都在数据输入层，对输入的数据进行求均值以及求方差做归一化，但是BN的出现后，我们可以在网络中任意一层进行归一化处理，从而使得当前层的输出靠近中间的区域，输入很小的变化就能显著地体现在损失函数中，从而有效避免了梯度消失的问题。详情见博客：https://www.cnblogs.com/skyfsm/p/8453498.html。 ​ Inception-v3网络用多层小卷积核来替换大的卷积核，从而减少计算量和参数量，并保持感受野不变。比如：1）使用两层3×3的卷积来替换v1中的5×5的卷积；2）使用连续的𝐾×1和1×𝐾 来替换𝐾×𝐾 的卷积。此外，Inception-v3网络同时也引入了标签平滑以及批量归一化等优化方法进行训练。 3.2.4 ResNet​ 前面介绍的各种神经网络技术在不断加深神经网络的层数，但是在突破神经网络深度问题上最具有颠覆性的技术还是来自ResNet（残差网络），达到了152层。残差网络通过给非线性的卷积层增加直连边的方式来提高信息的传播效率，其原理需要结合论文《Deep residual learning for image recognition》。 3.3 基于卷积神经网络的图像目标检测算法3.3.1 R-CNN（区域卷积神经网络）​ R-CNN主要包括四个步骤： ​ （1）候选区域提取：通过选择性搜索从原始图片中提取2000个左右的候选区域。 ​ （2）特征提取：将所有候选区域裁剪缩放为固定大小，再对每个候选区域用AlexNet提取出4096维的图像特征。 ​ （3）线性分类：用特定类别的SVM（Supported Vector Machine，支持向量机）对每个候选区域做分类。 ​ （4）边界框回归：用线性回归来修正边界框的位置和大小，其中每个类别单独训练一个边界框回归器。 ​ R-CNN存在以下几个主要缺点： ​ （1）重复计算：2000个候选框都需要做卷积神经网络处理，计算量特别大，候选框之间很可能有较多的重叠部分，这些部分都会重复计算，增大了计算量。 ​ （2）SVM分类：在标注数据足够多的时候，用卷积神经网络做图像分类比SVM更为准确。 ​ （3）训练测试步骤多：计算过程中的很多中间数据需要单独保存，数据需要反复读写，效率低。 ​ （4）检测速度慢：重复计算和反复读写造成了耗时多，检测速度慢。 ​ 为了解决上述问题，分别有Fast R-CNN和Faster R-CNN的提出。 3.3.2 YOLO（You Only Look Once）​ YOLO使用统一检测模型，将目标分类和定位用一个神经网络统一起来，实现了端到端的目标检测，可以满足实时性应用要求。 ​ 相对于传统目标检测，有如下优点： ​ （1）检测速度快：YOLO将目标检测重建为单一回归问题，对输入图像直接处理，输出目标位置以及分类概率。 ​ （2）背景误判少：YOLO在训练和测试时每个格子都可以看到全局信息，减少背景误判。 ​ （3）泛化性好：YOLO能够学习到目标的泛化表示，能够迁移到其他领域。 ​ 虽然YOLO的检测速度很快，但是精度不高，主要是因为每个格子只能预测两个边界框和一种目标的分类，如果多个物体的中心在同一个格子内，就会丢失其他类别的物体；并且损失函数设计过于简单；模型不易训练。 3.3.4 SSD（Single Shot Detector，单次检测器）​ SSD的主要思想是：在不同大小的特征图上都提取默认框做检测，以找到最合适的默认框的位置和大小。在比较大的特征图上检测比较小的目标，在比较小的特征图中检测比较大的目标。 ​ SSD 使用卷积网络中较深的层来检测目标，导致图像的分辨率显著降低，可能已无法定位在低分辨率中难以检测的小目标。 3.4 序列模型：循环神经网络​ 循环神经网络是一类具有短期记忆能力的神经网络，在循环神经网络中，神经元不仅可以接受其他神经元的信息，还可以接受自己的信息，形成具有环路的网络结构。循环神经网络主要用于机器翻译、图片描述、视频标注、视觉问答等。 ​ 下图是一个循环神经网络，其输入是$x$，输出为$\\hat{y}$，隐层为$h$，隐层$h$称为记忆单元，具有存储信息的能力，其输出会影响下一时刻的输入。 ​ 循环神经网络通过下面的公式更新带反馈边的隐藏层的活性值𝒉𝑡：$$h_t=f(h_{t-1},x_t)$$​ RNN的训练一般采用一种变种的反向传播算法，学名为基于时间的反向传播，核心是将RNN按时间展开后做反向传播。BPTT完成正向传播后一般用交叉熵作为损失函数，然后做梯度下降。 ​ 由于RNN很容易出现梯度消失或梯度爆炸，RNN只能学到很短期的依赖关系，可以使用现在流行的长短期记忆模型（LSTM）和门限循环单元（GRU）。 3.5 生成对抗网络​ 目前最常见的两类深度学习算法是处理图像信息的卷积神经网络和处理序列信息的循环神经网络。这两类神经网络的共同特点是需要大量的训练样本。如何用少量样本去训练出准确的神经网络，由此便有了生成对抗网络（Generative Adversarial Net，GAN）。 ​ 生成对抗网络由生成网络和对抗网络组成。生成网络相当于伪装者，会通过不断学习生成足够以假乱真的样本，而判别网络相当于鉴定师，会判断该样本到底是真样本还是假样本。双方通过不断辩论，提升彼此的能力。用我自己的理解就是生成对抗网络相当于矛盾，一方生产能够刺穿一切盾的矛，一方生产足够抵挡一切矛的盾，双方在不断博弈的过程中，达到提升自己的能力，从而整个网络能力不断提高。 ​ GAN大致可分为：卷积GAN、条件GAN、集成预测模型的GAN、对抗自编码器。对应GAN的学习需要在日后的实际应用中深入学习。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E4%B8%89%E7%AB%A0/"},{"title":"《智能计算系统》第四章","text":"第四章 编程框架的使用4.1 TensorFlow编程模型及基本用法​ 在程序开发中，根据解决问题的不同思路，通常采用两种不同的编程方式，常见的编程方式有两种：命令式编程和声明式编程。 ​ 命令式编程：关注程序执行的具体步骤，计算机按照代码中的顺序一步一步地执行具体的运算，整体优化困难。比如交互式UI程序和操作系统。 ​ 声明式编程：告诉计算机想要表达的目标，不指定具体的实现步骤，而是通过函数、推理规则等来描述数据之间的关系，优化比较容易。比如人工智能和深度学习。 4.1.1 计算图​ 用包含了一组节点和边的有向图来描述计算过程，这个有向图叫做计算图。TensorFlow使用计算图来表示机器学习算法中所有的计算和状态。 4.1.2 操作​ 计算图中每个节点代表一个操作，表示一个局部计算，TensorFlow中一些常用操作如下： 操作类型 常用操作 标量运算 add、subtract、multiply、div、greater、less、equal、abs、sign、square、pow、log、sin、cos 矩阵运算 matmul、matrix_inverse、matrix_determinant、matrix_transpose 逻辑操作 logical_and、is_finite 神经网络运算 convolution、max_pool、bias_add、softmax、dropout、sigmoid、relu 保存和恢复 save、restore 初始化操作 zeros_initializer、random_normal_initializer、orthogonal_initializer 随机运算 random_gamma、multinomail、random_normal、random_shuffle 4.1.3 张量​ TensorFlow用张量来计算图中的所有数据。张量在计算图的节点之间流动，但张量并没有实际保存数据，只是对操作结果的引用。张量可以看作N维数组，数组的维数就是张量的阶数。对张量的常用操作可以查看书本。 4.1.4 会话​ 真正的计算过程需要在TensorFlow程序的会话中定义并执行。会话为程序提供了求解张量、执行操作的运行环境。一个典型的使用流程就是：创建会话；执行会话；关闭会话。 4.1.5 变量​ 变量是计算图中的一种有状态节点，用来在多次执行同一计算图时存储并更新指定张量，常用来表示机器学习或深度学习算法中的模型参数。变量的常用属性如下： 属性名称 含义 dtype 变量的数据类型 shape 变量的形状 name 变量在计算图中的名称 op 产生此变量的操作 device 存储此变量所用的设备名 graph 包含此变量的计算图 initialized_value 变量的初始值 initializer 为变量赋值的初始化操作 trainable 是否在训练时被优化器更新 4.1.6 占位符​ 占位符是TensorFlow中特有的数据结构，它本身没有初值，仅在程序中分配了内存。通过占位符将张量传递到会话中。 4.1.7 队列​ 通过队列处理数据读取和计算图的异步执行。队列是一种有状态的操作机制，用来处理数据读取。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E5%9B%9B%E7%AB%A0/"},{"title":"《智能计算系统》第五章","text":"第五章 编程框架机理5.1 TensorFlow设计原则​ TensorFlow的设计原则主要集中在三方面：高性能、易开发、可移植。 5.1.1 高性能​ 首先，TensorFlow中集成的算子在设计过程中已经针对底层硬件架构进行了充分的优化；同时，针对生成的计算图，TensorFlow提供了一系列的优化操作，提升了计算图的运行效率；并且TensorFlow调度器可以根据网络结构的特点，并行运行没有数据依赖的节点，异步发射满足依赖关系的多个节点而不同步等待每个节点的中间结果。 5.1.2 易开发​ TensorFlow针对现有的深度学习算法，提取了大量的共性运算，并且将这些运算封装成TensorFlow中的各种算子，以便用户进行调用。 5.1.3 可移植​ TensorFlow通过定义不同设备的通用抽象来实现应用程序的跨平台可移植目标。 5.2 TensorFlow计算图机制5.2.1 计算图​ 计算图是TensorFlow运行的核心，涵盖了TensorFlow的各类功能，包括数据计算、数据存取、逻辑控制和设备通信等。 5.2.1.1 自动求导​ 深度学习通常采用梯度下降法来更新模型参数，根据前向计算得到的结果和目标结果产生损失函数值，通过计算梯度来得到每个参数应该调整的偏移量，进而更新参数。常见的求导方法有以下几种： ​ （1）手动求导 ​ 用链式法则求出梯度公式，然后根据公式编码，代入数值计算得到梯度结果。其缺点就是无法通用或者复用，每次修改算法模型都需要重新求解梯度公式、重新编写代码。 ​ （2）数值求导 ​ 利用导数的定义进行求解，如公式：$$f’(x)=\\lim_{h\\rightarrow0}\\frac{f(x+h)-f(x)}{h}$$但是计算量大，运行速度慢，并且会引入舍入误差和截断误差。 ​ （3）符号求导 ​ 利用求导规则对表达式自动操作，但可能会遇到“表达式膨胀”的问题，导致求解速度变慢。 ​ （4）自动求导 ​ 这是一种介于符号求导和数值求导之间的方法，自动求导首先实现了一批常用基本算子的求导表达式，然后带入数值计算，保留中间结果，最后求出整个函数的导数。TensorFlow计算图将多输入的复杂计算表示成了由多个基本二元计算组成的有向图，并保留了所有中间变量，有助于程序自动利用链式法则进行求导。 5.2.1.2 检查点​ TensorFlow利用检查点机制进行模型的保存与恢复。通过向计算图中插入Save节点及其关联节点来完成保存模型的功能。其关联节点包括记录文件名的Const和tensor_names节点，分别用来指定检查点文件名以及所有需保存的Tensor列表；同样，恢复模型通过在计算图中插入Restore节点及其关联节点来完成，Restore通过赋值（Assign）节点来给待恢复的变量进行赋值。 5.2.1.3 控制流​ TensorFlow提供了5个基本的控制流算子，分别为Switch、Merge、Enter、Exit和NextIteration，通过这五个算子的组合可以实现条件分支以及while循环的功能。 5.2.1.4 执行模式​ TensorFlow的计算图执行包括客户端、主控进程以及一个或多个工作进程。每个工作进程可以访问一个或多个计算设备，并在上面执行计算图。TensorFlow提供了本地执行和分布式执行两种执行方式。其中本地执行主要是指客户端、主控进程以及工作进程都只在一个操作系统的单一物理机上运行，而分布式执行则可以支持三者在不同的机器上执行。 ​ 计算图中的节点将按照图中的依赖关系顺序执行，TensorFlow调度器会持续监视未被执行的节点，一旦某个节点所依赖的前驱节点的数量为0，该节点就会处于就绪状态，会被立即放入预执行队列中。之后执行器从队列中取出节点，根据节点信息，选择合适的设备创建相应的算子交给设备端来执行。 5.2.2 计算图的本地执行​ 计算图从创建到真正执行的过程包括以下四个步骤： ​ （1）计算图剪枝：根据输入输出列表在完整计算图上进行剪枝操作，从而得到最小依赖计算图。 ​ （2）计算图分配：在最小依赖计算图上，根据特定的设备分配规则以及操作的设备约束对计算图中的节点进行设备分配。 ​ （3）计算图优化：对计算图进行优化来提高运行效率。 ​ （4）计算图切分：根据划分结果，对计算图进行切分，从而为每个设备创建自身的计算子图。 5.2.2.1 计算图剪枝​ 计算图剪枝的目的是得到本地运行所需的最小子图，主要包括：去除计算图中与最终输出节点无关的节点和边，就是从输出节点进行宽度搜索遍历，对在遍历过程中没有接触到的节点和边进行删除；给输入输出节点建立和外界的交互，遍历完成之后可能会生成多个连通图，此时需要将每个连通图的入度为0的节点通过依赖控制边与Source节点相连，出度为0的节点通过控制依赖边和Sink节点相连，从而形成完整的计算图。 5.2.2.2 计算图分配​ 计算图分配用以解决在多设备运行的环境中，计算图在哪个设备上执行的问题，用户可以自行指定某个操作的计算设备，也可以指定哪些计算节点需要绑定在同一个设备上。为了获得最合适的设备分配方案，TensorFlow设计了相应的代价模型，对于未指定的计算节点，TensorFlow采用贪心策略来对每个节点进行分配，从Source节点开始，算法模拟每个节点在支持该节点的所有不同设备上的执行情况，得到不同设备是该节点的执行开销，进而选择合适的设备进行分配。 5.2.2.3 计算图优化​ TensorFlow中的图优化由Grappler模块来实现，Grappler已经实现了多种优化方法。典型的优化方法包括ConstFold（包括常量折叠等优化）、Arithmetic（包括算术简化等）、Layout（包括布局优化等）和Remapper（包括算子融合等）。通过计算图优化，可以根据不同的硬件结构调整计算调度策略，从而获得更快的计算速度和更高的硬件利用率。也能减少预测过程中所需的峰值内存，从而允许运行更大的模型。 5.2.2.4 计算图切分和设备通信​ 计算图切分，是在计算图的一系列优化完成之后，将计算图放到多个设备上计算，每个设备对应一个切分子图，这时就需要解决各个设备间的通信问题。在新的设备中，所有跨设备的边都被替换为一对由Send和Recv组成的节点，在运行时，Send/Recv节点合作完成跨设备的通信。其中Send/Recv屏蔽了和设备相关的通信细节，简化了运行时的复杂性。在Recv没有得到有效数据之前，图的运行会被阻塞。而主控机只需要向不同的工作机传递运行请求，不需要负责不同工作机的同步问题，使得系统更可扩展和更高效。 5.2.3 计算图的分布式执行​ 随着神经网络规模及数据规模指数型增加，为了有效提高神经网络训练效率，降低训练时间，在模型训练中普遍采用分布式技术。计算图的分布式执行与多设备计算图的本地执行类似，在图分配后为每个设备都创建一个子图，工作进程间的通信由Send/Recv节点合作通过远程通信机制进行数据传输。 5.3 TensorFlow系统实现5.3.1 整体架构​ 如图所示，架构主要分为三个部分：第一部分是面向各种语言的语言包；第二部分是C/C++API，基于TensorFlow的核心代码，使用C和C++语言封装出了两套APT，主要面向有较高性能需求的用户；第三部分是TensorFlow的后端代码，由C++代码实现，保证了可移植性和性能。 ​ 5.3.2 计算图执行模块5.3.2.1 Session执行​ Session是用户和TensorFlow运行时的接口。在Session接收到输入数据时，便可开始运行。一般情况下，每个设备会有一个执行器（Executor），负责本设备上子计算图的执行。Run函数是Session执行的核心逻辑，在其中完成计算图的执行，包括传参、运行和返回。 ​ TensorFlow1.x通过先构建静态图，然后通过tf.Session来执行。TensorFlow2.0则将使用正常的python编程方式，不再使用tf.Session，而使用tf.function。tf.function做为装饰器来使用，可以将函数转换成图，帮助优化和序列化。 5.3.2.2 执行器逻辑​ 引入执行流，执行流是一个可以存储计算任务的队列，队列中的计算任务按照加入队列的顺序执行。通常设备在执行任务时会存在不同的流，流间任务可以并行执行，流内任务串行执行。执行器在对计算图节点进行流分配的原则是将有数据依赖的节点分配到同一流中，没有数据依赖的节点分配到不同的流中，这样可以最大限度地实现流与流之间的并行。 ​ 执行器逻辑的具体流程就是在对计算图分配完流之后，执行器启动ScheduleReady函数开始异步执行计算图中的节点，执行器调用完RunAsync函数后，返回主逻辑，等待执行结束。 ​ ScheduleReady逻辑主要处理两个队列：ready队列（预执行队列，inline_ready队列。如果inline_ready队列为空，使用新线程分别处理ready队列中的每个节点。如果inline_ready队列不为空，如果节点都是低开销的，则逐一放到inline_ready队列中，如果节点是高开销的，如果inline_ready队列为空则将首个高开销节点放入inline_ready队列中，否则启用新线程去执行。ready队列中节点真正的计算都在possess函数中，possess函数为OpKernel设置运行参数、为OpKernel准备输入和参数、 调用设备计算、处理计算输出、传播输出、更新节点间依赖关系。 5.3.3 设备抽象和管理​ TensorFlow将设备分成本地设备和远程设备两类，TensorFlow使用注册机制来管理设备。每个设备负责一个子图的运算，可以通过注册接口支持自定义设备。设备继承自DeviceBase类，其定义了基本的数据结构与接口，基于DeviceBase类又设计了LocalDevice类，本地设备可以基于LocalDevice类创建自己的设备类。 5.3.4 网络和通信​ TensorFlow中不同设备间的通信都由Send和Recv节点进行，Send和Recv使用Rendezvous机制完成数据交互，Rendezvous是一个基于生产者-消费者模型的抽象类。每个Rendezvous实例拥有一个通道表，用来记录每对Send/Recv的关系和状态。不同的通道拥有唯一的键值，生产者使用Send方法将数据传到特定通道（可以传输多组数据），消费者可以在任何时候使用Recv方法从特定通道获取数据（可按照发送顺序获取），也可以使用回调或者阻塞的方法来获取数据。不论哪种方法，消费者都能在数据有效时尽快得到数据，生产者在任何时候都不会被阻塞。 ​ 对于本地传输来说，TensorFlow提供了LocalRendezvous 实现类，对于远程通信来说，TensorFlow提供 了RemoteRendezvous实现类。 5.3.5 算子实现​ 算子是TensorFlow的基本单元。OpKernel是算子的特定执行，依赖于底层硬件。基于不同设备、不同的数据类型，算子可以由不同的OpKernel实现：既可以使用底层硬件提供的高性能库，也可以采用特定的编程语言。TensorFlow通过注册机制来支持不同的算子和相应的OpKernel函数。 ​ OpKernel的计算可以是同步的也可以是异步的，由于同一个图可能同时被执行多份，所以所有的OpKernel的Compute方法必须保证线程安全。大部分OpKernel的计算是同步的，”Compute()”返回即认为数据已经被正确处理。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E4%BA%94%E7%AB%A0/"},{"title":"《智能计算系统》第六章","text":"第六章 深度学习处理器原理6.1 深度学习处理器概述6.1.1 深度学习处理器的意义​ 随着神经网络算法的发展，神经网络从只有输入和输出层的感知机，发展到有一个隐层的多层感知机，再到深度神经网络。在这个过程中，伴随着神经网络的层数、神经元数量、突触数量的不断增长，传统芯片CPU、GPU已经难以满足神经网络不断增长的速度和能效需求。由此诞生了深度学习处理器。 6.1.2 深度学习处理器的发展历史​ 早期的神经网络计算机/芯片只能处理很小规模的浅层神经网络算法，未能取得工业实践中的广泛应用。随着深度学习技术的兴起，推动了人工智能芯片的研究和发展。 ​ 深度学习处理器的蓬勃发展主要得益于以下三个方面： ​ （1）深度学习应用广泛 ​ （2）集成电路工艺发展放缓 ​ （3）计算机体系结构技术的发展 6.1.3 设计思路​ 整个体系结构最重要的问题：算法范围界定和算法分析。深度学习处理器需要在通用性和灵活性之间取得平衡，既要能效高，又要能对深度学习应用有全面的支持。深度学习处理器需要具备可编程的能力，通过编程来支持深度学习编程框架中已有的深度学习算子，甚至是未来的算子。 ​ 因此，设计深度学习处理器时，首先要分析算法的计算特性和访存特性，然后根据算法特性，确定深度学习处理器的微体系结构，包括指令集、流水线、运算部件、访存部件。 6.2 目标算法分析​ 以本书驱动范例，针对VGG19进行分析。 6.2.1 计算特征​ 不同层的计算特点如表所示： 层 计算类型 乘加操作个数 激活函数操作个数 卷积层 矩阵内积、向量的元素操作 $N_{if}\\times N_{of}\\times N_{or}\\times N_{oc}\\times K_{r}\\times K_{c}$个乘加 $N_{of}\\times N_{or}\\times N_{oc}$ 池化层 向量的元素操作 $N_{if}\\times N_{or}\\times N_{oc}\\times K_{r}\\times K_{c}$个加法或比较$+N_{if}\\times N_{or}\\times N_{oc}$个除法操作（平均池化） 无 全连接层 矩阵乘向量，向量的元素操作 $N_{o}\\times N_{i}$个乘加 $N_{o}$ 6.2.2 访存特征​ 不同层的重用特点如表所示： 层 可重用 不可重用 卷积层 输入神经元、输出神经元、突触权重 无 池化层 当池化窗口大于步长时，部分输入神经元可重用 当池化窗口小于等于步长时，输入神经元、输出神经元都不可重用 全连接层 输入神经元、输出神经元 突触权重 6.3 深度学习处理器DLP结构6.3.1 指令集​ 硬连线方案为每个神经网络提供专门的硬件控制逻辑，这种方案对特定神经网络能效极高，但无法支持新的神经网络，通用性差。 ​ 指令集方案是把各种神经网络层或算子拆分成一些基本的操作，每个操作由一条指令来完成。只要指令集覆盖了各种深度学习算子的最大公约数，新的神经网络层就能够由这些指令拼接组合起来，因此指令集方案兼顾了能效和通用性。 ​ 在提升并行性方面，采用数据级并行，数据级并行是指一条指令可以同时处理多个数据。数据级并行的优点在于指令数较少，因而指令流水线功耗、面积开销小。虽然指令级并行的灵活性高，但其指令流水线控制通路复杂，功耗和面积开销都很大，由于深度学习中主要是规整的向量、矩阵操作，并且迫切需要提升效率，降低功耗和面积开销，所以采用数据级并行的指令集。 6.3.2 流水线​ DLP的一条指令执行主要经历7个流水线阶段：取指、译码、发射、读寄存器、执行、写回、提交。DLP深度学习处理器架构如图所示： 其中，VFU为向量功能单元，MFU为矩阵功能单元。 6.3.3 运算部件6.3.3.1 向量MAC​ 下图是一个最基本的标量MAC单元，功能是完成一个乘加操作，它的输入是两个标量a和b，它的输出为两个标量的乘积加上原始值c，即$a\\times b+c$。 ​ 而向量MAC的输入则是两个向量$a=[a_1;a_2;a_3;\\cdots;a_N]$和$b=[b_1;b_2;b_3;\\cdots;b_N]$，输出为两个向量的内积再加上原始值c，即$$\\sum_{i=1}^Na_i\\times b_i+c$$​ 输入为两个N维向量的MAC，每个时钟周期可以完成一个N输入1输出的神经网络全连接层的计算。如果DLP集成了M个向量MAC，那么每个时钟周期就可以处理完成一个N输入M输出的神经网络全连接层的计算。 6.3.3.2 对向量MAC单元的扩展​ 对向量MAC单元作如下改进，以支持VGG19网络中前向计算的所有算子。 ​ （1）增加可重构的非线性激活函数的运算部件。 ​ （2）增加局部累加器，支持加偏置的运算。 ​ （3）增加MFU-1/MFU-2/MFU-3的退出通路以支持池化运算。 ​ 6.3.3.3 MFU和VFU​ MFU和VFU分别用于支持矩阵指令和向量指令，因此MFU支持矩阵向量乘指令MMV、向量矩阵乘指令VMM、矩阵标量乘指令NMS、外积乘指令OP、矩阵加矩阵指令MAM和矩阵减矩阵指令MSM。而VFU则需要支持神经网络算法中单纯的一维向量操作指令，而无需实现在MFU上，降低MFU的复杂度，提高向量操作的灵活性。 6.3.4 访存部件​ 深度学习处理器采用Scratchpad Memory管理方案，将输入神经元、输出神经元、突出权重这三类数据放在不同的片上存储器上（可解耦性），形成“运算单元-片上-片外“的存储架构，提高片上数据复用率。分别为NRAM-in（输入神经元缓存）、NRAM-out（输出神经元缓存）和WRAM（权重缓存）。 6.3.5 算法到芯片的映射​ 由于输入神经元/输出数据元的个数数量级非常高，现阶段没有任何单个芯片足以放下100万个乘法器，因此在计算过程中硬件运算必须时分复用。在每个计算周期只用一小块的输入数据去计算一小块的输出数据，下一计算周期计算下一小块的输出数据，最后汇总得到最终的输出数据。 6.4 优化设计6.4.1 基于标量MAC的运算部件​ 由于卷积运算中存在多种数据可复用性，在设计标量MAC的运算单元时可以有效地利用这些特性，其一种实现如图所示： 通过PE间的数据传递来获得所需要的数据，可以有效地减少片外访存带宽，缓解访存压力。 6.4.2 稀疏化​ 采用稀疏化的方法，可以大幅降低神经网络的计算量和数据量。我们可以对权重稀疏化，也可以对神经元稀疏化，也可以动态稀疏化。利用稀疏的基本思路有两个，一个时是只计算非稀疏的部分，一个是直接跳过稀疏部分。前一种思路需要在计算前先对稀疏数据做处理，把里面的零去掉，从而把稀疏数据变成稠密数据，最后通过硬件单元直接计算，这样所得的计算结果都是有效数据。这种思路可以高效地利用稀疏，不仅可以加快计算速速，还可以高能效，但是需要对硬件做较大的改动。而后一种思路，硬件改动简单，只需要判断输入是否为零，如果为零，则输出直接为零。 ​ 为了进一步利用神经网络稀疏化的特点来降低存储和访存带宽，可以把稀疏化和量化压缩结合起来，最后神经元和权重所需的片上存储空间和访存带宽可以减少到十分之一左右。 6.4.3 低位宽​ 在处理器设计时采用更低位宽的运算器，虽然很多神经网络算法在计算时采用32位的单精度浮点数，但实际上16位定点数或者8位定点数已经足够满足应用需求。 6.5 性能评价6.5.1 性能指标​ 深度学习处理器衡量计算能力的常用指标是TOPS（Tera Operations Per Second），即每秒执行多少万亿次操作。$$TOPS=f_c\\times (N_{mul}+N_{add})/1000$$处理器主频 $f_c$的单位是 GHz，$N_{mul}$ 和 $N_{add}$分别表示每个时钟周期执行多少乘法或加法操作。 ​ 处理器的实际性能还受到访存带宽BW的影响，包括访问外存的带宽、访问多级片上存储的带宽。其中$$BW=f_m\\times b\\times \\eta$$表示访存带宽BW与存储器的主频$f_m$ 、存储位宽 $b$、访存效率 $\\eta$的关系。 6.5.2 基准测试​ 基准测试程序MLPerf： ​ 6.5.3 影响性能的因素​ 一个深度学习任务的运行时间可以写为：$$T=\\sum_iN_i\\times C_i/f_c$$其中𝑁𝑖表示该任务中第i类操作的数量，𝐶𝑖表示完成第i类操作所需要的时钟周期数，𝑓𝑐表示处理器的主频。 ​ 因此，为了减少深度学习任务的处理时间，可以从以下几个方面入手： ​ 首先，减少经常出现的操作的执行周期数；其次，利用数据局部性，减少访存开销；最后，多级并行。 6.6 其他加速器​ 如表所示，DLP和其他加速器的比较： 类别 目标 速度 能效 灵活性 DLP 深度学习专用 高 高 深度学习领域通用 FPGA 通用可编程电路 低 中 通用 GPU SIMT架构矩阵加速 中 低 矩阵类应用通用","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E5%85%AD%E7%AB%A0/"},{"title":"《智能计算系统》第七章","text":"第七章 深度学习处理器架构​ 为了满足智能终端的实际应用需求，DLP-S在DLP的基础上对控制部件、运算部件和存储部件进行了优化，在降低功耗的同时提升了性能。 7.1 单核深度学习处理器​ DLP-S在DLP的基础上进行了优化，主要体现在如下四个方面： ​ （1）在控制模块中设计了多发射队列，使得没有依赖关系的指令可以并行发射，从而支持指令级并行。 ​ （2）在向量运算单元中添加更多的运算操作组合，提高性能和灵活性。 ​ （3）在矩阵运算单元中采用低位宽的运算器，并且支持稀疏数据，减少运算能耗。 ​ （4）在存储模块中采用TLB和LLC减少了访存的延迟。 7.1.1 总体架构​ 图为DLP-S的总体架构示意图。DLP-S包括三大模块，即控制模块、运算模块和存储模块。 ​ 控制模块包括取指单元IFU（Instruction Fetch Unit）和指令译码单元IDU（Instruction Decode Unit）。运算模块包括向量运算单元VFU（Vector Function Unit）和矩阵运算单元MFU（Matrix Function Unit）。存储模块包括权重存储单元WRAMW（Weight RAM）和神经元存储单元NRAM（Neuron RAM）和直接内存存取单元DMA（Direct Memory Access）。 ​ DLP-S执行一次深度学习运算的流程具体如下： ​ （1）IFU通过DMA从DRAM中读取程序指令，然后经过IDU 进行译码后分发给DMA、VFU 和 MFU。 ​ （2）DMA接收到访存指令（读tensor指令，包括地址， 数据量等信息）后从DRAM读取神经元tensor至NRAM，读取权值tensor至WRAM。 ​ （3）VFU接收到指令后从NRAM中读取神经元tensor，并对神经元tensor进行预处理（如边界扩充等），然后发送给MFU。 ​ （4）MFU接收到指令后从VFU接收经过预处理的神经元tensor，并从WRAM中读取权重tensor，完成矩阵运算后将结果发送给VFU。 ​ （5）VFU对输出神经元tensor进行后处理（如激活、池化等）。 ​ （6）VFU将运算结果tensor写回NRAM。 ​ （7）DMA将输出神经元tensor从NRAM写回到DRAM。 ​ 由上述流程可以知道神经元tensor数据流的走向为：DRAM-&gt;NRAM-&gt;VFU-&gt;(MFU-&gt;VFU-&gt;)NRAM-&gt;DRAM，权重的数据流走向为：DRAM-&gt;WRAM-&gt;MFU。 7.1.2 控制模块​ 控制模块负责取指令和翻译指令两个基本功能，这两个功能分别由IFU和IDU完成。 ​ IFU抽象视图如下： 包括地址生成器AGU（Address Generator Unit）、 指令高速缓存ICache（Instruction Cache）、指令回填单元RB（Refill Buffer）、指令队列IQ（Instruction Queue，用来缓存PC和指令）。 ​ IFU首先通过AGU得到当前PC值，如果PC在ICache命中，则直接从ICache中读出指令，如果不命中，将PC和预取指令条数发给RB，RB向DMA发送指令回填请求，DMA根据PC从DRAM读取对应的指令到ICache中，完成取指令操作。 ​ IDU的抽象视图如下： 包括译码单元Decoder 、指令发射队列（Issue Queue）：Control IQ，Compute IQ，Memory Access IQ和算数逻辑单元ALU。 ​ Decoder接收来自IFU的指令并进行译码，然后根据指令类型发送给对应的指令发射队列。指令具体分为三类：控制指令、运算指令和访存指令。在三类指令在没有依赖关系的情况下可以并行执行，三个队列也是队内有序，队间无序，但是如果不同队列的指令间存在依赖关系，就会在两者之间插入同步指令（SYNC），以保证程序执行的正确性。最后ALU用来完成标量运算和分支跳转等功能。 7.1.3 运算模块​ 运算模块包括向量运算单元VFU和矩阵运算单元MFU。 ​ 向量运算单元VFU完成输入神经元的前处理和输出神经元的后处理 ，包括向量流水单元和转置单元，向量流水单元承载向量运算功能，转置单元承载数据重新摆放功能。 ​ MFU采用分布式设计，由M个PE构成，M个PE之间采用H树的方式进行连接，采用低位宽定点运算器减少MFU的功耗。 7.1.4 存储单元​ DLP-S的存储单元主要包括NRAM、WRAM和DMA三个部分，将内部的SRAM和外部的DRAM统一编址，称为虚拟地址，这样可以直接实现内部SRAM的高速访问和外部DRAM的间接访问。需要注意的是，片内无需虚实地址转换，片内外需要虚实地址转换。并且DLP-S为了减少对DRAM的访存开销，设计了TLB缓存常用页表以及LLC缓存经常访问的DRAM数据。 7.2 多核深度学习处理器​ DLP-M采用多核处理器分层结构设计，如图所示，DLP-M可以分为Chip-Cluster-Core三个层级，即一个DLP-M由多个DLP-C互联构成，一个DLP-C由多个DLP-S构成。 ​ 在Chip层级，DLP-M包括五个部分，外部存储控制器 、外设通信模块 、片上互联模块 、同步模块GBC（Global Barrier Controller）和四个DLP-C。 ​ 在Cluster层级，一个DLP-C由四个DLP-S 和一个存储核MEMCORE（Memory Core）构成。 ​ 存储核主要功能是存储和通信。存储：DLP-S共享数据 ，通信：DLP-C与片外DRAM，DLP-C之间，多个DLP-S之间的通信。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E4%B8%83%E7%AB%A0/"},{"title":"《智能计算系统》第八章","text":"第八章 智能编程语言8.1 为什么需要智能编程语言​ 传统编程语言和智能计算系统存在三方面的鸿沟：一是语义鸿沟，传统编程语言无法高效地描述高层智能计算语义，导致开发智能应用程序效率低下；二是硬件鸿沟，传统编程语言难以高效地抽象智能计算硬件特性，导致最终生成的代码的执行效率较低；三是平台鸿沟，智能计算硬件平台种类繁多并且在不断增长，传统编程语言难以实现跨平台可移植，针对特定平台优化的程序难以实现在不同平台上的高效执行。 8.1.1 语义鸿沟​ 传统编程语言通常是以面向通用计算的加、减、乘、除等基本标量运算为基础的。而智能计算任务通常核心都是向量和矩阵运算，智能编程语言通过直接提供智能计算核心操作算子，大幅提高开发效率，为了进一步提高开发效率，还出现了面向具体领域的编程语言。 8.1.2 硬件鸿沟​ 控制逻辑：传统编程语言通过编译优化以及硬件架构优化来充分挖掘代码的并行度，其具体的控制逻辑对用户是透明的，而对于智能计算硬件而言，其指令以高度并行、相对规整的向量指令或宏指令为主。因此传统编程语言中的控制流、大量标量运算，以及相对耗时的片外访存都极容易带来流水线的气泡，影响计算效率。智能编程语言为用户提供更多的底层硬件特性，如特殊的控制流指令让用户直接采用底层硬件所支持的特殊向量或宏指令实现的计算函数来编写程序以降低分支控制的开销；通过提供高层语言特性，让用户更容易控制计算和访存之间的平衡。 ​ 存储逻辑：传统通用处理器以硬件管理下对程序员透明的cache为主，辅以程序员可见的逻辑寄存器，传统编程语言并不需要看到上述存储层次，通过编译器优化和硬件架构策略充分利用片上存储缓解存储墙问题。但这种方式无法最大限度地发挥底层硬件的计算性能，智能计算硬件采用程序员显示管理的SPM来降低硬件开销并提高灵活性。 ​ 计算逻辑：传统通用处理器主要提高ALU和FPU，一般不具有面向智能计算特性的定制运算单元，如低位宽运算器。而当下很多场景的智能计算任务具有一定的误差容忍度，不需要高精度运算器，故智能计算系统通过提供定制运算单元和更多的数据类型，从而提高效率降低功耗。 8.1.3 平台鸿沟​ 针对特定硬件平台优化地很好的程序，在新的硬件平台上可移植性存在很大挑战。智能编程语言通过抽取不同硬件平台的共性特征，在硬件抽象层次和性能间寻找最佳平衡点。 8.2 智能计算系统抽象架构8.2.1 抽象硬件架构​ 不同规模的计算系统可以整体抽象为存储、控制和计算三大部分。智能计算系统的每一层都包含存储单元、控制单元和若干计算单元。其中每个计算单元又进一步分解为子控制单元、子计算单元和子存储单元三部分。整个系统以这样的方式递归实现。在最底层，每个叶节点都是具体的加速器，用于完成最基本的计算任务。 8.2.2 典型智能计算系统​ 多卡的DLP服务器可以抽象为五个层次：服务器级（Server）、板卡级（Card）、芯片级（Chip）、处理器簇级（Cluster）和处理器核级（Core）。该架构可以方便地通过增加各层次的规模来提升整个系统算力。 8.2.3 控制模型​ 指令是实现对计算和存储进行控制的关键。为了设计高效的指令集、需要充分分析智能领域的典型计算模式，提炼最具代表性的操作，并进行针对性设计。 ​ 对智能算法进行抽象得到四类典型操作：控制、数据传输、计算（标量、向量和矩阵运算等）和逻辑操作（标量和向量运算等）。 ​ 关注计算与存储的交互：尽可能将计算与存储并行，例如可以将控制计 算和访存的指令分开在不同的队列中发射执行，以提高并行度。 8.2.4 计算模型​ 程序员可见的主要包括定制运算单元和并行计算架构。 8.2.4.1 定制运算单元​ 智能应用具有一定误差容忍度。因此一般在智能计算系统中会采用定制的低位宽运算单元（如FP16、INT8、 BF16甚至是INT4等）以提升处理能效。由于智能应用的多样性和复杂性，目前对于哪种低位宽最为合适并未形成统一结论。 8.2.4.2 并行计算架构​ 要求程序员对任务进行切分，将任务尽量均衡地分配到大量并行计算单元上执行。并且需要有相应的同步机制，以保证切分后任务之间的依赖关系。 8.2.5 存储模型​ 智能应用中存在大量数据密集的内存访问，因此合理地组织存储层次和计算单元同样重要，需要两者协同设计以平衡计算与访存，实现高效的智能计算。存储分为全局存储和本地存储。 8.3 智能编程模型8.3.1 异构编程模型​ 异构计算系统组成：（1）通用处理器：控制设备（简称主机端），负责控制和调度等工作。（2）领域处理器：从设备（简称设备端），负责大规模的并行计算或领域专用计算任务。二者协同完成完整计算任务。 ​ 异构并行编程模型从用户接口角度大致可分为两类：一是构建全新的异构并行编程语言；二是对现有编程语言进行异构并行扩展。典型异构并行编程模型的对比如下： 编程模型 类别 主要编程考量 OpenCL 语言扩展 任务划分+数据分布、通信、同步 CUDA 语言扩展 任务划分+数据分布、通信、同步 Copperhead 新语言 任务划分为主 Merge 新语言 任务划分为主 ​ 异构编程模型的编译和链接流程如下图所示： ​ 异构并行编程语言编译器需要为任务划分、数据分布、数据通信和同步机制等提供底层支持。具体如下： ​ （1）任务划分 ​ 编程模型需要向程序员提供并行编程接口，方便程序员定义和划分任务。编译器负责底层的任务划分，使得程序可以在并行架构上高效执行。 ​ （2）数据分布 ​ 对于编译器和底层运行时系统而言，需要根据算法和硬件架构的特点，通过合适的数据分布指导后续编译和运行时优化。 ​ （3）数据通信 ​ 由于设备端通常有多级存储空间、编译器需要支持各种地址空间声明，以方便程序员显式控制存储数据的地址空间。 ​ （4）并行同步 ​ 设备端程序一般要求感知多个核的并行处理，因此需要提供对同步机制的支持。 ​ 异构运行时的主要任务是保证任务映射及调度，即指定任务具体在哪个设备或计算单元上以何种顺序执行。 8.3.2 通用智能编程模型8.3.2.1 Kernel函数​ Kernel是DLP上执行任务的程序，资源允许情况下DLP可以同时执行多个并行的Kernel。每个Kernel有一个入口函数，BCL中用__dlp_entry__来指定。Kernel的启动需调用运行时API：InvokeKernel函数。设备端程序默认的函数类型：Device函数，以__dlp_device__来修饰。 8.3.2.2 编译器支持​ 1. 任务划分 ​ 用户可以使用内建变量clusterDim，clusterId，coreDim，coreId分别表示Cluster和Core的维度和ID。程序表示任务的内建变量有：taskDim、taskDimX、taskDimY、taskDimZ、taskId、taskIdX、taskIdY、taskIdZ。表示Kernel启动task的规模，有XYZ三个维度，用户根据需求进行指定。 ​ 任务调度类型有分为：BLOCK类型（Kernel为单核任务，按单核进行调度）和UNIONx类型（Kernel为多核并行任务，其中x可以为1/2/4，UNION1对应1个cluster4个core） ​ 2. 数据通信 ​ 隐式数据管理：在GPR进行标量数据计算，由编译器隐式插入Load/Store指令。 ​ 显式数据管理：在DRAM/NRAM/WRAM/SRAM间进行向量及张量数据计算。 ​ 3. 同步支持 ​ 提供两者不同类型的同步操作：__sync_all(同步任务执行的所有核)和__sync_cluster(同步一个Cluster内部的所有核)。 ​ 4. 内建运算 ​ 为用户编程提供支持，通用智能编程语言提供并实现了__conv和__mlp等内建函数接口，分别对应卷积和全连接等典型神经网络运算，提高开发效率。 8.3.2.3 运行时支持​ 智能编程模型采用粗粒度的调度策略：以BLOCK/UNIONx为任务调度单位将Kernel中的任务在时间或空间维度展开。BLOCK（单核调度，当有一个核空闲时，调度一个任务执行）、UNION1（调度时需要1个cluster，当有1个cluster空闲时，调度任务执行）、UNION2（调度时需要2个cluster，当有2个cluster空闲时，调度任务执行）。调度单位需要用户指定，运行时只有当空闲硬件资源数大于调度单位时，Kernel才会被调度。 ​ 在智能编程模型中，将执行流的概念抽象为执行队列。队列管理需要执行的任务，队列既可以单独工作，也可以协同工作。 8.4 智能编程语言基础8.4.1 语法概述​ 智能编程语言基于过程式语言，主要原因有二：一是当前大多数语言都是过程式的，可以减少用户学习成本；二是当前主流智能算法可以描述为明确的过程，适合采用过程式语言描述。与经典过程式语言一样，智能编程语言同样具有数据和函数两个基本要素。 8.4.2 数据类型 基本数据类型 长度 说明 int8_t 1 byte 1 字节整数 uint8_t 1 byte 1 字节无符号整数 int16_t 2 byte 2 字节整数 uint16_t 2 byte 2 字节无符号整数 int32_t 4 byte 4 字节整数 uint32_t 4 byte 4 字节无符号整数 half 2 byte 半精度浮点数据类型，采用IEEE-754 fp16格式 float 4 byte IEEE-754 fp32格式浮点类型,目前仅支持类型转换计算 char 1 byte 对应C语言char类型 bool 1 byte 对应C语言bool类型 指针 8 byte 指针类型 8.4.3 宏、常量与内置变量​ 宏/常量由用户定义，内置变量是语言自带的。宏不仅可以定义常量数据，也可定义一段代码；常量是不可修改的数据，只能在初始化时被赋值。内置变量是编程语言本身包含的常量和变量，不需用户定义即可直接使用。 8.4.4 I/O操作语句​ 不同层次的智能处理节点有各自的本地存储，需要提供不同存储层次间的数据搬移。常用数据搬移操作类型如下： ​ ​ 针对上述搬移操作类型，可以在智能编程语言中定义相应的内建函数__memcpy，方便用户进行不同类型的数据搬移。 8.4.5 标量计算语句​ 两种形式：运算符号（如 +，-，* ，/等）和内建函数（如 abs，max，min 等）。 8.4.6 张量计算语句​ 张量计算是智能编程语言的主要特点，可以通过内建函数直 接映射到张量计算单元。常见张量计算语句示例如下： 张量计算语句 具体功能 __vec_add(float* out, float* in1, float* in2， int size) 向量对位加 __vec_sub(float* out, float* in1, float* in2， int size) 向量对位减 __vec_mul(float* out, float* in1, float* in2， int size) 向量对位乘 __conv(half* out, int8* in, int8* weight, half bias, int ci, int hi, int wi, int co, int kh, int kw, int sh, int sw) 卷积运算 __mlp(half* out, int8* in, int8* weight, half* bias, int ci, int co) 全连接运算 __maxpool(half* out, half* in, int ci, int hi, int wi, int kh, int kw, int sh, int sw) 最大池化运算 8.4.7 控制流语句​ 同通用编程语言类似。 8.5 智能应用编程接口8.5.1 Kernel函数接口​ 为了充分利用并行资源，需要在Kernel内部对任务进行有效切分，同时在主机端配置和调用相应的Kernel函数接口。 8.5.2 运行时接口​ 主要包括设备管理、队列管理和内存管理等接口。 设备管理主要涉及初始化、设备设置、设备销毁等操作；队列管理用于管理任务队列；内存管理主要分为主机端内存管理、设备端内存管理和主机与设备端内存拷贝三类。 8.6 智能应用功能调试​ 编程语言功能调试接口：打印函数接口和例外报错（断言机制和核心转储功能） ​ 编程框架功能调试接口：框架应用层的断言和打印机制、框架核心层的日志打印宏和框架适配层的目标架构调试。 8.7 智能应用性能调优​ 性能调优的核心是核心是如何充分利用大规模的并行计算单元。常用性能调优方法有：使用片上存储、张量计算（将大量标量运算合并为张量计算）和多核运行（将一个任务分拆到多个核上并行计算）。性能调优接口有：通知接口（找到耗时长的部分）和硬件性能计数器接口（分析硬件执行特征）。也可以使用性能调优工具，具体有：应用级性能剖析工具和系统级性能监控工具。","link":"/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/%E3%80%8A%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E3%80%8B%E7%AC%AC%E5%85%AB%E7%AB%A0/"},{"title":"WindowsTerminal环境搭建","text":"1.安装 Windows Terminal​ 从 Microsoft Store 搜索下载 2.安装新款 Powershell Core​ 从Powershell Core选择release版本下载 3.安装 Powershell 插件​ 打开刚装好的新版 powershell,，运行以下命令: 12345678# 1. 安装 PSReadline 包，该插件可以让命令行很好用，类似 zshInstall-Module -Name PSReadLine -Scope CurrentUser# 2. 安装 posh-git 包，让你的 git 更好用Install-Module posh-git -Scope CurrentUser# 3. 安装 oh-my-posh 包，让你的命令行更酷炫、优雅Install-Module oh-my-posh -Scope CurrentUser 安装过程可能有点慢，好像卡住了一样，但是请耐心等待几分钟。等不及的同学自行搜索科学方法访问 GitHub. 安装时系统会提问是否继续，不用管它直接输入 A 并回车即可。 4. 配置 Windows Terminal核心步骤：配置setting.json 需要下载字体，有些字体不匹配会出现乱码。 1234567891011121314151617181920212223242526// 默认的配置就是我们的新 powershell（重要！！！）&quot;defaultProfile&quot;: &quot;{574e775e-4f2a-5b96-ac1e-a2962a402336}&quot;,{ // 键标记 &quot;guid&quot;: &quot;{574e775e-4f2a-5b96-ac1e-a2962a402336}&quot;, &quot;name&quot;: &quot;PowerShell Core 7.1.0.5&quot;, // 行为 &quot;closeOnExit&quot;: true, &quot;commandline&quot;: &quot;C:/Program Files/PowerShell/7-preview/pwsh.exe -nologo&quot;, &quot;hidden&quot;: false, &quot;historySize&quot;: 9001, &quot;snapOnInput&quot;: true, &quot;startingDirectory&quot;: &quot;.&quot;, // 外观 &quot;icon&quot;: &quot;D:/Users/newton/Documents/Softwares/software_windows/develop/shell/pwsh.ico&quot;, &quot;acrylicOpacity&quot;: 0.5, &quot;cursorColor&quot;: &quot;#FFFFFF&quot;, &quot;cursorShape&quot;: &quot;bar&quot;, &quot;fontFace&quot;: &quot;JetBrains Mono&quot;, &quot;fontSize&quot;: 11, &quot;padding&quot;: &quot;5, 5, 20, 25&quot;, &quot;useAcrylic&quot;: false, // 颜色主题 &quot;colorScheme&quot;: &quot;Homebrew&quot;}, 同时附上 Homebrew 配色，该配色经过我改良。 123456789101112131415161718192021{ &quot;name&quot;: &quot;Homebrew&quot;, &quot;black&quot;: &quot;#000000&quot;, &quot;red&quot;: &quot;#FC5275&quot;, &quot;green&quot;: &quot;#00a600&quot;, &quot;yellow&quot;: &quot;#999900&quot;, &quot;blue&quot;: &quot;#6666e9&quot;, &quot;purple&quot;: &quot;#b200b2&quot;, &quot;cyan&quot;: &quot;#00a6b2&quot;, &quot;white&quot;: &quot;#bfbfbf&quot;, &quot;brightBlack&quot;: &quot;#666666&quot;, &quot;brightRed&quot;: &quot;#e50000&quot;, &quot;brightGreen&quot;: &quot;#00d900&quot;, &quot;brightYellow&quot;: &quot;#e5e500&quot;, &quot;brightBlue&quot;: &quot;#0000ff&quot;, &quot;brightPurple&quot;: &quot;#e500e5&quot;, &quot;brightCyan&quot;: &quot;#00e5e5&quot;, &quot;brightWhite&quot;: &quot;#e5e5e5&quot;, &quot;background&quot;: &quot;#283033&quot;, &quot;foreground&quot;: &quot;#00ff00&quot;}, 5.添加启动参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#------------------------------- Import Modules BEGIN -------------------------------# 引入 posh-gitImport-Module posh-git# 引入 oh-my-poshImport-Module oh-my-posh# 引入 ps-read-lineImport-Module PSReadLine# 设置 PowerShell 主题# Set-PoshPrompt ysSet-PoshPrompt paradox#------------------------------- Import Modules END -------------------------------#------------------------------- Set Hot-keys BEGIN -------------------------------# 设置预测文本来源为历史记录Set-PSReadLineOption -PredictionSource History# 每次回溯输入历史，光标定位于输入内容末尾Set-PSReadLineOption -HistorySearchCursorMovesToEnd# 设置 Tab 为菜单补全和 IntellisenseSet-PSReadLineKeyHandler -Key &quot;Tab&quot; -Function MenuComplete# 设置 Ctrl+d 为退出 PowerShellSet-PSReadlineKeyHandler -Key &quot;Ctrl+d&quot; -Function ViExit# 设置 Ctrl+z 为撤销Set-PSReadLineKeyHandler -Key &quot;Ctrl+z&quot; -Function Undo# 设置向上键为后向搜索历史记录Set-PSReadLineKeyHandler -Key UpArrow -Function HistorySearchBackward# 设置向下键为前向搜索历史纪录Set-PSReadLineKeyHandler -Key DownArrow -Function HistorySearchForward#------------------------------- Set Hot-keys END -------------------------------#------------------------------- Functions BEGIN -------------------------------# Python 直接执行$env:PATHEXT += &quot;;.py&quot;# 更新系统组件function Update-Packages { # update pip Write-Host &quot;Step 1: 更新 pip&quot; -ForegroundColor Magenta -BackgroundColor Cyan $a = pip list --outdated $num_package = $a.Length - 2 for ($i = 0; $i -lt $num_package; $i++) { $tmp = ($a[2 + $i].Split(&quot; &quot;))[0] pip install -U $tmp } # update TeX Live $CurrentYear = Get-Date -Format yyyy Write-Host &quot;Step 2: 更新 TeX Live&quot; $CurrentYear -ForegroundColor Magenta -BackgroundColor Cyan tlmgr update --self tlmgr update --all # update Chocolotey Write-Host &quot;Step 3: 更新 Chocolatey&quot; -ForegroundColor Magenta -BackgroundColor Cyan choco outdated}#------------------------------- Functions END -------------------------------#------------------------------- Set Alias BEGIN -------------------------------# 1. 编译函数 makefunction MakeThings { nmake.exe $args -nologo}Set-Alias -Name make -Value MakeThings# 2. 更新系统 os-updateSet-Alias -Name os-update -Value Update-Packages# 3. 查看目录 ls &amp; llfunction ListDirectory { (Get-ChildItem).Name Write-Host(&quot;&quot;)}Set-Alias -Name ls -Value ListDirectorySet-Alias -Name ll -Value Get-ChildItem# 4. 打开当前工作目录function OpenCurrentFolder { param ( # 输入要打开的路径 # 用法示例：open C:\\ # 默认路径：当前工作文件夹 $Path = '.' ) Invoke-Item $Path}Set-Alias -Name open -Value OpenCurrentFolder#------------------------------- Set Alias END -------------------------------#------------------------------- Set Network BEGIN -------------------------------# 1. 获取所有 Network Interfacefunction Get-AllNic { Get-NetAdapter | Sort-Object -Property MacAddress}Set-Alias -Name getnic -Value Get-AllNic# 2. 获取 IPv4 关键路由function Get-IPv4Routes { Get-NetRoute -AddressFamily IPv4 | Where-Object -FilterScript {$_.NextHop -ne '0.0.0.0'}}Set-Alias -Name getip -Value Get-IPv4Routes# 3. 获取 IPv6 关键路由function Get-IPv6Routes { Get-NetRoute -AddressFamily IPv6 | Where-Object -FilterScript {$_.NextHop -ne '::'}}Set-Alias -Name getip6 -Value Get-IPv6Routes#------------------------------- Set Network END -------------------------------","link":"/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/windowsterminal%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"FFT算法介绍","text":"快速傅里叶变换(FFT)​ FFT的任务就是将多项式的系数表示法转化为点值表示法，再由点值表示法转化为系数表示法的过程。前面的过程称为求值（DFT），后面的过程称为插值（IDFT）。 ​ 任取n+1个互不相同的$S=\\lbrace p_1,p_2,…,p_{n+1}\\rbrace$,对$f(x)$分别求值后得到$f(p_1),f(p_2),…,f(p_{n+1})$，此时称$A(x)=\\lbrace(p_1,f(p_1)),(p_2,f(p_2)),…,(p_{n+1},f(p_{n+1}))\\rbrace$为多项式f(x)在S下的点值表示法。 ​ 得到一个n次多项式的点值表示法需要代入n+1个数到多项式里面去，如果只是随意选取n+1个，每个数值的计算复杂度为O(n)，那么n+1个数值的计算复杂度将仍然是O(n²)，因此想到了利用奇偶函数的对称性代入，这样计算量就变为了原来的一半，之后不断递归，但由于后续的递归过程如果代入的是实数平方，后续递归将不能进行。由此便引入了复数。通过将n次单位根组成S，记$A_0(x)$为偶次项和，$A_1(x)$为奇次项和：$$A_0(x)=a_0x^0+a_2x^1+…+a_{n-1}x^{\\frac{n}{2}}$$$$A_1(x)=a_1x^0+a_3x^1+…+a_{n-2}x^{\\frac{n}{2}}$$ 于是有$A(\\omega_n^m)=a_0\\omega_n^0+a_1\\omega_n^m+a_2\\omega_n^{2m}+a_3\\omega_n^{3m}+…+a_{n-1}\\omega_n^{(n-1)*m}+a_n\\omega_n^{nm}$ 之后：$A(\\omega_n^m)=A_0((\\omega_n^m)^2)+\\omega_n^mA_1((\\omega_n^m)^2)=A_0(\\omega_\\frac{n}{2}^m)+\\omega_n^mA_1(\\omega_\\frac{n}{2}^m)$ $A(\\omega_n^{m+\\frac{n}{2}})=A_0((\\omega_n^m)^2)+\\omega_n^{m+\\frac{n}{2}}A_1((\\omega_n^m)^2)=A_0(\\omega_\\frac{n}{2}^m)-\\omega_n^mA_1(\\omega_\\frac{n}{2}^m)$ 因此递归的FFT伪代码为： 123456789101112def FFT(A)# A-[a0,a1,...,an-1]n=len(A)if n==1: return AA0,A1=[a0,a2,...,an-2],[a1,a3,...,an-1]a=[0]*nfor i in range(n/2): a[i]=a0[i]+w*a1[i]; a[i+n/2]=a0[i]-w*a1[i] w=w*wnreturn a","link":"/%E7%A1%AC%E4%BB%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8A%A0%E9%80%9F/fft%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D/"},{"title":"硬件加速背景以及卷积神经网络优化","text":"大数据时代的到来，数据呈爆发式增长的态势，深度学习技术不断发展，比如图像识别、语音识别和自然语言处理等。但是这些深度学习技术都有着极为庞大的计算量，对芯片的性能功耗要求很高，现今，比较热门的比如神经网络被广泛应用于人工智能应用之中，而传统的通用芯片再处理复杂神经网络的时候收到了带宽和能耗的限制，因此就推动了人们对深度学习硬件加速器的研究，目前主流的硬件加速器有三类：GPU、ASIC和FPGA。 GPU：与传统CPU不同，GPU的内部拥有大量的逻辑计算单元，远超其中的控制单元和寄存器的规模；GPU拥有一些存储单元可以使得GPU线程之间可以共享这些内存而不依赖于全局内存；GPU拥有相对高速且内存带宽相对较大的全局内存。 ASIC：针对某一个或者某一类算法进行硬件定制，通常来说，相对于其他硬件加速器，ASIC加速深度学习算法能取得较高的性能和功耗，但是其开发周期长，成本高，缺乏灵活性。 FPGA：与其他硬件加速其不同的是FPGA具有可编程性，也就是FPGA内部的逻辑块是可以通过编程进行调整的，因此灵活性较高，并且也拥有不错的性能和较低的功耗。现阶段，GPU更适合深度学习算法的训练阶段，FPGA更适合深度学习算法的推理阶段。 ​ 当前还有许多关于神经网络专用加速器的研究，一类是基于冯诺依曼体系结构下的加速器，其设计的重点就是如何平衡片上片外的数据分配，最小化数据的搬移。在运算单元结构设计中，如DianNao，DaDianNao采用了NFU结构作为加速器的基本处理单元，很好地支持了神经网络的计算。又有Google TPU所采用的脉动整列结构，让数据在运算单元的整列中流动了起来，增加了数据的复用，减少了访存次数；在存储结构的设计中，比如分块存储，双缓冲等，又因为传统2D存储结构的DDR技术的带宽已经不能适应现在神经网络的规模，人们将3D存储技术也加入到了神经网络加速器的设计之中。另一类是采用忆阻器等新器件来设计处理存储一体化的加速器。它本身具有存储数据的功能，另外利用基尔霍夫定律产生的位线电流就是卷积运算乘累加的结果，节省了乘法和累加的计算时间。 ​ 前面讲了体系结构方面专用芯片对神经网络的支持，在数据流调度的过程中，神经网络中常用的数据流有权重固定流、输出固定流、无局部复用和行固定流，常用的数据流优化处理手段有0值跳过、稀疏矩阵、参数压缩等。 ​ 接下来介绍卷积神经网络，卷积神经网络由于其大部分的计算都是卷积操作，而卷积层包含的是大量的乘加运算，因此利用FPGA加速神经网络的工作性能都受限于片上数字处理单元（DSP）的数量。因此如何提高DSP的利用率，有如下四种实现卷积操作的算法： 非快速算法 空间卷积算法：易于实现，可以很快地部署到CPU、GPU上执行，计算公式为：$$Out(o,p,q)=\\sum_{c&lt;C,i&lt;K,j&lt;L}F(o,c,i,j)\\times In(c,p\\times st_r+i-pad,q\\times st_c+j-pad)$$其中In为输入数据（三维张量），其第一维是通道数 C, 第二维是图片高度 H, 第三维是图片宽度 W。F 对应着卷积层中的 Filter（四维），O 表示 输出通道数, C 表示输入通道数, K 为 Filter 高度, L 为 Filter 宽度。另外的输入 str,stc, pad 分别为 Filter 的沿高度方向滑动距离与沿宽度方向滑动距离以及边界处补全长度。 通用矩阵乘法算法（GEMM）：主要就是利用现今成熟的矩阵乘法程序完成卷积操作，前面的学习中有涉及过，此处不作赘述。 快速算法：非快速算法中输出特征图中的每个元素被单独计算，而快速算法在运算过程中对输入的局部元素同时计算。快速算法可分为三个步骤：（1）输入块与卷积核变换（2）点对点乘法（3）逆变换 FFT算法:可以使运算复杂度从 O(N²) 减少到 O(NlogN) 的复数乘法, 且不会出现精度损失。 Winograd算法 ​ 如今卷积神经网络的规模日益庞大, 而大量应用场景都无法提供相应的必需资源，现在也有许多卷积神经网络结构优化的研究。 网络剪枝与稀疏化 下表是不同网络剪枝后的效果，不难发现网络剪枝极大地减少了参数量，并且对精度的影响微乎其微。 张量分解 将原始张量分解为若干低秩张量，从而减少卷积操作数量。然而目前大多数的张量分解方法都是逐层分解网络，缺乏整体性的考虑, 有可能导致不同隐含层之间的信息损失。并且涉及矩阵分解操作，需要花费高昂的计算资源。 知识迁移 过程如图所示，简单来说就是将没有标签的数据经过教师网络进行预测，人工合成为有标签的数据交给学生网络进行训练。这样就可以使得学生网络具有与教师网络相当的性能，但是参数数量大幅降低。 精细模块设计 Inception模块 如将5×5卷积分解为两个3×3卷积，下图可以证明替换的有效性，并且只需原来花费（3*3+3*3）/5*5=72%的计算开销。 1×1卷积可以减少神经网络的参数量，还可以压缩通道数，提高计算效率。 网中网（Network in network） 一种区别于广义线性模型的非线性结构—Mlpconv, 即在卷积核后面添加一个多层感知机。增强了网络对局部感知野的特征辨识能力和非线性表达能力。通过堆叠Mlpconv层构建出的网络被称为网中网。 残差模块 与高速网络不同，残差网络的门限机制不是可学习的，而是恒定的，始终保持信息畅通状态，大幅降低了网络复杂度，加速了网络训练速度。","link":"/%E7%A1%AC%E4%BB%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8A%A0%E9%80%9F/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E8%83%8C%E6%99%AF%E4%BB%A5%E5%8F%8A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/"},{"title":"轻量级神经网络架构","text":"1. 人工设计的轻量级神经网络模型1.1 使用小卷积核代替大卷积​ 使用多层小卷积核代替一层大卷积核，可以减少网络的参数。如图所示： 例如使用两层3×3的卷积核代替5×5的卷积核，其卷积核的参数量可以从25减少到18，对于输入大小为 H×W×Cin 的特征,输出为 H×W×Cout 大小的特征图时，其浮点运算数从H×W×Cin×Cout×5²减少到了2×H×W×Cin×Cout×3。对于图b使用1×3核3×1的卷积核代替3×3的卷积核，可以使得参数量减少为原来的1/3。 1.2 限制中间特征的通道数量​ Fire model:《SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE》 ​ 如图，核心思想就是通过许多的fire model模块替代原来的conv+pool，具体包含两个部分：压缩(squeeze)层和扩张(expand)层。其中的squeeze层是卷积核为1×1的卷积层，后面的expand层是由1×1以及3×3的两个卷积层共同构成的。 1.3 分解卷积运算​ 例如利用深度可分离卷积对Mobile V1的标准卷积进行分解。标准卷积的计算量为$D_k×D_k×M×N×H×W$,而深度可分离卷积的计算量为$D_k×D_k×M×H×W+ M×N×H×W$,计算量大幅缩小 ​ 还有一些其他的卷积分解操作见https://blog.csdn.net/weixin_40004659/article/details/111637585。 2. 卷积神经网络的压缩算法2.1 基于规则的神经网络模型压缩 权重裁剪 权重量化 低秩分解 知识蒸馏 2.2 基于自动机器学习的自动神经网络模型压缩​ 通过设计一系列的控制器操作机器学习模型,使得模型可以自动地学习到合适的参数和网络架构而不需人工的干预,减少对专业知识和领域知识的要求,从而降低设计机器学习算法的难度。 ​ 以AMC算法（AMC: AutoML for Model Compression and Acceleration on Mobile Devices）为例，与传统的在离散空间上进行搜索不同，AMC算法采用 DDPC代理的连续压缩比控制策略，通过优化损失函数学习模型压缩策略。特别地, DDPC代理以分层的方式处理神经网络，对于每一层 Lt，代理接受编码该层的有用特征 St，然后输出精确压缩比。第 Lt 层压缩完成后，代理移动到下一层 Lt+1，在没有微调的情况下，对压缩后的神经网络中的所有层的精度进行评估。 AMC模型通过强化学习算法来训练代理，实现动作的预测并计算稀疏性，执行压缩。同时快速评估压缩后的模型性能，通过优化损失函数更新代理。 3. 基于神经网络架构搜索的自动化轻量级神经网络设计​ 神经网络架构搜索（NAS）是指根据某种搜索策略，在特定的搜索空间内，自动设计出解决特定任务的高性能神经网络架构。 ​ NAS由三部分组成，分别是搜索空间、搜索策略和性能评估策略。 搜索空间：定义了构建神经网络的基本架构单元，将适合该任务的典型网络架构作为先验知识，从而减少搜索空间的大小（该过程可能会引入人为因素，从而收到干扰）。 搜索策略：决定如何搜索用于解决该任务的神经网络架构，并决定网络中不同层，不同模块的连接方式和参数。 性能评估策略：准确高效地评价神经网络的性能。 ​ 如图为神经网络搜索的流程图，搜索策略从搜索空间中选择神经网络架构A，通过性能评估策略评价神经网络架构的性能，作为奖励反馈给搜索策略，搜索策略根据接收到的奖励调整神经网络架构，通过不断的迭代，最终获得最佳的神经网络架构。","link":"/%E7%A1%AC%E4%BB%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8A%A0%E9%80%9F/%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"title":"《神经网络与深度学习》循环随机网络部分","text":"基于门控的循环神经网络长短期记忆网络(LSTM)​ 这个部分主要就是理解如下图所示的循环单元结构： 图中有三个门，分别是输入门${i}_t$，遗忘门${f}_t$和输出门${o}t$。其计算过程为：1）首先利用上一 时刻的外部状态${h}{t-1}$ 和当前时刻的输入${x}_t$，计算出三个门，以及候选状态${\\widetilde{c}}_t$；2） 结合遗忘门 ${f}_t$ 和输入门${i}_t$来更新记忆单元${c}_t$；3）结合输出门${o}_t$，将内部状态的信息传递给外部状态${h}_t$．（根据谷歌的测试表明，LSTM中对学习贡献较大的是Forget gate，其次是Input gate，最次是Output gate） LSTM网络的各种变体 无遗忘门的LSTM网络 内部状态更新方式为：$$c_t=c_{t-1}+i_{t}\\odot\\widetilde{c}_t$$ peephole连接 使三个门不但依赖于输入${x}t$和上一时刻的隐状态${h}{t-1}$，也依赖于上一个时刻的记忆单元${c}_{t-1}$。 耦合输入门和遗忘门 将LSTM网络中的输入门和遗忘门合并为一个门，内部状态更新方式为：$$c_t=(1-{i}t)\\odot{c}{t-1}+i_{t}\\odot\\widetilde{c}_t$$ 门控循环单元网络(GRU)​ 如图所示： ​ GRU的输入输出结构和普通的RNN相同，都是一个当前的输入$x_t$和上一时刻传下来的隐状态$h_{t-1}$，通过GRU得到输出$y_t$和要传给下一时刻的隐状态$h_t$。 ​ 与LSTM不同的是，GRU只有两个门控，分别为重置门（Reset Gate）和更新门（Update Gate）。$$\\pmb{r}_t=\\sigma(\\pmb{W}_r\\pmb{x}_t+\\pmb{U}r\\pmb{h}{t-1}+\\pmb{b}_r)$$ $$\\pmb{z}_t=\\sigma(\\pmb{W}_z\\pmb{x}_t+\\pmb{U}z\\pmb{h}{t-1}+\\pmb{b}_z)$$ ​ GRU工作的整个流程就是： ​ （1）得到门控信号后，首先通过重置门控来得到重置之后的信息，即：$$\\pmb{h}{t-1}’=\\pmb{h}{t-1}\\odot \\pmb{r}t$$再将$\\pmb{h}{t-1}’$与输入$\\pmb{x}_t$拼接，再通过一个tanh激活函数将数据缩放到-1~1的范围，得到$\\widetilde{\\pmb{h}}_t$，即：$$\\widetilde{\\pmb{h}}_t=\\tanh(\\pmb{W}_h\\pmb{x}_t+\\pmb{U}h\\pmb{h}{t-1}’+\\pmb{b}_h)$$​ （2）更新记忆：这个阶段我们同时继续了遗忘和记忆两个步骤。通过更新门来控制当前状态需要从历史状态中保留多少信息（不经过非线性变换），以及需要从候选状态中接受多少新信息，即：$$\\pmb{h}_t=\\pmb{z}t\\odot \\pmb{h}{t-1}+(1-\\pmb{z}_t)\\odot \\widetilde{\\pmb{h}}_t$$这里便是与LSTM不一样的地方，LSTM使用两个门控来进行遗忘和记忆，而GRU只需要一个门控即可完成。不难看出，当$\\pmb{z}_t=0,\\pmb{r}_t=1$时，GRU网络退化为简单循环网络；若$\\pmb{z}_t=0,\\pmb{r}_t=0$ 时，当前状态$\\pmb{h}_t$只和当前输入$\\pmb{x}t$相关，和历史状态$\\pmb{h}{t-1}$无关．当$\\pmb{z}t=1$时，当前状态$\\pmb{h}t=\\pmb{h}{t-1}$等于上一时刻状态$\\pmb{h}{t-1}$，和当前输入$\\pmb{x}_t$无关。 ​ 由于GRU与LSTM的实验效果相似，但是GRU的参数量比LSTM更少，所以一般情况下模型都会选择GRU，这样收敛速度更快，可以快速迭代。 深层循环神经网络堆叠循环神经网络​ 将多个循环网络堆叠起来，从不同时刻的角度来看，这个神经网络是很深的，从同一时刻输入到输出的角度来看，这个神经网络又是很浅的，如图所示： 双向循环神经网络​ 如图所示，有时间顺序和时间逆序两个序列，某一个时刻的输出不但和过去时刻的信息有关，也和后续时刻的信息有关。 扩展到图结构递归神经网络​ 如图所示： ​ 递归神经网络就是一个树状的参差结构，当递归神经网络的每个父节点都仅与一个子节点连接时，就退化成一个简单循环神经网络。 图神经网络A Comprehensive Survey on Graph Neural Networks 图卷积网络（Graph Convolution Networks，GCN） 基于谱（Spectral-based） 基于空间（spatial-based） 图注意力网络（Graph Attention Networks） 图自编码器（ Graph Autoencoders） 图生成网络（ Graph Generative Networks） 图时空网络（Graph Spatial-temporal Networks）","link":"/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E5%BE%AA%E7%8E%AF%E9%9A%8F%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%83%A8%E5%88%86/"},{"title":"《神经网络与深度学习》第2-3章","text":"为什么平方损失函数不适用于分类问题？​ 在Softmax激活函数的作用下，使用平方损失函数，随着实际值与预测值的绝对误差的不断增大，梯度反而会不断减小，这就使得调整参数的速度减慢，不利于快速收敛。 如何理解最小二乘法与最大似然估计？​ ​ 如图所示，线性回归中我们的任务是找到一条直线来拟合图中的这些样本点，现实中，样本点的维数是不会只有1维的，可以是多个维度，所以我们令样本的维数为p，则有如下两个向量：$$x_i=\\left[ \\begin{matrix} 1 \\ x_{i1} \\ x_{i2} \\ x_{i3} \\ \\vdots \\ x_{ip} \\end{matrix} \\right] \\space\\space\\space w=\\left[ \\begin{matrix} w_0 \\ w_1 \\ w_2 \\ w_3 \\ \\vdots \\ w_{p} \\end{matrix} \\right]$$这里将偏置$b$记为$w_0$，所以最终的映射关系就写为$y=w^Tx$. 在最小二乘法中，我们定义了如下的损失函数：$$L(W)=\\sum_{i=1}^{N}|w^Tx_i-y_i|^2$$其目标就是要找到一组向量$w$，使得最终拟合出来预测值与真实值之间的误差的平方最小，由此得出最佳的拟合结果。 ​ 以上面图的例子为例，我们是否可以找到一条直线让其精准地通过图上所有的样本点，显然这是不可能的。样本数据本身是带有噪声的，也就是带有随机性，所以这就造成了样本点都围绕着直线的上下，而其中的误差便是噪声，也是随机性。这里就引入了高斯噪声，我们令噪声$\\epsilon$服从均值为0，方差为$\\sigma^2$的一维高斯分布，此时$$\\epsilon \\sim N(0,\\sigma^2)$$于是有$$y=w^Tx+\\epsilon$$此时$$y \\sim N(w^Tx,\\sigma^2)$$写成概率密度的形式为$$p(y|x;w)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\lbrace-\\frac{(y-w^Tx)^2}{2\\sigma^2}\\rbrace$$于是对于N个独立同分布的训练集D，我们利用极大似然估计去估计参数$w$。 接下来解释一下什么是极大似然估计，通俗地讲就是根据既定事实去推断参数，极大似然函数就是关于参数的函数，极大似然估计就是找到能够符合当前事实概率最大的参数。 参数$w$在训练集D上的对数似然函数为$$L(w)=log\\prod_{i=1}^{N}p(y_i|x_i;w)=\\sum_{i=1}^Nlogp(y_i|x_i;w)$$目标是指找到一组参数𝒘使得似然函数 𝑝(𝒚|𝑿; 𝒘) 最大，也就是使得对数似然函数最大。 ​ 最终待估计的蚕食$w$的极大似然估计值是：$$w_{mle}=argmax_u\\sum_{i=1}^N(log\\frac{1}{\\sqrt{2\\pi}\\sigma}-\\frac{(y_i-w^Tx_i)^2}{2\\sigma^2})$$去掉与$w$无关的常数项，最终得到：$$w_{mle}=argmax_u\\sum_{i=1}^{N}-(y_i-w^Tx_i)^2=argmin_u\\sum_{i=1}^{N}(y_i-w^Tx_i)^2$$由此便得到了最小二乘法的定义式，上式化简可以得到$$L(w)=(w^TX^T-Y^T)(Xw-Y)=w^TX^TXw-2w^TX^TY+Y^TY$$对$w$求偏导，令$$\\frac{\\partial}{\\partial w}L(w)=\\frac{\\partial}{\\partial w}(w^TX^TXw-2w^TX^TY+Y^TY)=2X^TXw-2X^TY=0$$得到：$X^TXw=X^TY$,从而有$w=(X^TX)^{-1}X^TY$ 这里让我想到一个问题，如开始的图中所示，看到这样的样本数据分布，确实第一个想到的就是线性回归模型，样本数据在拟合的直线上下波动，我们可以假定为噪声的影响，但并非所有的场景线性回归模型都适合，如何样本数据分布近似一条曲线，我们却用线性回归模型去训练，最终得出的也是样本点在直线上下波动，当然此时的波动就大了，显然我们不可以将这些误差全然视为噪声，此时我们可以选择使用别的模型，例如多项式回归模型，从理论上来说，通过泰勒定理，任何函数都可以通过泰勒级数逼近。 线性回归模型为什么不适合分类问题？​ 首先线性回归模型并非不能用于分类问题，最小化平方损失函数本质上等同于在误差服从高斯分布下的极大似然估计，这个在前面已经得到证明，对于一些分类任务，只需要设置一个合适的阈值就可以进行分类，但是大部分分类任务的误差并不服从高斯分布，使用线性回归模型稳定性很差，在样本分布较为复杂时，无法进行准确分类。 ​ 如下图所示的二分类问题，我们可以使用线性函数去解决分类问题，真实值只有两个可能的值，即0和1，我们当然可以人为设置当x满足使得y=0.5x+0.53大于0.53时，则预测值为1，当小于0.53时，则预测值为0来完成分类任务，但这也仅仅适合分布较为简单的情况。同样，我们可以使用激活函数，图中所示为sigmod函数（函数平滑，并且有利于求导），将线性回归预测值压缩到（0，1）之间，以此表示预测标签的概率，图中我们可以选取0.5为分界线，当概率大于0.5，我们认为预测值为1，当概率小于0.5，我们认为预测值为0，当前分界线可以认为设定，对于高可靠性的任务场景，我们可以将分界线设置地较高，以满足任务需求。","link":"/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%AC2-3%E7%AB%A0/"},{"title":"《神经网络与深度学习》第7章","text":"高维变量的非凸优化​ 之前我们遇到的问题都是使用梯度下降法会陷入局部最优点无法逃离，事实上这只是在低维空间中，现在的多数机器学习任务都是在高维空间中的，并且遇到的大多数都是鞍点，因此，非凸优化的难点并不在于如何逃离局部最优点，而是如何逃离鞍点，如图所示： 从数学上解释鞍点很简单，鞍点的特征是一阶梯度为0，但 是二阶梯度的 Hessian 矩阵不是半正定矩阵，如图，在二维空间中，这只是一条曲线，显然这个时候已经到达了最低点，而在三维空间中这显然没有到达最低点。 ​ 对比于局部最优点来说，鞍点并不可怕，相反，我们更希望的是遇到鞍点。如何逃离鞍点呢？现在我们将损失函数$L(\\theta)$​泰勒展开：$$L(\\theta)\\approx L(\\theta’)+(\\theta-\\theta’)^Tg+\\frac{1}{2}(\\theta-\\theta’)^TH(\\theta-\\theta’)$$如果我们今天走到的是局部最优点，那么梯度g=0，于是上述公式便可以化简为：$$L(\\theta)\\approx L(\\theta’)+\\frac{1}{2}(\\theta-\\theta’)^TH(\\theta-\\theta’)$$我们记$(\\theta-\\theta’)$为$\\pmb{v}$，$H$​为 Hessian 矩阵. 对于所有的$\\pmb{v}$​​，现有三种情况： $\\pmb{v}^TH\\pmb{v}&gt;0$​​​，可以得到$L(\\theta)&gt;L(\\theta’)$​，那么就是局部最低点。等价于$H$是正定矩阵（特征值都是正的）。​ $\\pmb{v}^TH\\pmb{v}&lt;0$，可以得到$L(\\theta)&lt;L(\\theta’)$，那么就是局部最高点。等价于$H$是负定矩阵（特征值都是负的）。 $\\exists\\pmb{v}^TH\\pmb{v}&gt;0,\\exists\\pmb{v}^TH\\pmb{v}&lt;0$​​​,​那么就是鞍点。（特征值有正有负） 对于局部最优点，g=0，我们无法获知下一步参数更新方向，而对于鞍点，$H$可以告知我们下一步走参数更新方向。 现在记$\\mu$​​​为H的特征向量，$\\lambda$​​​为H的特征值，并且$(\\theta-\\theta’)$​代入的就是$\\mu$，​则有$\\mu^TH\\mu=\\mu^T(\\lambda\\mu)=\\lambda|\\mu|^2$​​​. 如果$\\lambda&lt;0$，那么$\\lambda|\\mu|^2&lt;0$，于是有$L(\\theta)&lt;L(\\theta’)$​​. 此时$\\theta-\\theta’=\\mu\\Rightarrow\\theta=\\theta’+\\mu$，这时就可以减小L，也就是让$\\theta$沿着特征值$\\mu$的方向去更新，就可以降低损失。 为什么要批量训练？​ 如图所示，左边相当于没有使用批量训练，需要看过所有的训练资料再进行参数更新，右边每看过一个训练资料便进行参数更新。所以，哪个方法比较好呢？看起来左边的更新方向比较“稳”，而右边的更新方向较为“曲折”，并且左边更新一次参数的时间远远大于右边，但事实并不是这样。 ​ 由于并行运算的存在，比较大的batch size更新一次参数的时间并不一定比小的batch size更新一次参数的时间长，如下图所示，小的batch size和大的batch size每次更新参数花费的时间几乎差不多，除非size超过了并行运算的极限，时间才会倍数增加。由于这样的原因，小的batch size跑完一个epoch所花费的时间将远远大于使用大的batch size跑完一个epoch所花费的时间。 ​ 讨论到这里，我们发现使用大的batch size不仅参数更新方向更为稳定，并且花费的时间也较少，那么是否大的batch size比小的batch size好呢？事实反而相反，如下图所示： ​ 这里可以看到，batch size越大，模型的准确性反而在降低，为什么？ 如图，如果我们选择full batch，也就是不使用批量下降，那么如果我们的损失函数遇到局部最优点，那么很可能发生的情况就是模型无法训练下去，陷在了局部最优点上，而如果我们选择批量下降，那每个bacth的损失函数可能略有差异，于是即使在L1上陷入了局部最优点 ，也可以在L2上走出来。 《ON LARGE-BATCH TRAINING FOR DEEP LEARNING: GENERALIZATION GAP AND SHARP MINIMA》 从上面两个表中可以得出：即使是将使用large batch和small batch的模型在训练集上的准确率训练得差不多，但是使用large batch和small batch的模型在测试集上的表现却不相同，很明显，使用small batch的模型在测试集上的表现更好。 why?如图，文中给出的解释是： 在训练集和测试集上LOSS函数的差异如图，Sharp Minimum在训练集和测试集上的表现会相差很大，而Flat Minimum在训练集和测试集上的表现不会相差很大，使用small batch size趋向于走向Flat Minimum，而使用large batch size趋向于走向Sharp Minimum。 ​ 当然batch size也是一个超参数，同样需要自己的调整，并且现在也有相关技术可以同时兼得large batch size训练快，small batch size训练表现好的优点，具体可以参考比如LARGE BATCH OPTIMIZATION FOR DEEP LEARNING: TRAINING BERT IN 76 MINUTES","link":"/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%AC7%E7%AB%A0/"},{"title":"《神经网络与深度学习》第8章","text":"8.4 人脑中的记忆​ 这个部分主要讲了生物神经网络中人脑记忆的特性。其中人脑记忆的一个特点就是记忆一般分为长期记忆和短期记忆。长期记忆体现为神经元之间的连接形态，更新速度比较慢，因此长期记忆可以类比于人工神经网络中的权重参数；短期记忆体现为神经元的活动，更新较快，可以类比于人工神经网络中的隐状态。 ​ 除此以外，人脑中还存在一个缓存，称为工作记忆，工作记忆是一个临时存储和处理系统，类似计算机的存储系统。 ​ 其次是联想记忆，联想记忆就是根据一种事物会想到其他与之有关系的事物。在计算机中，联想记忆是指一种可以通过内容匹配的方法进行寻址的信息存储方式。 ​ 之前介绍的LSTM（长短期记忆网络），其中的记忆单元可以类比于计算机中的寄存器，而外部记忆可以类比于计算机中的内存单元。 ​ 借鉴人脑中的工作记忆，于是在神经网络中引入了一个外部记忆单元来提高网络的容量。这种装备外部记忆的神经网络称为记忆增强神经网络。 8.5 记忆增强神经网络​ 记忆网络的典型结构如图所示： ​ 主网络(控制器)C：负责信息处理以及通过读写模块与外界进行交互。 ​ 外部记忆单元M：用来存储信息，一般分为很多个记忆片段，记忆片段用一组向量M表示，形如：$\\pmb{M}=[\\pmb{m_1},…,\\pmb{m_N}]$​​。 ​ 读写模块（RW）：读取模块根据主网络生成查询向量$q_r$​​​，从外部记忆单元M中读取相应信息$r=R(M,q_r)$​​​，写入模块根据主网络生成查询向量$q_w$​​​和要写入的信息$a$​​​来更新外部记忆$M=W(M,q_w,a)$​​​ ​ ​ 这里实现要实现联想记忆功能，就需要按内容寻址进行定位，按内容寻址通常需要注意力机制来进行。 ​ 比如读取模型R的是实现方式为：$$\\begin{align*}&amp;\\pmb{r}=\\sum_{n=1}^N\\alpha_n\\pmb{m}_n\\&amp;\\alpha_n=softmax(s(\\pmb{m}_n,\\pmb{q}_r))\\end{align*}$$​ 注意力机制的计算可以分为两步：一是在所有输入信息上计算注意力分布(也就是$\\alpha_n$)，二是根据注意力分布来计算输入信息的加权平均(也就是$\\pmb{r}$)。 ​ 这边的$s(\\pmb{m}_n,\\pmb{q}_r)$​​是注意力打分函数，用来计算每个输入向量和查询向量之间的相关性。类比于人类，就是说人可以在面对一堆信息时，可以选择关注一些信息，并且忽略另一些信息。 ​ 然后$m_n$​​根据其所得分数$\\alpha_n$​进行加权平均，对输入的信息进行汇总，这就是软性注意力机制。 8.5.1 端到端记忆网络​ 首先将需要存储的信息(一组向量)$m_{1:N}={m_1,…,m_N}$​​划分成两个记忆片段$A=[a_1,…,a_N]$​​和$C=[c_1,…,c_N]$​​​​ ​ 主网络根据输入$\\pmb{x}$生成$\\pmb{q}$（即查询向量），并使用键值对注意力机制来从外部记忆中读取相关信息$\\pmb{r}$​。 ​ 这里使用键值对机制，那么A就相当于Key，C就相当于Value，他们是一一对应的。再看公式：$$\\pmb{r}=\\sum_{n=1}^Nsoftmax(\\pmb{a}^T_n\\pmb{q})\\pmb{c}_n$$​ 首先就是根据$\\pmb{q}$​和A（就是KEY）计算二者的相似度，也就是注意力的得分，再通过softmax函数对注意力得分进行数值转换，然后根据对应的权重系数对C（就是Value）进行加权求和。 整个过程如图所示： ​ ​ 接下来是多跳操作，其实就是让上述过程多进行几次，在第k轮交互中，主网络根据上次从外部记忆中读取的信息$r^{(k-1)}$​，产生新的查询向量$$\\pmb{q}^{(k)}=\\pmb{r}^{(k-1)}+\\pmb{q}^{(k-1)}$$​ 第k轮交互后，主网络从外部记忆读取的信息应该为：$$\\pmb{r}^{(k)}=\\sum_{n=1}^Nsoftmax((\\pmb{a}_n^{(k)})^T\\pmb{q}^{(k)})\\pmb{c}_n^{(k)}$$​ 用图表示就是下面这个过程（用前一次所得到信息r产生新的查询向量q）： 8.5.2 神经图灵机​ 首先是图灵机，图灵机是一种抽象的数学模型，可以用来模拟任何可计算问题。 ​ 从图中可以看出，图灵机主要由三个部分组成： ​ （1）首先是一条无限长的纸带，类似于计算机的内存，里面的一个个方格子可以存储数字，符号。 ​ （2）然后是读写头，它可以做到从方格里读出数据，可以写入数据到方格里，也可以左右移动方格。 ​ （3）最后是控制器，它可以根据机器指定的规则，决定读写头每一步的动作。 ​ 然后是神经图灵机，直接看图： ​ ​ 它的主要过程就是通过控制器接收当前时刻的输入$\\pmb{x}t$、上一时刻的输出$\\pmb{h}{t-1}$和上一时刻从外部记忆读取的信息$\\pmb{r}_{t-1}$,然后产生输出$\\pmb{h}_t$。 ​ 同时，生成和读写外部记忆相关的三个向量：查询向量$\\pmb{q}_t$、删除向量$\\pmb{e}_t$和增加向量$\\pmb{a}_t$，通过这三个向量对外部记忆$\\pmb{M}_t$进行读写操作，同时生成新的读向量$\\pmb{r}t$和新的外部记忆$\\pmb{M}{t+1}$​。 ​ 这里的读操作和上面介绍的一样，通过注意力机制来进行基于内容的寻址，写操作则是分为两步：删除操作是根据注意力分布$\\alpha_{t,n}$(t时刻的第n个记忆片段的得分)来按比例地在每个记忆片段中删除$\\pmb{e}_t$，增加操作是根据注意力分布来按比例地给每个记忆片段加入$\\pmb{a}_t$​。 ​ 具体过程如下：$$\\pmb{m}{t+1,n}=\\pmb{m}{t,n}(1-\\alpha_{t,n}\\pmb{e}t)+\\alpha{t,n}\\pmb{a}_t$$​ 从前半部分删除需要删除的部分，从后半部分增加需要增加的。 8.6 基于神经动力学的联想记忆​ 这个部分主要介绍一个经典的联想记忆模型Hopfield网络，与我们之前所学习的神经网络模型不同，之前我们所学习的神经网络都是作为机器学习模型的一个输入-输出的映射函数，而这里是作为一种记忆的存储和检索模型。 ​ 它的结构如图所示： ​ ​ Hopfield网络是一种循环神经网络网络模型，也可以理解为一种递归网络模型，它只有一层，并且所有神经元都互相连接，但和自身没有反馈连接，每个神经元既是输入单元也是输出单元，不同神经元之间的连接权重是对称的。 ​ 用公式来表示就是：$$\\begin{align*}&amp;w_{ii}=0 \\qquad\\forall i\\in[1,M] \\&amp;w_{ij}=w_{ji}\\quad,\\forall i\\in[1,M]\\end{align*}$$​ 第i个神经元的更新规则为（这里介绍的是离散Hopfield网络，也就是神经元的状态只有两种，+1和-1，分别表示神经元处于激活或者抑制的状态）： ​ Hopfield网络的更新方式有异步和同步两种方式，异步更新就是每次只更新一个神经元，同步更新就是一次更新所有的神经元。 ​ 比如四个节点的Hopfield网络，要更新$s_1$，通过公式就是先计算$w_{11}s_1+w_{12}s_2+w_{13}s_3+w_{14}s_4+b_1$，看这个结果是否是大于等于0的，如果是，那么$s_1=1$，如果不是，那么$s_1=-1$​。然后这个$s_1$又成为下一时刻的输入。 ​ 那么Hopfield网络是怎么工作的，比如现在给定$s(0)=[s_1(0),s_2(0),…,s_n(0)]^T$，将这个称为初态，那么经过Hopfield不断的更新，发现:$$\\lim_{k\\rightarrow\\infty}s(k)$$不再改变，这个时候就进入了稳态。这个过程也就是Hopfield的价值所在。打个比方，你在大街上看见了一个人，你发现这人很眼熟，那么这开始的输入便是初态，经过你大脑的不断回想，你发现他是那个小学同学某某某，最后在你脑海的是他小学时候的那个样子，那这最后的结果便是稳态。同样也可以类比找极值的过程，刚开始所得到的值是初态，最后不断求解，最终得到了极值，也就是稳态。 ​ 所以初态其实就是记忆样本的部分信息，而稳态就是记忆样本，hopfield通过部分样本信息不断联想，最终得到完整的样本信息。 ​ 如何定义网络的稳定性？看下面这个图，图a网络从初态在有限次递归后其状态不再发生变化，就是说网络可以任一初态收敛到一个稳态，则该网络是稳定的；图b和图c网络都是不稳定的，因为是离散网络（只有1和-1两种情况），所以不管怎么发散，网络都不可能无限发散，图b是有限环网络（网络在有限的幅度内振荡），图c的现象称为混沌，它的变化状态既不重复也不停止，状态变化又无穷多个。 于是在Hopfield网络中稳定性指的是，从某一时刻开始，网络中的所有神经元状态不再改变，那么这个时候网络就是稳定的，并且这个稳定状态被称为网络的吸引子。如果把吸引子视为整个问题的解，那么从初态朝吸引子演变的过程就是求解计算的过程，如果把需要记忆的样本信息存储在不同的吸引子上，当输入含有部分记忆信息的样本时，整个网络的演变过程就是从部分信息寻找全部信息，即联想回忆的过程。 ​ 那么Hopfield如何保证网络的稳定性，也就是不管我输入的是什么，我总能收敛到一个吸引子。 ​ 这里借助Lyapunov 定理（李雅普诺夫）得到两个定理，分别是： ​ 定理1：对于DHNN网络（也就是离散Hopfield网络），若按异步方式调整网络状态，且连接权矩阵W为对称阵，则对于任意初态，网络最终收敛到一个吸引子。 ​ 定理2：对于DHNN网，若按同步方式调整状态，且连接权矩阵W为非负定对称阵，则对于任意初态，网络最终收敛到一个吸引子。 ​ 这里给出证明过程（异步方式），同步方式证明方法是类似的： ​ 书中给了能量函数的图片，展示了网络的演化方向： ​ ​ 这个图也很明显的表现出来离散Hopfield网络的局限性，就是当记忆样本较接近时，网络不能始终回忆出正确的记忆。 ​ 接下来通过一个二分类问题展示Hopfield网络的应用，任务就是识别出是橘子还是苹果。通过传感器采集水果的特征，这里只采集三个维度（外形，质地，重量），看下面这个表格： 1 0 外形 圆形 椭圆形 质地 光滑 粗糙 重量 &lt;200g &gt;200g ​ 标准的橘子：$x^{(1)}=[1\\quad 0 \\quad1]^T$，标准的苹果$x^{(2)}=[0\\quad 1 \\quad0]^T$ ​ 第一步：设计Hopfield网络的结构，因为有三个特征，所以用三个神经元，如图 ​ 第二步：设计连接权矩阵，采用外积法，这里阈值设为0，也就是前面公式中的bi，并且$w_{ij}=w_{ji}$$$w_{ij}=\\begin{cases} \\sum_{l=1}^2(2x_i^{(l)}-1)(2x_j^{(l)}-1)\\quad i\\neq j\\\\qquad \\qquad \\qquad0 \\qquad\\qquad,,,\\quad i=j\\end{cases}$$ 比如我们计算$w_{12}=(2x_1^{(1)}-1)(2x_2^{(1)}-1)+(2x_1^{(2)}-1)(2x_2^{(2)}-1)=-1-1=-2=w_{21}$，最后计算得到权重矩阵$$W=\\left[\\begin{matrix}0 &amp; -2 &amp; 2\\ -2 &amp; 0 &amp; -2\\ 2 &amp; -2 &amp; 0\\\\end{matrix}\\right]$$​ 第三步：测试，输入$[1\\quad 1 \\quad1]^T$，初始状态：$$\\begin{cases}x_1(0)=1\\x_2(0)=1\\x_3(0)=1\\\\end{cases}$$​ 采用异步方式，设置更新次序为2-&gt;1-&gt;3，那么t=1时$$\\begin{align*}&amp;x_2(1)=f(\\sum_{j=1}^3w_{2j}x_j(0))=f(-2\\times1+(-2)\\times1)=f(-4)=0\\&amp;x_1(1)=x_1(0)=1\\&amp;x_3(1)=x_3(0)=1\\\\end{align*}$$​ t=2时，再算$$\\begin{align*}&amp;x_2(2)=f(\\sum_{j=1}^3w_{2j}x_j(1))=f(-2\\times0+(-2)\\times1)=f(-2)=0\\&amp;x_1(2)=x_1(1)=1\\&amp;x_3(2)=x_3(1)=1\\\\end{align*}$$​ t=3时，再算$$\\begin{cases}x_1(3)=1\\x_2(3)=0\\x_3(3)=1\\\\end{cases}$$​ 最终就是$$\\begin{cases}x_1(0)=1\\x_2(0)=1\\x_3(0)=1\\\\end{cases}\\quad\\begin{cases}x_1(1)=1\\x_2(1)=0\\x_3(1)=1\\\\end{cases}\\quad\\begin{cases}x_1(2)=1\\x_2(2)=0\\x_3(2)=1\\\\end{cases}\\quad\\begin{cases}x_1(3)=1\\x_2(3)=0\\x_3(3)=1\\\\end{cases}$$​ 再往下算下去，还是不会改变，已经进入稳定状态，可以判断这个水果是橘子。","link":"/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%AC8%E7%AB%A0/"},{"title":"计算机系统结构基础","text":"第2章 计算机系统结构基础​ 计算机系统设计三个层次： 应用、操作系统、编译系统 计算机系统结构（性能、价格、功耗） 逻辑设计、电路设计、工艺制造 摩尔定律和工艺的发展​ 之前，集成电路厂商大约每18月能把工艺提高一代，现在工艺的发展速度变慢了，变成了2~3年才更新一代。 ​ 工艺技术与系统结构的关系经历了三个阶段： 晶体管不够用 集成电路的集成度越来越高，晶体管更多、更快、更省电 晶体管越来越多，但越来越难用，晶体管复杂、不快、不省电 复杂：纳米级工艺的物理效应，比如线间耦合、片内漂移、可制作性等问题。 不快：晶体管的驱动能力越来越小，连线电容相对较大、连线延迟越来越长。 不省电：（1）工艺不断更新换代，漏电功能不断增加（纳米级工艺晶体管即使关掉之后还有漏电，有直流电流）（2）电压不再随着工艺的更新换代而更新降低（3）纳米级工艺连线功耗占主导，降低晶体管功耗对总功耗影响不大 ​ CMOS工艺的物理极限（面临原子和量子机制的边界） 蚀刻问题越来越难处理（难以制造） 片内漂移问题突出（同一硅片内不同位置的晶体管都有不一样的电参数） 栅氧（晶体管中栅极下面作为绝缘层的氧化层）厚度难以继续降低 ​ 如何解决？新材料与新器件P14 计算机应用的发展趋势​ 两台计算机。一台高端的，服务器更加普及，性能更高；一台融合了电脑、手机、电视等功能的手持普适信息终端。两者之间通过网络随时连接。（高和广两个特征） 计算机系统结构发展趋势 复杂度障碍 工艺提供的晶体管变多了，但是更“难用”了，导致了设计周期和设计成本大幅度增加。芯片设计越来越强调结构的层次化、功能部件的模块化和分布化。（每个功能部件都相对简单，部件内部尽可能保持通信的局部性） 主频障碍 在高频状态下要求导线越细越短越好，这样才能减小导线分布电容等杂散干扰以保证CPU运算正确。因此制造工艺的限制，是主频发展的最大障碍之一。 功耗障碍 由于晶体管的特性，今后处理器的工作电压不会随着工艺的进步而降低，加上频率的提高，导致了处理器的功耗密度随集成度的增加而增加。并且纳米级工艺的漏电功耗也在不断增加。 应用的变化 设计专用处理器结合特定的算法设计，使芯片中多数面积和功耗都用来做运算以满足特定应用。 多核结构的发展及其面临的问题​ 一开始的多核芯片：把好几个硅片封装在一起成为一个大芯片。 ​ 现在的多核芯片：采用比较复杂的少量核结构，其中的多核一般通过共享二级cache、三级cache或者内存进行互联和通信。 ​ 未来多核结构如何发展：第一把核越做越大；第二采用大量的基于分片的众核结构（可重构RAW处理器）；第三把通用处理器和协处理器集成在一起形成异构多核结构。 ​ 面临的问题： 编程墙问题 并行程序编程困难并且串行程序得不到加速，现在还没有一种结构方法可以在分布式结构和传统串行编程之间架设一座桥梁，以提高编程和调试的效率。 带宽墙问题 通俗地讲，就是访存速度跟不上CPU处理数据的速度。 一些新型工艺速度：3D封装技术、光互连技术。 衡量计算机的指标 运行速度快不快 影响计算机运算速度的因素主要有：算法和编译系统、体系结构、主频等。 算法和编译决定完成一个任务所需要的运算量；体系结构决定完成运算所需要的时钟周期数；主频决定每个时钟周期所需要的时间。 价格 功耗 性能评价​ 通过基准程序全面综合地评价计算机的性能。 第3章 二进制与逻辑电路计算机中数的表示​ 定点数表示：原码和补码，正数的原码和补码相同，负数的补码就是原码符号位不变，其余位取反后最低位加1。 ​ 计算机中的定点数一般用补码来表示，其优点就是可以把减法变成加法，即A-B=A+(B的负数)=A+(B按位取反加1)。 ​ 判断溢出的方法：两同号数相加，结果的符号位与参与运算的相反则溢出；两异号数相减，结果的符号位与被减数的符号位相反则溢出。 ​ 浮点数表示：IEEE 754标准 ​ 以单精度为例，阶码值的范围为0~255之间，其中阶码位0和255时表示特殊的数，阶码在1~254之间表示正常的数。阶码为0时，表示非规格化数或者正负零，阶码为255时，表示无穷大或者非数。 MOS管工作原理 ​ 以上图为例，如果直接在源极和漏极之间加上电压，则不会有电流通过。（源和漏之间有一对正反相对的PN结）如果先在栅极上加上电压，因为栅氧化层是绝缘层，于是在P衬底形成一个电场，栅极上的正电压会把P衬底的电子吸引到栅氧化层底部，形成一个很薄的沟道电子层，相当于在源极和漏极之间架设了一座桥梁，这个时候在源极和漏极之间加上电压就会有电流通过。P管与此相反，加上电不通。 ​ 三种情况：截止区、线性区、饱和区 MOS基本工艺​ 光刻、晶体管制作、版图设计 逻辑电路​ 组合逻辑电路和时序逻辑电路 ​ 下图是D锁存器和D触发器的原理图： ​ 图(a)，在RS触发器前面加上两个与非门，用时钟C控制D输入。例如，C为0时，不管输入D如何变化，R和S都是1，于是最终输出都保持原来的状态。C为1时，R和S的值与D相同，相当于直通，这就是D锁存器的原理，时钟信号为高电平时输入，时钟信号为低电平时保持。 ​ 图(b)，将两个D锁存器串接起来构成D触发器，C为1时，第一个锁存器直通，第二个锁存器保持；C为0时，第一个锁存器保持，第二个锁存器直通；C从1变到0的时刻把D的值锁存起来。 ​ 当时钟信号为高时，主触发器就读取输入数据。同时，中间的反相器确保从触发器的时钟是低电平，以使得从触发器在主触发器的值改变的时候能够保证输出值稳定。（比如C=1,D=1，这个时候输入D传到主触发器Q=1，但这个时候从触发器C=0，因此输出不会因为D的改变而改变）在时钟信号变低之后，从触发器的时钟为高电平，数据值就直接传递（主触发器Q=1传到了从触发器的输入D，并且从触发器时钟为高电平，因此从触发器Q=1），但是这时候主触发器就给它一个稳定的输入（主触发器此时的输入D不管怎么改变，主触发器Q保持1）。当时钟信号从0变到1，从触发器会在主触发器的值改变之前保存数据。","link":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%E5%9F%BA%E7%A1%80/"},{"title":"CPU电路功能分析","text":"CPU电路功能分析一、CPU控制器的工作过程CPU控制器主要负责解析指令的操作码以及R型指令的功能码。 例如：R型指令格式如下: OP rs rt rd shamt funct 6位（操作码） 5位 5位 5位 5位 6位（功能码） CPU控制器会对R型指令高六位操作码部分以及低六位功能码部分进行解析。 相关问题：R型指令的第六位功能码会对最终输出的ALU_Control产生影响，为什么其他类型的指令不会？ 答：其他类型指令的操作码不同，会从电路上进行设计，从而屏蔽其他指令低六位对最终ALU_Control的影响。 二、CPU数据通路电路分析1.分线器分离字段根据指令格式通过分线器将低26位的字段分成不同的部分，分别传向不同的端口。 详细地，就像是将低26位inst_field(25:0)分离为inst_field(25:21)、inst_field(2016)、inst_field(15:11)、inst_field(15:0)这四个不同的字段。 2.多路选择器多路选择器的功能就是对于多个输入信号，通过控制信号从而选择指定的输入信号进行输出。 3.寄存器堆 L_S为控制信号线，当且仅当L_S=1时，才能进行寄存器写操作。 clk为时钟信号，rst为复位reset信号（rst=1时，对寄存器堆中所有寄存器进行复位，复位至数值0）。 R_addr_A(4:0)、R_addr_B(4:0)为读地址线，Wt_addr(4:0)为写地址线，都为5位是因为寄存器堆总共有32个寄存器，所以寄存器的地址线位数为：log2 32 = 5位。 rdata_A(31:0)、rdata_B(31:0)为输出数据线，Wt_data(31:0)为写入数据线，都为32位是因为每个寄存器的位数为32位。 4.高位扩展器用于将16位的立即数扩展为32位，扩展的方法是将低16位的最高一位复制为16位，并将其作为高16位的值，形成一个32位数。 5.ALU运算单元 操作数输入端口：A(31:0)和B(31:0)，这两个端口输入需要执行运算的操作数。 运算器控制信号端口：ALU_operation(2:0),不同的值代表不同的运算，这里ALU_operation(2:0)为三位，故可以执行8种不同的运算。具体如下表所示： ALU_operation(2:0) 运算操作 000 AND 与 001 OR 或 010 ADD 加 011 XOR 异或 100 NOR 或非 101 SRL 移位 110 SUB 减 111 全0 这里的ALU_operation(2:0)源于ALU_Control(2:0)信号，而ALU_Control(2:0)信号是由CPU控制器解析指令的高6位操作码和低6位功能码生成的。 运算结果输出端口：res(31:0),输出32位的运算结果。 运算结果标记位端口：zero、overflow。当运算结果为0时，zero状态位置为1，当结果溢出时，overflow置为1。 6.PC程序计数器指针PC程序计数器是用于存放下一条指令所在单元的地址的地方。 （1）PC计数器复位 当rst=1时，对PC计数器进行复位，此时PC计数器输出Q(31:0)为0。 （2）PC计数器赋值 当条件满足rst==0,CE==1,并且clk时钟信号到来，将输入端D(31:0)的值写入到PC寄存器中，并且从Q(31:0)输出。 注意：PC计数器的值从Q(31:0)端口输出后，会将值传送至PC_out(31:0)端口，PC_out(31:0)输出后，将会传至指令存储器的地址输入端口，从而从ROM中读取相应的指令。 7.转移指令对PC指针的更新非转移指令：PC=PC+4 转移指令： (1)相对偏移跳转：branch 例如此时branch指令的地址为0x30 对于指令branch 0x10 最终会跳转到：0x44（PC=PC+4+offset） beq:branch if equal beq rs,rt,offset 例如：beq r17,r18,0x202→000100 10001 10010 0000 0010 0000 0010 inst_field(25:0)=10001 10010 0000 0010 0000 0010 BEQ指令的操作码为000100，经CPU控制器解析后，设置Branch=1,Jump=0,ALU_Control(2:0)=110(减法操作) R_addr_A=10001,rdata_A=R[17] R_addr_B=10010,rdata_B=R[18] ALU:操作数A=R[17],操作数B=R[18] res=A-B=R[17]-R[18],如果R[17]==R[18]，res=zero,置zero=1，使得多路选择器MUXD4=1,最终PC=branch_pc=PC+4+Branch_offset,实现了偏移跳转。 (2)直接跳转:jump,call 例如jump 0x20 会跳转至0x20（PC=target） jump指令的操作码为000010，经CPU控制器解析，置信号Jump=1,Branch=0,当jump=1时，Jump_addr直接传至PC 三.总结以下以一条C语言语句举例说明指令在CPU中的执行过程。 1.C语言语句：a=b+c; 2.汇编层次： 编译器将C语言编译器成汇编： (1) lds r18,0x300 将变量b的值存入r18 (2) lds r19,0x304 将变量c的值存入r19 (3)add r17,r18,r19 将b和c的值相加存入r17 3.机器码层次： 以下只分析指令add r17,r18,r19 →000000 10010 10011 10001 00000 100000 4.机器码存入ROM指令存储器中，假设这条add指令存放在ROM中地址0x56处 5.计算机执行过程中，当PC=0x56时，取出这条add指令，传入CPU的inst_in(31:0)端口 6.此时inst_in(31:0)=000000 10010 10011 10001 00000 100000 7.经过分线器，使得OPcode(5:0)=000000 Fun(5:0)=100000 操作码经过CPU控制器解析后：(1)生成控制信号：Branch=0、RegWrite=1、RegDst=1、MemtoReg=0、ALUSrc_B=0、mem_w=0、Jump=0 (2)生成ALUop0和ALUop1信号，传送至下面的电路和Fun(5:0)功能码一起解析，最终生成ALU_Control(2:0) 8.控制信号传入Data_path，从而对add指令的低26位操作数进行解析 9.inst_field(25:0)=10010 10011 10001 00000 100000，通过三个分线器，得到R_addr_A=10010(使得rdata_A=r18=b),R_addr_B=10011(使得rdata_B=r19=c) 10.ALU(算术逻辑运算单元) 操作数A=b，操作数B=rdata_B=c，由于ALU_operation(2:0)=010，所以ALU对操作数A和B做加法运算，故res=b+c 11.由于MemtoReg=0，故Wt_data=res=b+c，又RegDst=1故Wt_addr(4:0)=10001=17，则会将b+c→r17,r17中的值就是b+c的值，即运算结果","link":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/cpu%E7%94%B5%E8%B7%AF%E5%8A%9F%E8%83%BD%E5%88%86%E6%9E%90/"},{"title":"Redis面经（持续更新）","text":"缓存与数据库双写不一致的问题 延迟双删 内存队列 设置缓存过期时间 读多写多的场景，使用缓存是否有意义？ 不用缓存，会出现数据穿透，数据库无法承载高并发 canal 针对第五点，怎么办？（tidb） 为什么redis单线程性能如此高？ 基于内存 多路复用 底层基于epoll 底层高效的数据存储结构 底层有一张全局哈希表（一维数组+二维的链表）。 通道hash(key)%数组size得到对应哈希桶的位置，最后将key和value存储在对应的链表上。","link":"/Java/redis%E9%9D%A2%E7%BB%8F%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"},{"title":"Java常见并发容器总结","text":"Java常见并发容器总结JDK提供的并发容器大部分都在java.util.concurrent(juc)包 ConcurentHahsMap：线程安全的HashMap CopyOnWriteArrayList：线程安全的List，适用于读多写少的场景。 ConcurrentLinkedQueue：高效的并发队列，使用链表实现。可以当作一个线程安全的LinkedList，这是一个非阻塞队列。 BlockingQueue：这个一个接口，JDK内部通过链表、数组等方式实现了这个接口。表示阻塞队列，适合用于作为数据共享的通道。 ConcurrentSkipListMap：线程安全的跳表。 ConcurrentHashMap​ 首先HashMap不是线程安全 的，在并发场景下如果要保证一种可行的方式是使用Collections.synchronizedMap()方法来包装HashMap。但这是通过使用一个全局锁来做到并发控制，这对性能有很大的影响。 ​ 于是ConcurrentHashMap就出现了。在ConcurrentHashMap中，无论是读操作还是写操作都能保证很高的性能；在读操作的时候（几乎）不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其他段的访问。 CopyOnWriteArrayList123public class CopyOnWriteArrayList&lt;E&gt;extends Objectimplements List&lt;E&gt;, RandomAccess, Cloneable, Serializable ​ 在读多写少的场景中，由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁会影响性能。所有应该允许多个线程同时访问List的内部数据，因为读操作是线程安全的。这与ReentrantReadWriteLock读写锁的思想类似，就是读操作见共享，写操作与读操作或者写操作互斥。但是JDK中提供了CopyOnWriteArrayList类比相比于读写锁的思想又更进了一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList读取是完全不用加锁的，并且写入操作不会阻塞读取操作。只有写入和写入之间需要进行同步等待。 ​ 如何做到？ ​ CopyOnWriteArrayList类的所有可变操作（add,set等等）都是通过创建底层数组的副本来实现的。当List需要被修改的时候，并不会修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。所谓CopyOnWrite也就是说：在计算机中，如果需要对一块内存区域进行修改，不在原有的内存块中进行写操作，而是将其拷贝一份在新的内存区域中，在新的内存区域中进行写操作，写完之后，就将指向原来内存的指针指向新的内存，原来的内存就可以被回收掉了。 CopyOnWriteArrayList读取和写入源码分析CopyOnWriteArrayList读取操作的实现 读取操作没有任何同步控制和锁操作，理由就是内部数组不会发生修改，只会被另一个数组替换。因此可以保证数据安全。 123456789101112/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array;public E get(int index) { return get(getArray(), index);}@SuppressWarnings(&quot;unchecked&quot;)private E get(Object[] a, int index) { return (E) a[index];}final Object[] getArray() { return array;} CopyOnWriteArrayList写入操作的实现 CopyOnWriteArrayList写入操作add()方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会copy出来多个副本。 1234567891011121314151617181920/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return {@code true} (as specified by {@link Collection#add}) */public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock();//加锁 try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组 newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock();//释放锁 }} ConcurrentLinkedQueue​ Java提供的线程安全的Queue可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是BlockingQueue，非阻塞队列的典型例子是ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。阻塞队列可以通过加锁来实现，非阻塞队列可以通过CAS操作来实现。 ​ ConcurrentLinkedQueue使用队列作为其数据结构。ConcurrentLinkedQueue在高并发环境中拥有极佳的性能是因为其内部复杂的实现。其主要使用CAS非阻塞算法来实现线程安全。适用于对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果队列加锁的成本较高则适合用无锁的ConcurrentLinkedQueue来替代。 BlockingQueue​ BlockingQueue是阻塞队列。阻塞队列被广泛使用在“生产者-消费者”问题中，其原因是BlockingQueue提供了可阻塞插入和移除的方法。当队列容器满，生产者进程会被阻塞；当队列容器为空时，消费者线程会被阻塞，直到队列非空时为止。 ​ BlockingQueue是一个接口，继承自Queue，所有其实现类也可作为Queue的实现来使用。而Queue又继承自Collection接口。下面是BlockingQueue的相关实现类。 ​ 下面主要介绍三个常见的BlockingQueue的实现类：ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue。 ArrayBlockingQueue​ ArrayBlockingQueue是BlockingQueue接口的有界队列实现类，底层采用数组来实现。 123public class ArrayBlockingQueue&lt;E&gt;extends AbstractQueue&lt;E&gt;implements BlockingQueue&lt;E&gt;, Serializable{} ​ ArrayBlockingQueue一旦创建，容量不能改变，其并发控制采用可重入锁ReentrantLock，不管是插入操作还是读操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素加入队列将导致操作阻塞；尝试从一个空队列中取一个元素也会同样阻塞。 ​ ArrayBlockingQueue默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到ArrayBlockingQueue。而非公平性则是指访问ArrayBlockingQueue的顺序不是遵守严格的时间顺序，有可能存在，当ArrayBlockingQueue可以被访问时，长时间阻塞的线程依然无妨访问到ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的ArrayBlockingQueue，可采用如下代码： 1private static ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(10,true); LinkedBlockingQueue​ LinkedBlockingQueue底层基于单向链表实现的阻塞队列，可以当作无界队列也可以当作有界队列来使用，同样满足FIFO的特性，与ArrayBlockingQueue相比起来具有更高的吞吐量，为了防止LinkedBlockingQueue容量迅速增。损耗大量内存。通常在创建LinkedBlockingQueue对象时，会 指定其大小，如果未指定，容量等于Integer.MAX_VALUE。其构造方法如下： 12345678910111213141516171819202122/** *某种意义上的无界队列 * Creates a {@code LinkedBlockingQueue} with a capacity of * {@link Integer#MAX_VALUE}. */public LinkedBlockingQueue() { this(Integer.MAX_VALUE);}/** *有界队列 * Creates a {@code LinkedBlockingQueue} with the given (fixed) capacity. * * @param capacity the capacity of this queue * @throws IllegalArgumentException if {@code capacity} is not greater * than zero */public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);} PriorityBlockingQueue​ PriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自己定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。 ​ PriorityBlockingQueue并发控制采用的是可重入锁ReentranLock，队列为无界队列（ArrayBlockingQueue是有界队列，LinkedBlockingQueue也可以通过构造函数中传入capaciy指定队列的最大容量，但是PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。 ​ PriorityBlockingQueue就是PriorityQueue的线程安全版本。不可以插入null值，同时，插入队列的对象必须是可比较大小的，否则会抛出ClassCastException异常。其put方法不会阻塞，因为它是无界队列（take方法在队列为空的时候会阻塞）。 ConcurrentSkipListMap​ 什么是跳表？对于一个单链表，即使链表是有序的，如果我们想要在其中查找某个数据，也只能从头到尾遍历链表，这样效率低下。跳表（跳跃列表）是一种可以用来快速查询，插入和删除的有序的数据链表。跳表的平均查找和插入时间复杂度都是O(logn)。在高并发场景下，只需要部分锁即可保证线程安全。 ​ 跳表通过维护一个多层次的链表，最低层维护了跳表所有的元素，且每一层链表中的元素是前一层链表元素的子集。跳表内的所有链表的元素都是有序的。查找时，可以从顶层链表开始找。一旦发现被查找的元素大于当前链表中的取值，就会转入下一层了链表继续查找。整个查找的过程是“跳跃”的，显然，跳表是一种利用空间换时间的策略。 ​ 使用跳表实现Map和使用哈希算法实现Map的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表的所有元素都是有序的。因此在对跳表进行遍历时，得到的结果是有序的。因此，需要元素有序，跳表可以成为候选项之一。","link":"/Java/java%E5%B8%B8%E8%A7%81%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E6%80%BB%E7%BB%93/"},{"title":"Git宝典（持续更新）","text":"Git 简介Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. Git is easy to learn and has a tiny footprint with lightning fast performance. It outclasses SCM tools like Subversion, CVS, Perforce, and ClearCase with features like cheap local branching, convenient staging areas, and multiple workflows. Git 安装进入Git官网下载适合系统平台的稳定版本的git，无脑下一步即可。Git 各平台安装包下载地址为：http://git-scm.com/downloads 下载完成后，需要配置一下用户信息： Git提供了git config命令，可以用来配置相关的工作环境变量。这些环境变量决定了Git在各个环节的具体工作方式和行为。这些变量存放在一下三个不同的地方： /etc/gitconfig文件：系统配置，对所有用户都适用，使用git config --system --list可以查看相关的系统配置信息。 ~/.gitconfig：用户配置，只适用于该用户，使用git config --global --list可以查看用户配置信息。 工作目录中的 .git/config 文件：只对当前项目生效，并且配置是向上层覆盖的。 使用git config --global配置用户信息 12git config --global user.name &quot;xiaochenxin&quot;git config --global user.email &quot;caixindi98@qq.com&quot; Git 图解工作区：存放项目代码的地方 暂存区(stage/index)：存放在 .git 目录下的 index 文件（.git/index）中，使用git ls-files --stage可以查看存放在暂存区的文件。 本地仓库：存放数据的地方，包含所有版本数据。也就是**.git**目录下的内容，其中的HEAD可以理解为一个指针，指向当前所在的分支指针，而这个分支指针又会指向当前分支的最新提交。 远程仓库：托管代码的服务器。 掌握图中的几个git命令基本上已经可以初步使用git了。 Git 基础技能Git 将更新应用到仓库查看状态首先，我们必要要清楚，在工作目录下的每一个文件就只有两种状态：分别为已跟踪状态(tracked)和未跟踪状态(untracked)。已跟踪的文件会被纳入Git版本控制（就是Git已经知道的文件），在上一次的快照中会有它们的记录，它们的状态可能是未修改，已修改或者已放入暂存区。 而未跟踪文件不会在上次的快照记录中，并且也不会在暂存区中，在初次克隆某仓库的时候，你克隆下来的所有文件都属于已跟踪文件，并且是属于未修改状态。 如图是文件状态的变换过程： 我们可以使用git status命令来查看文件处于什么状态，对一个刚刚克隆的项目使用该命令，会有如下的输出： 1234$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.nothing to commit, working directory clean 这就表示当前文件在上次提交后都未更改过，并且当前目录下不存在未跟踪的文件，并且还告知我们当前所在分支与远程服务器上对应的分支没有发生偏离。 接下来尝试跟踪一个新的文件： 执行git add test.txt并且执行git status命令，显示如下： 此时发现文件已经被跟踪并且处于暂存状态。接下来我们修改一下这个test.txt文件（添加点内容），然后执行git status命令，显示如下： 这表示文件的内容已经更新但还没有放到暂存区里面，在暂存区里的那个文件并不是最新的，也就是这两个文件的版本并不是一致的，此时需要执行git add test.txt命令。再次查看status，显示如下： 所以git add不能仅仅只理解为将一个文件添加到项目中，而是将内容准确地添加到下一次的提交中去。当然，如果需要查看尚未暂存的文件哪些地方改变了，可以执行git diff命令，如图所示： 这个命令可以比较工作区中的当前文件和暂存区域文件之间快照的差异。当然如果需要知道暂存区域的文件和最后一次文件提交之间的差异，可以执行git diff --staged命令。 忽略文件在工作目录中，可以创建一个.gitignore文件用来告诉Git这些文件不需要被纳入管理，也不需要被跟踪。 文件 .gitignore 的格式规范如下： 所有空行或者以 # 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配，它会递归地应用在整个工作区中。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上叹号（!）取反。 看一个简单的例子： 12345678910# 忽略所有.txt文件*.txt# 跟踪test.txt文件，虽然你忽略了所有的txt文件！test.txt# 忽略该目录下的文件pkg/opcua/opcuapkg/modbus/modbuspkg/bluetooth/bluetooth.ideavendor/ 提交更新git commit命令将提交所有放在暂存区域的快照，如果文件没有通过git add添加进暂存区，将保持已修改的状态，可以在下次提交的时候纳入版本管理。可以使用git commit -m来增加提交信息，也可以使用git commit -a -m 来跳过使用暂存区域，也就是不需要执行git add，这将会将所有已跟踪的文件暂存起来一并提交。 注意：每一次的提交操作都会对项目做一次快照，也就是以后可以回到这个状态，或者与其他的状态进行比较。 删除和移动文件在Git中删除文件只需执行git rm命令，分为两种情况： 1234# 删除工作区文件并且删除缓存区文件$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file] 在Git中移动或者重命名一个文件需要执行git mv file_from file_to。事实上，这相当于执行了三条指令，分别是： 123$ mv file_from file_to$ git rm file_from$ git add file_to Git 查看提交历史使用git log命令可以查看Git的提交历史信息，比如： 直接使用该命令并且不添加任何参数，则会按时间的先后顺序一次输出该项目所有的提交历史，时间越新的排在越上面，包括每个提交的SHA-A校验和，作者的名字和电子邮件地址。当然，git log命令提供了许多的选项，使用git log --pretty=format可以定制记录的显示格式，format常用的选项如下表格所示： 选项 说明 %H 提交的完整哈希值 %h 提交的简写哈希值 %T 树的完整哈希值 %t 树的简写哈希值 %P 父提交的完整哈希值 %p 父提交的简写哈希值 %an 作者名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 –date=选项 来定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期（距今多长时间） %s 提交说明 git log的常用选项： 选项 说明 -p 按补丁格式显示每个提交引入的差异。 --stat 显示每次提交的文件修改统计信息。 --shortstat 只显示 –stat 中最后的行数修改添加移除统计。 --name-only 仅在提交信息后显示已修改的文件清单。 --name-status 显示新增、修改、删除的文件清单。 --abbrev-commit 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。 --relative-date 使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。 --graph 在日志旁以 ASCII 图形显示分支与合并历史。 --pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline、short、full、fuller 和 format（用来定义自己的格式）。 --oneline --pretty=oneline --abbrev-commit 合用的简写。 限制git log输出的选项： 选项 说明 -&lt;n&gt; 仅显示最近的 n 条提交。 --since, --after 仅显示指定时间之后的提交。 --until, --before 仅显示指定时间之前的提交。 --author 仅显示作者匹配指定字符串的提交。 --committer 仅显示提交者匹配指定字符串的提交。 --grep 仅显示提交说明中包含指定字符串的提交。 -S 仅显示添加或删除内容匹配指定字符串的提交。 Git 撤销操作撤销提交使用git commit --amend来重新提交，这个操作将会覆盖掉原来的提交信息。例如： 123$ git commit -m &quot;initial commit&quot;$ git add forgotten_file$ git commit --amend 这个操作怎么理解：与其说是修改原来的提交，不如理解为用新的提交去覆盖原来的提交，旧的提交将不会出现在git的版本历史中。 撤销暂存的文件使用git reset HEAD &lt;file&gt; ...命令可以取消文件的暂存，注意，这是个危险的命令，如果加上了--hard则会更危险，如果工作区的文件已经修改，执行git reset --hard命令将会重置暂存区与工作区，而保持与上一次commit一致。 撤销对文件的修改使用git checkout &lt;file&gt;将会恢复暂存区的指定文件到工作区，这同样也是一个危险的命令，因为你的本地修改都会被暂存区的文件所覆盖。 这边需要注意的是，需要注意保护本地工作区的文件，如果自己不清楚修改了哪些文件，不用轻易使用git reset或者git checkout命令，因为这将可能造成工作区文件修改的丢失，而向上提交的操作可以随时进行，因为在Git中任何已经提交的东西都是可以恢复的，甚至是那些被删除的分支中的提交或者使用了前面所提到的--amend选项覆盖的提交。 Git 远程仓库的使用 功能 命令 查看远程仓库[显示对应的URL] git remote [-v] 添加远程仓库 git remote add &lt;shortname&gt; &lt;url&gt; 从远程仓库拉取数据(git fentch只会将数据下载到你的本地仓库——它并不会自动合并或修改你当前的工作) git fentch &lt;remote&gt; 推送到远程仓库 git push &lt;remote&gt; &lt;branch&gt; 查看某个远程仓库 git remote show &lt;remote&gt; 远程仓库的重命名 git remote rename &lt;from&gt; &lt;to&gt; 远程仓库的移除 git remote remove &lt;remote&gt; Git 标签查看以及创建标签使用git tag 可以查看已有的标签，如果加上-l或者--list选项，那么就可以按照特定的模式查找标签。 Git支持两种标签，分别是轻量标签(lightweight)和附注标签(annotated)，轻量标签是某个特定提交的引用，而附注标签是存储在Git数据库中的一个完整对象，它可以被校验，其中包含打标签者的名字、电子邮件地址、日期时间以及一个可以使用GNU签名并验证的标签信息。 创建附注标签：例如git tag -a v1.0 -m &quot;my version 1.0&quot;，其中-m指定了一条将会存储在标签中的信息。通过git show v1.0命令可以看到标签信息和与之对应的提交信息。 创建轻量标签：例如git tag v1.0-dev，之后使用git tag命令就可以查询到这个标签，但是使用git show v1.0-dev将不会显示额外的标签信息，只会显示提交信息。 当前你也可以为过去的提交打标签，只需要知道过去提交的校验和(可以使用git log --pretty=oneline查询得到)，如图： 通过git tag -a v1.0-dev fe4ee36，这样就可以为之前的提交打上标签了。 共享标签默认情况下，Git将不会在使用git push命令时将标签信息推送到远程服务器上，必须显示推送，使用git push origin v1.0推送某个标签或者git push origin --tags推送所有标签，这样当其他人拉取仓库的时候，也可以得到这些标签。 删除标签使用git tag -d v1.0-dev可以删除你本地仓库上的标签，如果需要移除远程仓库的这个标签，有两种方式： 第一种：git push &lt;remote&gt; :refs/tags/&lt;tagname&gt;，这就表示将冒号前面的空值推送到远程标签名，从而达到删除的目的。 第二种：比较直接，使用git push origin --delete &lt;tagname&gt;。 检出标签在标签创建完成后，你在上线之前又做过多次修改。这时你可以检出你之前那个准备发布的版本(打标签的版本)进行部署。Git中不能真的检出一个标签，因为他们并不能像分支一样来回移动。如果想要工作目录与仓库中特定地标签版本完全一致，可以使用git checkout -b [分支名] [标签名]在特定地标签上创建一个新分支。例如： 12$ git checkout -b version1 v1.0-devSwitched to a new branch 'version1' Git 高阶技能Git 分支附录：Git 常用命令仓库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot; 增加/删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 代码提交123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@{0 day ago}&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 远程同步1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 其他12# 生成一个可供发布的压缩包$ git archive 参考资料官方：https://www.git-scm.com/book/zh/v2 菜鸟教程：https://www.runoob.com/git/git-tutorial.html","link":"/Git/git%E5%AE%9D%E5%85%B8%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"},{"title":"三色灯控制实现","text":"数组数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或者多个元素组成，由于数组的长度是固定的，所以在Go中很少使用。所以不作过多介绍。 数组的初始化的两种方式： 12var r = [3]int{1, 2, 3}q := [...]int{1, 2, 3} //语法糖 Slice 本文代码基于Go 1.17 slice 结构体12345678type slice struct { //指向底层数组的指针 array unsafe.Pointer //slice当前元素的个数 len int //slice的容量 cap int} 创建切片1234567891011121314151617func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap { // NOTE: Produce a 'len out of range' error instead of a // 'cap out of range' error when someone does make([]T, bignumber). // 'cap out of range' is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem &gt; maxAlloc || len &lt; 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true)} 这边有个unsafe.Pointer 12345go里面的指针类似于C++里的y任意类型的指针值都可以转换为unsafe.Pointer（A pointer value of any type can be converted to a Pointer.）unsafe.Pointer可以转换为任意类型的指针值（A Pointer can be converted to a pointer value of any type.）uintptr可以转换为unsafe.Pointer（A uintptr can be converted to a Pointer.）unsafe.Pointer可以转换为uintptr（A Pointer can be converted to a uintptr.） 增加元素以及扩容slice相比于数组的一大优势就是可以进行扩容， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135// growslice handles slice growth during append.// It is passed the slice element type, the old slice, and the desired new minimum capacity,// and it returns a new slice with at least that capacity, with the old data// copied into it.// The new slice's length is set to the old slice's length,// NOT to the new requested capacity.// This is for codegen convenience. The old slice's length is used immediately// to calculate where to write new values during an append.// TODO: When the old backend is gone, reconsider this decision.// The SSA backend might prefer the new length or to return only ptr/cap and save stack space.func growslice(et *_type, old slice, cap int) slice { if raceenabled { callerpc := getcallerpc() racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, funcPC(growslice)) } if msanenabled { msanread(old.array, uintptr(old.len*int(et.size))) } //如果需求的容量小于原始容量则报panic错误 if cap &lt; old.cap { panic(errorString(&quot;growslice: cap out of range&quot;)) } //append不能创建一个nil指针但是len长度不为0的切片 if et.size == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn't need to preserve old.array in this case. //当前切片大小为0，调用了扩容方法，直接返回应该新的容量的切片 return slice{unsafe.Pointer(&amp;zerobase), old.len, cap} } //扩容策略 //doublecap:原来容量的两倍 newcap := old.cap doublecap := newcap + newcap //如果要扩容的容量比原容量的两倍还要大，那么将要扩容的容量改为指定容量 if cap &gt; doublecap { newcap = cap } else { //如果旧容量小于1024,那么扩容至原来的两倍 if old.cap &lt; 1024 { newcap = doublecap } else { // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; cap { //循环 扩容容量=旧容量+旧容量*1/4 newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { //如果溢出 新容量=要扩容的容量 newcap = cap } } } //计算新的切片的容量和长度 var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don't need any division/multiplication. // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) &gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize //64位系统 这里sys.PtrSize=8 capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) &gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31 } lenmem = uintptr(old.len) &lt;&lt; shift newlenmem = uintptr(cap) &lt;&lt; shift capmem = roundupsize(uintptr(newcap) &lt;&lt; shift) overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift) newcap = int(capmem &gt;&gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // The check of overflow in addition to capmem &gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1&lt;&lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), &quot;\\n&quot;) // } if overflow || capmem &gt; maxAlloc { panic(errorString(&quot;growslice: cap out of range&quot;)) } var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem &gt; 0 &amp;&amp; writeBarrier.enabled { // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size+et.ptrdata) } } memmove(p, old.array, lenmem) return slice{p, old.len, newcap}} roundupsize 假设这边传入的是1600*8=12800，那么size是小于_MaxSmallSize(32768)，进入下一层条件判断，有12800&gt;1024-8，所以进入else，计算(size-smallSizeMax)/largeSizeDiv=(12800-1024+128-1)/128=92,则size_to_class128[92]=57,class_to_size[57]/8=1696 12345678910111213141516171819202122func roundupsize(size uintptr) uintptr { if size &lt; _MaxSmallSize { if size &lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]]) } else { return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]]) } } if size+_PageSize &lt; size { return size } return alignUp(size, _PageSize)}const ( _MaxSmallSize = 32768 smallSizeDiv = 8 smallSizeMax = 1024 largeSizeDiv = 128 _NumSizeClasses = 68 _PageShift = 13) 12345var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768}var class_to_allocnpages = [_NumSizeClasses]uint8{0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 3, 2, 3, 4, 5, 6, 1, 7, 6, 5, 4, 3, 5, 7, 2, 9, 7, 5, 8, 3, 10, 7, 4}var class_to_divmagic = [_NumSizeClasses]uint32{0, ^uint32(0)/8 + 1, ^uint32(0)/16 + 1, ^uint32(0)/24 + 1, ^uint32(0)/32 + 1, ^uint32(0)/48 + 1, ^uint32(0)/64 + 1, ^uint32(0)/80 + 1, ^uint32(0)/96 + 1, ^uint32(0)/112 + 1, ^uint32(0)/128 + 1, ^uint32(0)/144 + 1, ^uint32(0)/160 + 1, ^uint32(0)/176 + 1, ^uint32(0)/192 + 1, ^uint32(0)/208 + 1, ^uint32(0)/224 + 1, ^uint32(0)/240 + 1, ^uint32(0)/256 + 1, ^uint32(0)/288 + 1, ^uint32(0)/320 + 1, ^uint32(0)/352 + 1, ^uint32(0)/384 + 1, ^uint32(0)/416 + 1, ^uint32(0)/448 + 1, ^uint32(0)/480 + 1, ^uint32(0)/512 + 1, ^uint32(0)/576 + 1, ^uint32(0)/640 + 1, ^uint32(0)/704 + 1, ^uint32(0)/768 + 1, ^uint32(0)/896 + 1, ^uint32(0)/1024 + 1, ^uint32(0)/1152 + 1, ^uint32(0)/1280 + 1, ^uint32(0)/1408 + 1, ^uint32(0)/1536 + 1, ^uint32(0)/1792 + 1, ^uint32(0)/2048 + 1, ^uint32(0)/2304 + 1, ^uint32(0)/2688 + 1, ^uint32(0)/3072 + 1, ^uint32(0)/3200 + 1, ^uint32(0)/3456 + 1, ^uint32(0)/4096 + 1, ^uint32(0)/4864 + 1, ^uint32(0)/5376 + 1, ^uint32(0)/6144 + 1, ^uint32(0)/6528 + 1, ^uint32(0)/6784 + 1, ^uint32(0)/6912 + 1, ^uint32(0)/8192 + 1, ^uint32(0)/9472 + 1, ^uint32(0)/9728 + 1, ^uint32(0)/10240 + 1, ^uint32(0)/10880 + 1, ^uint32(0)/12288 + 1, ^uint32(0)/13568 + 1, ^uint32(0)/14336 + 1, ^uint32(0)/16384 + 1, ^uint32(0)/18432 + 1, ^uint32(0)/19072 + 1, ^uint32(0)/20480 + 1, ^uint32(0)/21760 + 1, ^uint32(0)/24576 + 1, ^uint32(0)/27264 + 1, ^uint32(0)/28672 + 1, ^uint32(0)/32768 + 1}var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32}var size_to_class128 = [(_MaxSmallSize-smallSizeMax)/largeSizeDiv + 1]uint8{32, 33, 34, 35, 36, 37, 37, 38, 38, 39, 39, 40, 40, 40, 41, 41, 41, 42, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 48, 48, 48, 49, 49, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 54, 54, 54, 54, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67} 内置的append函数可能使用比appendInt更复杂的内存扩展策略。因此，通常我们并不知道append调用是否导致了内存的重新分配，因此我们也不能确认新的slice和原始的slice是否引用的是相同的底层数组空间。同样，我们不能确认在原先的slice上的操作是否会影响到新的slice。因此，通常是将append返回的结果直接赋值给输入的slice变量,比如x=append(x,y) Map在Go语言中，一个map就是一个哈希表的引用，map类型可以写为map[K]V，其中K和V分别对应key和value。map中所有的key都有相同的类型，所有的value也有着相同的类型，但是key和value之间可以是不同的数据类型。其中K对应的key必须是支持==比较运算符的数据类型，所以map可以通过测试key是否相等来判断是否已经存在。虽然浮点数类型也是支持相等运算符比较的，但是将浮点数用做key类型则是一个坏的想法，正如第三章提到的，最坏的情况是可能出现的NaN和任何浮点数都不相等。对于V对应的value数据类型则没有任何的限制。 抽象结构go/src/cmd/compile/internal/types/type.go 123456789type Map struct { Key *Type // Key type Elem *Type // Val (elem) type Bucket *Type // internal struct type representing a hash bucket Hmap *Type // internal struct type representing the Hmap (map header object) Hiter *Type // internal struct type representing hash iterator state} 前两个字段分别位Key和Value，并且支持多种数据类型，Bucket是哈希桶，Hmap是map底层使用的hashtable的原始数据结构，Hiter是用于遍历go map的数据结构。 底层结构hmapgo中map的底层结构是hamp，结构如下： 123456789101112131415161718192021type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go. // Make sure this stays in sync with the compiler's definition. count int //当前map的元素个数 flags uint8 //当前map的状态：读，写，扩容等 // map标记: // 1. key和value是否包指针 // 2. 是否正在扩容 // 3. 是否是同样大小的扩容 // 4. 是否正在 `range`方式访问当前的buckets // 5. 是否有 `range`方式访问旧的bucket B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) 桶个数为2^B noverflow uint16 // 溢出桶个数 hash0 uint32 // hash种子 用于计算hash值 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. 哈希桶首地址 oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing 旧哈希桶地址 nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) 已迁移的哈希桶个数 extra *mapextra // optional fields这个字段是为了优化GC扫描而设计的。当key和value均不包含指针，并且都可以inline时使用，extra是指向mapextra类型的指针。} 通过该数据结构也可以知道，map在作为函数传参的时候，实际传递的是一个指针。直接看下面这个例子： 12345678910111213func main(){ m := make(map[string]string, 3) m[&quot;test&quot;] = &quot;fail&quot; fmt.Printf(&quot;%#v\\n&quot;, m) fmt.Printf(&quot;原map的内存地址是：%p\\n&quot;, m) m=update(m) fmt.Printf(&quot;%#v\\n&quot;, m) fmt.Printf(&quot;修改后map的内存地址是：%p\\n&quot;, m)}func update(m map[string]string) { m[&quot;test&quot;] = &quot;success&quot;} 输出为： bmapbmap就是bucket map，它是桶bucket的底层结构，但是在go的源码中并没有显示的定义，下面的结构体中中只是存储了一个tophash。 12345type bmap struct { //tophash 此桶中每个键的值的哈希值最高字节的高8位信息，用来在每一个桶中区别出键。 //如果tophash[0]&lt;minTopHash,那么tophash[0]就表示该桶的搬迁(evacuation)状态。 tophash [bucketCnt]uint8} 根据src/cmd/compile/internal/reflectdata/reflect.go可以还原出bmap的结构： 123456type bmap struct { topbits [8]uint8 //hash值的高8位 keys [8]keytype //存放哈希桶中所有的键 elems [8]elemtype //存放哈希桶中所有的值 overflow uintptr //overflow是一个uintptr类型的指针，存放了指向溢出桶的地址} 这里需要注意的是为了保证内存对齐，键值对并不是连续存储的，由此我们可以得到一个bucket的抽象内存模型: mapextra1234567891011121314// mapextra holds fields that are not present on all maps.type mapextra struct { // 如果 key 和 value 都不包含指针，并且可以被 inline(&lt;=128 字节) // 就使用 hmap的extra字段 来存储 overflow buckets，这样可以避免 GC 扫描整个 map // 然而 bmap.overflow 也是个指针。这时候我们只能把这些 overflow 的指针 // 都放在 hmap.extra.overflow 和 hmap.extra.oldoverflow 中了 // overflow 包含的是 hmap.buckets 的 overflow 的指针 // oldoverflow 包含扩容时的 hmap.oldbuckets 的 overflow 的指针 overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap //指向下一个溢出桶} 这边需要注意一个问题，当key和elem的长度超过128的时候，go在map中会使用指针存储，如下代码： 123456if keytype.Width &gt; MAXKEYSIZE { keytype = types.NewPtr(keytype)}if elemtype.Width &gt; MAXELEMSIZE { elemtype = types.NewPtr(elemtype)} 而当一个bmap的key和elem的长度都没有超过128的时候，该map的bucket类型会被标注为不含指针，这样GC将不会扫描到该map，这样就会出现问题，因为bucket的底层结构bmap中含有一个指向溢出桶的uintptr类型的指针，不能保证该指针指向的内存区域不会被GC给清理掉，因为GC不扫描bmap结构，就会导致该指针指向的内存区域被GC给清理掉。因此Go在hmap中新增了一个mapextra字段，其中的overflow是一个指向保存所有hamp.buckets的溢出桶地址的slice指针，oldoverflow是指向保存所有hamp.oldbuckets的溢出桶地址的slice指针。并且只有当map的key和elem都不含之争的时候这两个字段才会有效，因此mapextra的设置就是为了解决因为map没有没有被GC扫描掉而导致相关内存被GC释放的问题，当map的key和elem字段是指针的时候，GC会扫描map，也就知道了bmap中指针指向的内存区域是有被引用的，也就不会释放相应的内存。 由此，现在可以得到一个Go的map结构图： hiter123456789101112131415161718// 遍历maptype hiter struct { key unsafe.Pointer // Must be in first position. Write nil to indicate iteration end (see cmd/compile/internal/walk/range.go). elem unsafe.Pointer // Must be in second position (see cmd/compile/internal/walk/range.go). t *maptype h *hmap buckets unsafe.Pointer // bucket ptr at hash_iter initialization time bptr *bmap // current bucket overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // bucket iteration started at offset uint8 // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1) wrapped bool // already wrapped around from end of bucket array to beginning B uint8 i uint8 bucket uintptr checkBucket uintptr}","link":"/Golang/%E4%B8%89%E8%89%B2%E7%81%AF%E6%8E%A7%E5%88%B6%E5%AE%9E%E7%8E%B0/"},{"title":"《神经网络与深度学习》第4-5章","text":"如何理解反向传播？​ 首先介绍一下什么是梯度下降法。以神经网络为例，给定一组神经网络参数，即$$\\theta={w_1,w_2,…,b_1,b_2,…}$$记$$\\nabla L(\\theta)=\\left[\\begin{matrix}\\frac{\\partial L(\\theta)}{\\partial w_1} \\\\frac{\\partial L(\\theta)}{\\partial w_2} \\\\vdots \\\\frac{\\partial L(\\theta)}{\\partial b_1} \\\\frac{\\partial L(\\theta)}{\\partial b_2} \\\\vdots\\end{matrix}\\right]$$通过计算$\\nabla L(\\theta^0)$，得到$\\theta^1=\\theta^0-\\eta\\nabla L(\\theta^0)$，通过计算$\\nabla L(\\theta^1)$，得到$\\theta^2=\\theta^1-\\eta\\nabla L(\\theta^1)$，不断反复，最后找到最佳参数。与线性回归，逻辑回归不同的是，神经网络中往往参数量是百万级别的，如何有效率地计算梯度，这便是反向传播的作用。 ​ 这里先介绍一下链式法则，如书中附录部分： 以B.16为例，$\\Delta x\\rightarrow\\Delta y\\rightarrow\\Delta z$，于是我们有$\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{\\partial y}\\frac{\\partial y}{\\partial x}$。 还有一种情况就是$x=g(t),y=h(t),z=k(x,y)$，此时$$\\frac{\\partial z}{\\partial t}=\\frac{\\partial z}{\\partial x}\\frac{\\partial x}{\\partial t}+\\frac{\\partial z}{\\partial y}\\frac{\\partial y}{\\partial t}$$ 这里为了说明方便，我们截取特定输入样本的某一层的某个神经元进行说明。这里只介绍$\\frac{\\partial C}{\\partial w}$，因为计算$\\frac{\\partial C}{\\partial b}$的原理是一样的。$$L(\\theta)=\\sum_{n=1}^NC^n(\\theta)\\rightarrow \\frac{\\partial L(\\theta)}{\\partial w}=\\sum_{n=1}^{N}\\frac{\\partial C(\\theta)}{\\partial w}$$ 显然前面的这一项$\\frac{\\partial z}{\\partial w}$非常容易计算，如图中所示，$$\\frac{\\partial z}{\\partial w_1}=x_1 , \\frac{\\partial z}{\\partial w_2}=x_2$$，其结果就是连接这个权重的输入，我们称这个过程为顺推法。而计算$\\frac{\\partial C}{\\partial z}$就比较复杂了，如下图所示： 我们知道$\\frac{\\partial a}{\\partial z}=\\sigma’(z)$，接下来就是计算$\\frac{\\partial C}{\\partial a}$，图中通过链式法则我们可以得到，复杂的情况下，下面可能会产生很多项：$$\\frac{\\partial C}{\\partial a}=\\frac{\\partial z’}{\\partial a}\\frac{\\partial C}{\\partial z’}+\\frac{\\partial z’’}{\\partial a}\\frac{\\partial C}{\\partial z’’}$$其中的$\\frac{\\partial z’}{\\partial a}$和$\\frac{\\partial z’’}{\\partial a}$很容易计算，就是$w_3$和$w_4$，此时我们得到：$$\\frac{\\partial C}{\\partial z}=\\sigma’(z)[w_3 \\frac{\\partial C}{\\partial z’}+w_4\\frac{\\partial C}{\\partial z’’}]$$上述公式可以看出如下的类似的反向神经网络，其中$\\sigma’(z)$是一个常量，因为在前向传播中，z的值已经被计算出来，带入即可得到其值。 现在所有的问题都集中在如何计算$\\frac{\\partial C}{\\partial z’}$和$\\frac{\\partial C}{\\partial z’’}$，会遇到两种情况，第一种就是$z’,z’’$已经到达输出层，如图所示： 这两项都可以直接计算得出，因为你知道最后的激活函数，你也知道你的损失函数是怎么定义的。 还有一种情况就是$z’,z’’$只是在中间的隐藏层，后面还有许多层，如图所示： 我们发现计算$\\frac{\\partial C}{\\partial z’}$和$\\frac{\\partial C}{\\partial z’’}$与之前计算$\\frac{\\partial C}{\\partial z}$一样，例如:$$\\frac{\\partial C}{\\partial z’}=\\frac{\\partial a’}{\\partial z’}\\frac{\\partial C}{\\partial a’}=\\sigma’(z’)[\\frac{\\partial z_a}{\\partial a’}\\frac{\\partial C}{\\partial z_a}+\\frac{\\partial z_b}{\\partial a’}\\frac{\\partial C}{\\partial z_b}]=\\sigma’(z’)[w_5 \\frac{\\partial C}{\\partial z_a}+w_6\\frac{\\partial C}{\\partial z_b}]$$接下来就是无线套娃的过程，这里我们如果一直从前往后推这是非常复杂的过程，但如果我们一开始就从后往前计算，整个过程就变得很简单，这便是反向传播。如图所示，如果我们要计算$\\frac{\\partial C}{\\partial z_1}$，正向计算我们需要算$\\frac{\\partial C}{\\partial z_3},\\frac{\\partial C}{\\partial z_4},\\frac{\\partial C}{\\partial z_5},\\frac{\\partial C}{\\partial z_6}$，而想要得到$\\frac{\\partial C}{\\partial z_3}$，我们需要计算$\\frac{\\partial C}{\\partial z_5},\\frac{\\partial C}{\\partial z_6}$，以此类推，图中所给示例还是比较简单的结构，如果复杂一点，计算量可想而知。 而现在，我们从后面往前算，先计算$\\frac{\\partial C}{\\partial z_5},\\frac{\\partial C}{\\partial z_6}$，再根据$\\frac{\\partial C}{\\partial z_5},\\frac{\\partial C}{\\partial z_6}$计算$\\frac{\\partial C}{\\partial z_3},\\frac{\\partial C}{\\partial z_4}$，再根据$\\frac{\\partial C}{\\partial z_3},\\frac{\\partial C}{\\partial z_4}$，计算$\\frac{\\partial C}{\\partial z_1},\\frac{\\partial C}{\\partial z_2}$. 总结一下反向传播的过程就是先顺推出例如$\\frac{\\partial z}{\\partial w}$的值，然后逆推出$\\frac{\\partial C}{\\partial z}$,最终便可以得到$\\frac{\\partial C}{\\partial w}=\\frac{\\partial z}{\\partial w}\\frac{\\partial C}{\\partial z}$. 自动梯度计算这个部分可以参考论文《Automatic Differentiation in Machine Learning: a Survey》 数值微分 数值微分（Numerical Differentiation）是用数值方法来计算函数𝑓(𝑥)的导数。函数𝑓(𝑥)的点𝑥的导数定义为$$f’(x)=\\lim_{\\Delta x\\rightarrow0}\\frac{f(x+\\Delta x)-f(x)}{\\Delta x}$$找到一个合适的扰动 Δ𝑥十分困难。如果 Δ𝑥 过小，会引起数值计算问题，比如舍入误差；如果Δ𝑥 过大，会增加截断误差，使得导数计算不准确。因此，数值微分的实用性比较差。 何为截断误差？例如函数$e^x$可以展开为无穷幂级数：$$e^x=1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+\\frac{x^4}{4!}+\\dots$$若取其中的部分项比如:$$e^x\\approx 1+x+\\frac{x^2}{2!}$$作为其近似计算公式，于是后面的项便舍弃了，便产生了误差，这就是截断误差。 书中说使用下面公式来计算梯度，可以减少截断误差，也称中心差分：$$f’(x)=\\lim_{\\Delta x\\rightarrow0}\\frac{f(x+\\Delta x)-f(x-\\Delta x)}{2\\Delta x}$$利用python程序进行验证： $f(x)=e^ x$ h=0.1 h=0.01 h=0.001 前向差分 1.0517091807564771 1.005016708416795 1.0005001667083846 后向差分 0.9516258196404048 0.9950166250831893 0.9995001666249781 中心差分 1.001667500198441 1.0000166667499921 1.0000001666666813 符号微分 符号微分可以利用代数软件自动实现一些微分的公式，比如：$$\\frac{d}{dx}(f(x)+g(x)) \\leadsto \\frac{d}{dx}f(x)+\\frac{d}{dx}g(x)$$ $$\\frac{d}{dx}(f(x)g(x))\\leadsto(\\frac{d}{dx}f(x))g(x)+f(x)(\\frac{d}{dx}g(x))$$ 符号微分有一些不足之处：1）编译时间较长，特别是对于循环，需要很长时间进行编译；2）为了进行符号微分，一般需要设计一种专门的语言来表示数学表达式，并且要对变量（符号）进行预先声明；3）很难对程序进行调试。 同时，符号微分还存在表达式膨胀（ expression swell）的问题，如表所示： 自动微分（Automatic Differentiation，AD） 以复合函数$f(x;w,b)$为例：$$f(x;w,b)=\\frac{1}{\\exp(-(wx+b))+1}$$将其分解为一系列基本操作，并且构成一个计算图，计算图中的每个非叶子节点表示一个基本操作，每个叶子节点为一个输入变量或常量。下图给出了当 𝑥 = 1, 𝑤 = 0, 𝑏 = 0 时复合函数$f(x;w,b)$的计算图： 可以看出该函数由6个基本函数组成，如下表所示： 通过计算图上与参数$w$和$b$有关的路径可以得到函数$f(x;w,b)$关于参数$w$和$b$的导数： 前向模式：与计算图计算方向相同递归地计算梯度，其过程如下：$$\\begin{align*}&amp;\\frac{\\partial h_1}{\\partial w}=x=1 \\&amp;\\frac{\\partial h_2}{\\partial w}=\\frac{\\partial h_2}{\\partial h_1}\\frac{\\partial h_1}{\\partial w}=1 \\times 1=1 \\&amp;\\frac{\\partial h_3}{\\partial w}=\\frac{\\partial h_3}{\\partial h_2}\\frac{\\partial h_2}{\\partial w}=-1\\times 1=-1 \\&amp;\\frac{\\partial h_4}{\\partial w}=\\frac{\\partial h_4}{\\partial h_3}\\frac{\\partial h_3}{\\partial w}=\\exp(h3)\\times -1=1\\times -1=-1 \\&amp;\\frac{\\partial h_5}{\\partial w}=\\frac{\\partial h_5}{\\partial h_4}\\frac{\\partial h_4}{\\partial w}=1\\times-1=-1\\&amp;\\frac{\\partial h_6}{\\partial w}=\\frac{\\partial h_6}{\\partial h_5}\\frac{\\partial h_5}{\\partial w}=-0.25\\times-1=0.25\\&amp;\\frac{\\partial f(x;w,b)}{\\partial w}=\\frac{\\partial f(x;w,b)}{\\partial h_6}\\frac{\\partial h_6}{\\partial w}=1\\times0.25=0.25\\end{align*}$$反向模式：与反向传播的计算方式相同，可以说反向传播是反向模式的一种特殊形式。 如何理解？对于像神经网络这种模型，通常输入是上万到上百万维，而输出损失函数是一维的模型，只需要一遍反向模式的计算过程，便可以求出输出对于各个输入的导数，从而轻松求取梯度用于后续优化更新。 如何理解通用近似定理(如何理解神经网络)？​ 如图所示，现在有如下函数需要我们去拟合，显然这条红色的折线段可以表示为：红色线=多个分段函数累加+常量（偏置） ​ 如图所示，红色折线段可以由蓝色线段0（常量偏置）+蓝色线段1+蓝色线段2+蓝色线段3合成。 ​ 通过这个例子我们可以知道任意的分段线性函数可以由一个常量+多个如图所示的蓝色函数组成，只是不同的分段线性函数所用的蓝色函数不一定相同。 ​ 当然实际我们遇到的函数困难如下图所示，是一条连续的曲线，我们依然可以用多条直线段合成去逼近这条曲线（只要我们绿色的点取的足够的多），这里也就告诉我们只要蓝色的函数足够地多，那么任意一条曲线我们都可以去逼近。 ​ 那么现在的问题就是我们怎么去表示这些蓝色的函数，如下图所示，如果用分段函数的形式去表示，结构有一些复杂，仔细观察，这样的函数非常像sigmoid函数，如下图所示： 所以我们可以用形如：$y=c\\frac{1}{1+e^{-(b+wx_1)}}$的曲线（平滑，易于求导）去逼近上述蓝色的分段函数（这里我们称之为“Hard Sigmoid”），现在我们的目标就是用sigmoid函数去逼近各种各样的蓝色分段函数。 ​ 此时我们只需要调整参数值，就可以得到不同的sigmoid函数，总结一下，整体的流程就是：通过各种的sigmoid函数去逼近各种各样的hard sigmoid(蓝色函数)，通过多个hard sigmoid合成得到线性分段函数，用线性分段函数去近似各种的连续函数。 ​ 来看刚刚的例子，如图所示，这条红色的线性分段函数便可以用如下的形式去拟合：$$y=b+\\sum_ic_isigmoid(b_i+wix_1)$$ 这里出现了通用近似定理的雏形，想对于之前的只有一个特征的线性回归模型$y=b+wx_1$，此处的模型变得更有弹性。如果线性模型变为多维特征输入，形如：$$y=b+\\sum_jw_jx_j$$我们同样可以用如下的模型去拟合：$$y=b+\\sum_ic_isigmoid(bi+\\sum_jw_{ij}x_j)$$这个就是通用近似定理给出的形式。上面的公式拆解一下，就变成了神经网络的形式。现在我们只关注$sigmoid(bi+\\sum_jw_{ij}x_j)$，我们假定i=1，2，3；j=1,2,3，可以有$$\\begin{align*}&amp;r_1=b_1+w_{11}x_1+w_{12}x_2+w_{13}x_3\\&amp;r_2=b_2+w_{21}x_1+w_{22}x_2+w_{23}x_3\\&amp;r_3=b_3+w_{31}x_1+w_{32}x_2+w_{33}x_3\\\\end{align*}$$也就是：$$\\left[\\begin{matrix}r_1\\r_2\\r_3\\end{matrix}\\right]=\\left[\\begin{matrix}b_1\\b_2\\b_3\\end{matrix}\\right]+\\left[\\begin{matrix}w_{11}&amp;w_{12}&amp;w_{13}\\w_{21}&amp;w_{22}&amp;w_{23}\\w_{31}&amp;w_{32}&amp;w_{33}\\\\end{matrix}\\right]\\left[\\begin{matrix}x_1\\x_2\\x_3\\end{matrix}\\right]$$记作：$$\\mathbf{r=b+wx}$$最终函数的形式也就可以表示为:$$y=b+\\mathbf{c^T}\\sigma(\\mathbf{b+wx})$$这便是一个神经网络的结构，如下图所示，这里也解释了神经网络是如何拟合任意函数的。 ​ 简单地说，通用近似定理定义了一个神经网络，只需要其中有一个包含足够多但有限数量神经元的隐藏层，在激活函数的作用下（书中说𝜙(⋅)是一个非常数、有界、单调递增的连续函数），我的理解是就是一个S型的函数，后面由Kurt Hornik证明通用近似定理并不依赖于特定的激活函数，而是由多层前馈网络结构所决定的，也就是说该定理适合所有激活函数，比如Relu函数，其实两个Relu函数便可以逼近sigmoid函数。 ​ 这里有一个有趣的问题就是，既然只有一个隐藏层的浅层神经网络可以拟合出任意函数，为什么现在的神经网络更加追求称为一个很高的瘦子（即追求深度），其中的一个解释就是如果只有一个隐藏层，那么其中的参数量会非常多，容易发现过拟合，当然现在层数很多的深层神经网络，纵然是作者自己有些原因都无法解释，这也是为什么现在很多人称深度学习为”玄学”，这里面更多地原因还需要在以后的学习中去体会。","link":"/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%AC4-5%E7%AB%A0/"},{"title":"Atomic原子类总结","text":"Atomic原子类Atomic是基于unsafe类和自旋操作实现的，要理解Atomic首先需要理解CAS。Atomic是指一个操作是不可中断的，即使在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 所以，所谓源自类就说具有原子/原子操作特征的类。根据操作的数据类型，可以讲JUC包中的原子类分为4类。 要理解Atomic首先得了解CAS，CAS（Compare and Swap）,其功能就是判断内存中的某个值是否与预期的值相等，相等就用新值更新旧值，否则就不更新。Java中CAS是基于unsafe类首先的，所有的unsafe类中的方法都是native（原生）方法，直接调用操作系用底层资源执行任务。 基本类型 使用原子的方式更新基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 数组类型 使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicMarkabaleReference：原子更新带有标记的引用类型。该类将boolean标记与引用关联起来 AtomicMarkableReference无法解决ABA问题，因为它是将一个boolean值作为是否有效的标记，也就是说它的版本号其实只有两个，修改的时候标记只是在true和false之间切换，这样做并不能解决ABA问题。 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于可决原子的更新数据和数据版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题 CAS ABA问题：第一个线程取到了变量x的值A，然后做一些其他的操作，在此期间第二个线程也取到了变量x的值A，然后第二个线程把变量x的值改为B，最好又把变量x的值改为A，最后第一个线程对变量x进行操作，但这个时候虽然x的值还是A，compareAndSet操作依然成功。也就是第一个线程对第二个线程的操作是没有感知的。这在某些场景下是会产生问题的。比如在银行系统中，如果无法感知第二个线程，这是很危险的。 对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整型字段的更新器 AtomicLongFieldUpdater：原子更新长整型字段的更新器 AtomicReferenceFieldUpdater：原子更新引用类型里的字段 基本类型原子类以AtomicInteger为例，其常用类方法如下： 1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 使用示例： 1234567891011121314151617import java.util.concurrent.atomic.AtomicInteger;public class AtomicIntegerDemo { public static void main(String[] args) { // TODO Auto-generated method stub int temvalue = 0; AtomicInteger i = new AtomicInteger(0); temvalue = i.getAndSet(3); System.out.println(&quot;temvalue:&quot; + temvalue + &quot;; i:&quot; + i);//temvalue:0; i:3 temvalue = i.getAndIncrement(); System.out.println(&quot;temvalue:&quot; + temvalue + &quot;; i:&quot; + i);//temvalue:3; i:4 temvalue = i.getAndAdd(5); System.out.println(&quot;temvalue:&quot; + temvalue + &quot;; i:&quot; + i);//temvalue:4; i:9 }} 基本数据类型原子类的优势 多线程环境不使用原子类保证线程安全 需要使用synchronized，示例如下： 1234567891011class Test { private volatile int count = 0; //若要线程安全执行执行count++，需要加锁 public synchronized void increment() { count++; } public int getCount() { return count; }} 多线程环境使用原子类保证线程安全（基本数据类型） 1234567891011class Test2 { private AtomicInteger count = new AtomicInteger(); public void increment() { count.incrementAndGet(); } //使用AtomicInteger之后，不需要加锁，也可以实现线程安全。 public int getCount() { return count.get(); }} AtomicInteger线程安全原理分析部分源码如下： 123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); }}private volatile int value; AtomicInteger类主要利用CAS+volatile和native方法来保证原子操作，从而避免使用synchronized的高开销，执行效率大为提升。 CAS就是拿期望值和原来的值进行比较，如果相同就更新，如果不相同就不更新。Unsafe类的objectFieldOffset()方法是一个native方法，这个方法是用来拿到旧值的内存地址，另外value是一个volatile变量，在内存中可见，因此JVM可以保证在任何时刻任何线程总能拿到该变量的最新值。 数组类型原子类数组类型原子类介绍使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整型数组原子类 AtomicReferenceArray：引用数组类型原子类 上面三个类提供的方法几乎相同，这边以AtomicIntegerArray为例进行介绍。 AtomicIntegerArray类常用方法 1234567public final int get(int i) //获取 index=i 位置元素的值public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValuepublic final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减public final int getAndAdd(int i, int delta) //获取 index=i 位置元素的值，并加上预期的值boolean compareAndSet(int i, int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update）public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 AtomicIntegerArray常见方法的使用 12345678910111213141516171819202122import java.util.concurrent.atomic.AtomicIntegerArray;public class AtomicIntegerArrayTest { public static void main(String[] args) { // TODO Auto-generated method stub int temvalue = 0; int[] nums = { 1, 2, 3, 4, 5, 6 }; AtomicIntegerArray i = new AtomicIntegerArray(nums); for (int j = 0; j &lt; nums.length; j++) { System.out.println(i.get(j)); } temvalue = i.getAndSet(0, 2); System.out.println(&quot;temvalue:&quot; + temvalue + &quot;; i:&quot; + i); temvalue = i.getAndIncrement(0); System.out.println(&quot;temvalue:&quot; + temvalue + &quot;; i:&quot; + i); temvalue = i.getAndAdd(0, 5); System.out.println(&quot;temvalue:&quot; + temvalue + &quot;; i:&quot; + i); }} 引用类型原子类引用类型原子类介绍基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用引用类型原子类。 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用类型关联起来，可用于解决原子更新数据和数据的版本后，可以解决使用CAS进行原子更新时可能出现的ABA问题。 AtomicMarkableReference：原子更新带有标记的引用类型。该类将boolean标记与引用类型关联起来。 上面三个类可以提供的方法几乎相同，接下来以AtomicReference为例介绍： 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.concurrent.atomic.AtomicReference;public class AtomicReferenceTest { public static void main(String[] args) { AtomicReference&lt;Person&gt; ar = new AtomicReference&lt;Person&gt;(); Person person = new Person(&quot;SnailClimb&quot;, 22); ar.set(person); Person updatePerson = new Person(&quot;Daisy&quot;, 20); ar.compareAndSet(person, updatePerson); System.out.println(ar.get().getName()); System.out.println(ar.get().getAge()); }}class Person { private String name; private int age; public Person(String name, int age) { super(); this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 结果如下： 12Daisy20 上诉代码首先创建了一个Person对象，然后把Person对象设置进AtomicReference对象中，然后调用compareAndSet方法，该方法就是通过CAS操作设置ar。如果ar的值为person的话，则将其设置为updatePerson。实现原理与AtomicInteger类中的compareAndSet方法相同。 AtomicStampedReference类使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.atomic.AtomicStampedReference;public class AtomicStampedReferenceDemo { public static void main(String[] args) { // 实例化、取当前值和 stamp 值 final Integer initialRef = 0, initialStamp = 0; final AtomicStampedReference&lt;Integer&gt; asr = new AtomicStampedReference&lt;&gt;(initialRef, initialStamp); System.out.println(&quot;currentValue=&quot; + asr.getReference() + &quot;, currentStamp=&quot; + asr.getStamp()); // compare and set final Integer newReference = 666, newStamp = 999; final boolean casResult = asr.compareAndSet(initialRef, newReference, initialStamp, newStamp); System.out.println(&quot;currentValue=&quot; + asr.getReference() + &quot;, currentStamp=&quot; + asr.getStamp() + &quot;, casResult=&quot; + casResult); // 获取当前的值和当前的 stamp 值 int[] arr = new int[1]; final Integer currentValue = asr.get(arr); final int currentStamp = arr[0]; System.out.println(&quot;currentValue=&quot; + currentValue + &quot;, currentStamp=&quot; + currentStamp); // 单独设置 stamp 值 final boolean attemptStampResult = asr.attemptStamp(newReference, 88); System.out.println(&quot;currentValue=&quot; + asr.getReference() + &quot;, currentStamp=&quot; + asr.getStamp() + &quot;, attemptStampResult=&quot; + attemptStampResult); // 重新设置当前值和 stamp 值 asr.set(initialRef, initialStamp); System.out.println(&quot;currentValue=&quot; + asr.getReference() + &quot;, currentStamp=&quot; + asr.getStamp()); // [不推荐使用，除非搞清楚注释的意思了] weak compare and set // 困惑！weakCompareAndSet 这个方法最终还是调用 compareAndSet 方法。[版本: jdk-8u191] // 但是注释上写着 &quot;May fail spuriously and does not provide ordering guarantees, // so is only rarely an appropriate alternative to compareAndSet.&quot; // todo 感觉有可能是 jvm 通过方法名在 native 方法里面做了转发 final boolean wCasResult = asr.weakCompareAndSet(initialRef, newReference, initialStamp, newStamp); System.out.println(&quot;currentValue=&quot; + asr.getReference() + &quot;, currentStamp=&quot; + asr.getStamp() + &quot;, wCasResult=&quot; + wCasResult); }} 输出结果如下： 123456currentValue=0, currentStamp=0currentValue=666, currentStamp=999, casResult=truecurrentValue=666, currentStamp=999currentValue=666, currentStamp=88, attemptStampResult=truecurrentValue=0, currentStamp=0currentValue=666, currentStamp=999, wCasResult=true AtomicMarkableReference类使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.atomic.AtomicMarkableReference;public class AtomicMarkableReferenceDemo { public static void main(String[] args) { // 实例化、取当前值和 mark 值 final Boolean initialRef = null, initialMark = false; final AtomicMarkableReference&lt;Boolean&gt; amr = new AtomicMarkableReference&lt;&gt;(initialRef, initialMark); System.out.println(&quot;currentValue=&quot; + amr.getReference() + &quot;, currentMark=&quot; + amr.isMarked()); // compare and set final Boolean newReference1 = true, newMark1 = true; final boolean casResult = amr.compareAndSet(initialRef, newReference1, initialMark, newMark1); System.out.println(&quot;currentValue=&quot; + amr.getReference() + &quot;, currentMark=&quot; + amr.isMarked() + &quot;, casResult=&quot; + casResult); // 获取当前的值和当前的 mark 值 boolean[] arr = new boolean[1]; final Boolean currentValue = amr.get(arr); final boolean currentMark = arr[0]; System.out.println(&quot;currentValue=&quot; + currentValue + &quot;, currentMark=&quot; + currentMark); // 单独设置 mark 值 final boolean attemptMarkResult = amr.attemptMark(newReference1, false); System.out.println(&quot;currentValue=&quot; + amr.getReference() + &quot;, currentMark=&quot; + amr.isMarked() + &quot;, attemptMarkResult=&quot; + attemptMarkResult); // 重新设置当前值和 mark 值 amr.set(initialRef, initialMark); System.out.println(&quot;currentValue=&quot; + amr.getReference() + &quot;, currentMark=&quot; + amr.isMarked()); // [不推荐使用，除非搞清楚注释的意思了] weak compare and set // 困惑！weakCompareAndSet 这个方法最终还是调用 compareAndSet 方法。[版本: jdk-8u191] // 但是注释上写着 &quot;May fail spuriously and does not provide ordering guarantees, // so is only rarely an appropriate alternative to compareAndSet.&quot; // todo 感觉有可能是 jvm 通过方法名在 native 方法里面做了转发 final boolean wCasResult = amr.weakCompareAndSet(initialRef, newReference1, initialMark, newMark1); System.out.println(&quot;currentValue=&quot; + amr.getReference() + &quot;, currentMark=&quot; + amr.isMarked() + &quot;, wCasResult=&quot; + wCasResult); }} 输出结果如下： 123456currentValue=null, currentMark=falsecurrentValue=true, currentMark=true, casResult=truecurrentValue=true, currentMark=truecurrentValue=true, currentMark=false, attemptMarkResult=truecurrentValue=null, currentMark=falsecurrentValue=true, currentMark=true, wCasResult=true 对象的属性修改类型原子类如果需要原子更新某个类的某个字段时，需要用到对象的属性修改类型原子类。 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicReferenceFieldUpdater：原子更新引用类型里的字段的更新器 原子地更新对象的属性需要两步。第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性；第二步，更新的对象属性必须使用public volatile修饰符。 上面三个类提供的方法几乎相同，所以我们这里以AtomicIntegerFieldUpdater为例子来介绍。 AtomicIntegerFieldUpdater类示例代码： 123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;public class AtomicIntegerFieldUpdaterTest { public static void main(String[] args) { AtomicIntegerFieldUpdater&lt;User&gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, &quot;age&quot;); User user = new User(&quot;Java&quot;, 22); System.out.println(a.getAndIncrement(user));// 22 System.out.println(a.get(user));// 23 }}class User { private String name; public volatile int age; public User(String name, int age) { super(); this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 输出结果： 122223 CAS与synchronized比较CAS支持多个线程并发修改，并发程度高，而synchronized一次只有一个线程修改，并发程度低； CAS只支持一个共享变量的原子操作； synchronized可以对多个变量进行加锁； CAS会出现ABA问题（可以解决）；","link":"/Java/atomic%E5%8E%9F%E5%AD%90%E7%B1%BB%E6%80%BB%E7%BB%93/"},{"title":"AQS原理以及AQS同步组件总结","text":"AQS介绍AQS全称（AbstractQueuedSynchronizer）,即抽象队列同步器。该类位于java.util.concurrent.locks包下。 AQS是一个抽象类，主要用来构建锁和同步器。AQS 为构建锁和同步器提供了一些通用功能的是实现，因此，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask(jdk1.7) 等等都是基于 AQS 的。 AQS原理AQS的核心思想是，如果请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁来实现的，即将暂时获取不到锁的线程加入到队列中。 CLH同步队列是一个FIFO的双向队列，AQS通过它来完成同步状态的管理，当前线程如果获取同步状态失败时，AQS会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程，当同步状态释放时，会将首节点唤醒（公平锁），使其再次尝试获取同步状态。 AQS原理图如下所示： AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过 protected 类型的getState()，setState()，compareAndSetState() 进行操作： 123456789101112//返回同步状态的当前值protected final int getState() { return state;} // 设置同步状态的值protected final void setState(int newState) { state = newState;}//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} AQS 对资源的共享方式 Exclusive（独占） 只有一个线程能执行，如ReentrantLock（可重入锁）。又可以分为公平锁和非公平锁，ReentrantLock同时支持两种锁，下面以ReentrantLock为例介绍公平锁和非公平锁。 公平锁：按照线程在队列中的排队顺序，先到先得 非公平锁：当线程要获取锁时，先通过两次CAS操作去强锁，如果没抢到，当前线程再加入到队列中等待唤醒。 ReentrantLock源码分析： ReentrantLock考虑更好的性能，默认采用非公平锁，通过构造方法传入boolean来决定是否用公平锁。 123456789/** Synchronizer providing all implementation mechanics */private final Sync sync;public ReentrantLock() { // 默认非公平锁 sync = new NonfairSync();}public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} ReentrantLock中公平锁的lock方法 12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync { final void lock() { acquire(1); } // AbstractQueuedSynchronizer.acquire(int arg) public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 1. 和非公平锁相比，这里多了一个判断：是否有线程在等待 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; }} 非公平锁的lock方法 123456789101112131415161718192021222324252627282930313233343536373839404142static final class NonfairSync extends Sync { final void lock() { // 2. 和公平锁相比，这里会直接先进行一次CAS，成功就返回了 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } // AbstractQueuedSynchronizer.acquire(int arg) public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); }}/** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 这里没有对阻塞队列进行判断 if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false;} 总结：公平锁和非公平锁只有两处不同： 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果此时锁没有被占用，就可以直接获取到锁返回。 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，而是排队。 公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。 相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。 Share（共享） 多个线程可以同时执行，如Semaphore/CountDownLatch。Semaphore、CourtDownLatch、CyclicBarrier、ReadWriteLock下面介绍。 ReentrantReadWriteLock读写锁允许多个线程同时对某一资源进行读操作。不同的自定义同步器争用共享资源的方式不同。自定义同步器在实现的时候只需要实现共享资源state（状态）的获取与释放即可，而具体线程等待队列的维护（比如获取资源失败入队、唤醒出队等），AQS已经在上层实现。 AQS底层使用模板方法模式同步器的设计是基于模板方法的。 使用者继承AbstractQueuedSynchronizer并且重写指定的方法。（即对共享资源state的获取与释放）。 将AQS组合在自定义同步组件的视线中，并且调用其模板方法，而这些模板方法会调用使用者重写的方法。 这与实现接口的方式不同，AQS是模板方法模式的一个经典应用。 AQS使用了模板方法模式，自定义同步器需要重写下面几个AQS提供的钩子方法： 12345protected boolean tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。protected boolean tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。protected boolean tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。protected boolean tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。protected boolean isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。 什么是钩子方法？钩子方法是一种被声明在抽象类中的方法，一般使用protected关键词修饰，它可以使空方法（由子类是实现），也可以是默认实现的方法。模板设计模式通过钩子方法控制固定步骤的实现。对于模板方法模式的详细介绍参考https://mp.weixin.qq.com/s/zpScSCktFpnSWHWIQem2jg 除了上面要重写的钩子方法，AQS类中的其他方法都是final，所以无法被其他子类重写。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并且将state+1。此后其他线程再tryAcquire()就会失败，直到A线程unlock()将state=0（即释放锁），其它线程才有机会获得该锁。当前，释放锁之前，A线程可以重复获取该锁（state的值会累加）,这就是可重入锁。需要注意获取多少次的锁就需要释放多少次的锁，否则state无法回到零态，其它线程将永远无法获得该锁。 以CountDownLatch为例，任务分为N个子线程去执行，state也初始化为N（N与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后执行countDown()方法，state会CAS地减1。等到所有子线程都执行完后（此时state=0），会执行unpack()方法调用主线程，然后 主线程会从await()函数返回，继续后续动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式。它们也只需要实现钩子方法中独占方式或者是共享方式中的一种。当然AQS也支持自定义同步器同时实现独占和共享两种方式，比如ReentrantReadWriteLock（读写锁）。 下面是两篇有关于AQS 原理和相关源码分析的文章： Java并发之AQS详解 Java并发包基石-AQS详解 Semaphore(信号量)synchronized和ReentrantLock都是一次只允许一个线程访问某个资源，Semaphore（信号量）可以指定多个线程同时访问某个资源。 示例代码如下： 12345678910111213141516171819202122232425262728293031323334public class SemaphoreExample1 { // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException { // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); // 一次只能允许执行的线程数量。 final Semaphore semaphore = new Semaphore(20); for (int i = 0; i &lt; threadCount; i++) { final int threadnum = i; threadPool.execute(() -&gt; {// Lambda 表达式的运用 try { semaphore.acquire();// 获取一个许可，所以可运行线程数量为20/1=20 test(threadnum); semaphore.release();// 释放一个许可 } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } }); } threadPool.shutdown(); System.out.println(&quot;finish&quot;); } public static void test(int threadnum) throws InterruptedException { Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println(&quot;threadnum:&quot; + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 }} 执行acquire()方法阻塞，直到有一个许可证可以获得然后拿走一个许可证；每个release方法增加一个许可证，这可能会释放一个阻塞的acquire()方法。然而，其实并没有实际的许可证对象，Semqphore只是维持了一个可获得许可证的数量。Semaphore经常用于选址获取某种资源的线程数量。 当然一次也可以获取或者释放多个许可，如下： 123semaphore.acquire(5);// 获取5个许可，所以可运行线程数量为20/5=4test(threadnum);semaphore.release(5);// 释放5个许可 除了 acquire() 方法之外，另一个比较常用的与之对应的方法是 tryAcquire() 方法，该方法如果获取不到许可就立即返回 false。 Semaphore 有两种模式，公平模式和非公平模式。 公平模式： 调用 acquire() 方法的顺序就是获取许可证的顺序，遵循 FIFO； 非公平模式： 抢占式。 Semaphore 对应的两个构造方法如下： 12345678 // 需要提供许可证数量 public Semaphore(int permits) { sync = new NonfairSync(permits); }// 需要提供许可证数量以及是否为公平锁，默认非公平锁 public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); } Semaphore 与 CountDownLatch 一样，也是共享锁的一种实现。它默认构造 AQS 的 state 为 permits。当执行任务的线程数量超出 permits，那么多余的线程将会被放入阻塞队列 Park,并自旋判断 state 是否大于0。只有当 state 大于0的时候，阻塞的线程才能继续执行,此时先前执行任务的线程继续执行 release() 方法，release() 方法使得 state 的变量会加1，那么自旋的线程便会判断成功。 如此，每次只有最多不超过 permits 数量的线程能自旋成功，便限制了执行任务线程的数量。 CountDownLatch（倒计时器）CountDownLatch允许count个线程阻塞，直到所有线程都执行完毕。 CountDownLatch是共享锁的一种实现，它默认构造AQS的state值为count。当线程调用countDown()方法的时候，其实是使用了tryReleaseShared()方法以CAS的操作来减少state，直到state为0。当调用await()方法的时候，如果state不为0，那就证明任务还没有执行完毕，await()方法会一直阻塞，因此await()方法之后的语句不会执行。然后，CountDownLatch会自选CAS判断state==0，如果等于0，就会释放所有等待的线程，await()方法之后的语句得到执行。 CountDownLatch的典型用法 某以线程再开始允许前等待n个线程执行完毕 将CountDownLatch的计数器初始化为n，每当一个线程执行完毕，就会将计数器减1（调用countdownlatch.countDown()），当计数器的值为0时，再CountDownLatch上await()的线程就会被唤醒。典型的应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 实现多个线程开始执行任务的最大并行性 并行强调多个线程在某一时刻同时执行。做法是初始化一个共享的CountDownLatch对象，将其计数器初始化为1（即newCOuntDownLatch(1)），多个线程在开始执行任务前首先执行countdownlatch.await()，当主线程调用countDown()时，计数器变为0，多个线程同时被唤醒。 示例代码如下所示： 123456789101112131415161718192021222324252627282930313233public class CountDownLatchExample1 { // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException { // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for (int i = 0; i &lt; threadCount; i++) { final int threadnum = i; threadPool.execute(() -&gt; {// Lambda 表达式的运用 try { test(threadnum); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } finally { countDownLatch.countDown();// 表示一个请求已经被完成 } }); } countDownLatch.await(); threadPool.shutdown(); System.out.println(&quot;finish&quot;); } public static void test(int threadnum) throws InterruptedException { Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println(&quot;threadnum:&quot; + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 }} 上述代码定义了请求的数量为550，当这550个请求被处理完成之后，才会执行System.out.println(&quot;finsh&quot;)。 与CountDownLatch的第一次交互是主线程等待其他线程。主线程必须在启动其他线程后立即调用CountDownLatch.await()方法。这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。 在使用await()方法的时候一定要注意死锁问题，如果不能释放count个线程，那么await()方法将会一直阻塞。 CountDownLatch的不足CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕之后，它不能被再次使用。 CountDownLatch常见面试题 CountDownLatch 怎么用？应用场景是什么？ CountDownLatch 和 CyclicBarrier 的不同之处？ CountDownLatch 类中主要的方法？ CyclicBarrier(循环栅栏)CyclicBarrier和CountDownLatch非常类似，它也可以实现线程间的技术等待，但是它的功能比CountDownLatch更加强大。主要应用常见和CountDownLatch类似。 CountDownLatch的实现是基于AQS的，而CyclicBarrier是基于ReentrantLock（ReentrantLock也属于AQS同步器)和Condition的。 CyclicBarrier是可循环使用的屏障(Barrier)。它要作的事情是：让一组线程到达一个屏障（也可以成为同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会打开， 所有被屏障拦截的线程才会继续执行。 CyclicBarrier的默认构造方法是CyclicBarrier(int parties)，如下所示： 12345678910public CyclicBarrier(int parties) { this(parties, null);}public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;} 其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉CyclicBarrier已经抵达屏障，然后阻塞等待。 CyclicBarrier 的应用场景CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个Sheet保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。 CyclicBarrier 使用示例123456789101112131415161718192021222324252627282930313233343536373839public class CyclicBarrierExample2 { // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) throws InterruptedException { // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) { final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; { try { test(threadNum); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (BrokenBarrierException e) { // TODO Auto-generated catch block e.printStackTrace(); } }); } threadPool.shutdown(); } public static void test(int threadnum) throws InterruptedException, BrokenBarrierException { System.out.println(&quot;threadnum:&quot; + threadnum + &quot;is ready&quot;); try { /**等待60秒，保证子线程完全执行结束*/ cyclicBarrier.await(60, TimeUnit.SECONDS); } catch (Exception e) { System.out.println(&quot;-----CyclicBarrierException------&quot;); } System.out.println(&quot;threadnum:&quot; + threadnum + &quot;is finish&quot;); }} 运行结果，如下： 1234567891011121314151617181920threadnum:0is readythreadnum:1is readythreadnum:2is readythreadnum:3is readythreadnum:4is readythreadnum:4is finishthreadnum:0is finishthreadnum:1is finishthreadnum:2is finishthreadnum:3is finishthreadnum:5is readythreadnum:6is readythreadnum:7is readythreadnum:8is readythreadnum:9is readythreadnum:9is finishthreadnum:5is finishthreadnum:8is finishthreadnum:7is finishthreadnum:6is finish 可以看到当线程数量也就是请求数量达到我们定义的5个的时候，await()方法之后的方法才会被执行。 另外，CyclicBarrier还提供一个更高级的构造函数CyclicBarrier(int parties,Runnable barrierAction)，用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。示例代码如下： 123456789101112131415161718192021222324252627282930313233343536public class CyclicBarrierExample3 { // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5, () -&gt; { System.out.println(&quot;------当线程数达到之后，优先执行------&quot;); }); public static void main(String[] args) throws InterruptedException { // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) { final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; { try { test(threadNum); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } catch (BrokenBarrierException e) { // TODO Auto-generated catch block e.printStackTrace(); } }); } threadPool.shutdown(); } public static void test(int threadnum) throws InterruptedException, BrokenBarrierException { System.out.println(&quot;threadnum:&quot; + threadnum + &quot;is ready&quot;); cyclicBarrier.await(); System.out.println(&quot;threadnum:&quot; + threadnum + &quot;is finish&quot;); }} 运行结果如下： 1234567891011121314151617181920212223threadnum:0is readythreadnum:1is readythreadnum:2is readythreadnum:3is readythreadnum:4is ready------当线程数达到之后，优先执行------threadnum:4is finishthreadnum:0is finishthreadnum:2is finishthreadnum:1is finishthreadnum:3is finishthreadnum:5is readythreadnum:6is readythreadnum:7is readythreadnum:8is readythreadnum:9is ready------当线程数达到之后，优先执行------threadnum:9is finishthreadnum:5is finishthreadnum:6is finishthreadnum:8is finishthreadnum:7is finish...... CyclicBarrier源码分析当调用CyclicBarrier对象调用await()方法时，实际上调用的是dowait(fasle,0L)方法。await()方法会阻塞线程，只有当阻塞的线程数量达到parties的值时，栅栏才会打开，线程才能继续执行。 1234567public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen }} dowait(fasle,0L)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// 当线程数量或者请求数量达到 count 时 await 之后的方法才会被执行。上面的示例中 count 的值就为 5。private int count;/** * Main barrier code, covering the various policies. */private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; // 锁住 lock.lock(); try { final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); // 如果线程中断了，抛出异常 if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } // cout减1 int index = --count; // 当 count 数量减为 0 之后说明最后一个线程已经到达栅栏了，也就是达到了可以执行await 方法之后的条件 if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; // 将 count 重置为 parties 属性的初始化值 // 唤醒之前等待的线程 // 下一波执行开始 nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation &amp;&amp; ! g.broken) { breakBarrier(); throw ie; } else { // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // &quot;belong&quot; to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); }} 总结：CyclicBarrier 内部通过一个 count 变量作为计数器，count 的初始值为 parties 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减一。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。 CyclicBarrier和CountDownLatch的区别CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用。在javadoc中是这么描述的： CountDownLatch: A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.(CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；)CyclicBarrier : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.(CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。) 对于CountDownLatch来说，重点是一个线程（多个线程）等待，而其他的N个线程在完成”某件事情“之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有到达”栅栏“位置，所有的线程都必须等待。 CountDownLatch是计数器，并且是递减地计数，而CyclicBarrier是一个阀门，需要所有的线程都到达，阀门才能打开，然后继续执行。 ReentrantLock 和 ReentrantReadWriteLock这个在上文已经介绍过，需要注意的是，读写锁 ReentrantReadWriteLock 可以保证多个线程可以同时读，所以在读操作远大于写操作的时候，读写锁就非常适合。 CLH同步队列原理CLH同步队列结构图如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101static final class Node { /** 节点正在共享模式下 */ static final Node SHARED = new Node(); /** 节点正在独占模式下 */ static final Node EXCLUSIVE = null; /** waitStatus值，表示线程已取消。超时或者中断，节点会被设置为取消状态，被取消的节点时不会参与到竞争中的，他会一直保持取消状态不会转变为其他状态；*/ static final int CANCELLED = 1; /** waitStatus值。后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后继节点，使后继节点的线程得以运行 */ static final int SIGNAL = -1; /** waitStatus值，表示线程赈灾等待条件。节点在等待队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal()后，改节点将会从等待队列中转移到同步队列中，加入到同步状态的获取中 */ static final int CONDITION = -2; /** * 表示下一次共享式同步状态获取将会无条件地传播下去 */ static final int PROPAGATE = -3; /** 等待状态 */ volatile int waitStatus; /** 前驱节点 */ volatile Node prev; /** 后继节点 */ volatile Node next; /** 获取同步状态的线程 */ volatile Thread thread; /** 链接到下一个等待条件的节点，或共享的特殊值。因为条件队列只有在独占模式下保持时才被访问，所以我们只需要一个简单的链接队列来在节点等待条件时保持节点。然后，它们被转移到队列中重新获取。由于条件只能是独占的，我们通过使用特殊值来指示共享模式来保存字段。*/ Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() { return nextWaiter == SHARED; } /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * * @return the predecessor of this node */ final Node predecessor() { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } /** Establishes initial head or SHARED marker. */ Node() {} /** Constructor used by addWaiter. */ Node(Node nextWaiter) { this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread()); } /** Constructor used by addConditionWaiter. */ Node(int waitStatus) { WAITSTATUS.set(this, waitStatus); THREAD.set(this, Thread.currentThread()); } /** CASes waitStatus field. */ final boolean compareAndSetWaitStatus(int expect, int update) { return WAITSTATUS.compareAndSet(this, expect, update); } /** CASes next field. */ final boolean compareAndSetNext(Node expect, Node update) { return NEXT.compareAndSet(this, expect, update); } final void setPrevRelaxed(Node p) { PREV.set(this, p); } // VarHandle mechanics private static final VarHandle NEXT; private static final VarHandle PREV; private static final VarHandle THREAD; private static final VarHandle WAITSTATUS; static { try { MethodHandles.Lookup l = MethodHandles.lookup(); NEXT = l.findVarHandle(Node.class, &quot;next&quot;, Node.class); PREV = l.findVarHandle(Node.class, &quot;prev&quot;, Node.class); THREAD = l.findVarHandle(Node.class, &quot;thread&quot;, Thread.class); WAITSTATUS = l.findVarHandle(Node.class, &quot;waitStatus&quot;, int.class); } catch (ReflectiveOperationException e) { throw new ExceptionInInitializerError(e); } }} 入列通过调用addWaiter()方法执行入队操作，源码如下： 1234567891011121314151617private Node addWaiter(Node mode) { //新建Node Node node = new Node(Thread.currentThread(), mode); //快速尝试添加尾节点 Node pred = tail; if (pred != null) { node.prev = pred; //CAS设置尾节点 if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //多次尝试 enq(node); return node;} addWaiter(Node node)先通过快速尝试设置尾节点，如果失败，则调用enq(Node node)方法设置尾节点： 123456789101112131415161718private Node enq(final Node node) { //多次尝试，直到成功为止 for (;;) { Node t = tail; //tail不存在，设置为首节点 if (t == null) { if (compareAndSetHead(new Node())) tail = head; } else { //设置为尾节点 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} 在上面代码中，两个方法都是通过一个CAS方法compareAndSetTail(Node expect, Node update)来设置尾节点，该方法可以确保节点是线程安全添加的。在enq(Node node)方法中，AQS通过“死循环”的方式来保证节点可以正确添加，只有成功添加后，当前线程才会从该方法返回，否则会一直执行下去。 出列CLH同步队列线程FIFO，首节点的线程释放同步状态后，将会唤醒它的后继节点(next)，而后继节点将会在获取同步状态成功时将会设置为首节点。head执行该节点并断开原来的首节点的next和当前节点的prev，注意在这个过程中时不需要使用CAS来保证的，因为只有一个线程能够成功获取同步状态。过程如下图所示：","link":"/Java/aqs%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8Aaqs%E5%90%8C%E6%AD%A5%E7%BB%84%E4%BB%B6%E6%80%BB%E7%BB%93/"},{"title":"ThreadLocal详解","text":"ThreadLocal解析 本文参照一枝花算不算浪漫 ThreadLocal的特点： 线程并发：在多线程场景下 传递数据：可以通过ThreadLocal在同一线程，不同组件中传递公共变量 线程隔离：每个线程的变量都是独立的，不会相互影响 主要探讨以下问题： ThreadLocal的key是弱引用，那么在ThreadLocal.get()的时候，发生GC之后，key是否为null？ ThreadLocal中ThreadLocalMap的数据结构？ ThreadLocalMap的Hash算法？ ThreadLocalMap的扩容机制？ ThreadLocalMap中过期key的清理机制？探测式清理和启发式清理流程？ ThreadLocalMap.set()方法实现原理？ ThreadLocalMap.get()方法实现原理？ ThreadLocal代码演示首先运行下面的代码： 1234567891011121314151617181920212223242526public class ThreadLocalTest{ ThreadLocal&lt;String&gt; t1 = new ThreadLocal&lt;&gt;(); private String content; private String getContent(){ return t1.get(); } private void setContent(String content){ t1.set(content); } public static void main(String[] args) { ThreadLocalTest test = new ThreadLocalTest(); for(int i=0;i&lt;5;i++){ Thread thread =new Thread(new Runnable() { @Override public void run() { test.setContent(Thread.currentThread().getName()+&quot;的数据&quot;); System.out.println(Thread.currentThread().getName()+&quot;---&gt;&quot;+test.getContent()); } }); thread.setName(&quot;线程&quot;+i); thread.start(); } }} 输出结果如下： 12345线程0---&gt;线程0的数据线程2---&gt;线程2的数据线程1---&gt;线程1的数据线程4---&gt;线程4的数据线程3---&gt;线程3的数据 如上，ThreadLocal实现了线程隔离，在多线程并发的场景下，每个线程中的变量都是相互独立的。ThreadLocal对象可以提供线程局部变量，每个线程Thread拥有一份自己的副本变量，多个线程互不干扰。 ThreadLocal与synchronized的区别 synchronized也同样可以实现上述代码的结果，但是程序的性能会大大降低，原本并行的程序可能会变成串行。 synchroniezd ThreadLocal 原理 同步机制采用“以空间换时间”的方式，只提供了一份变量，让不同的线程排队访问。 ThreadLocal采用“以空间换时间”的方式，为每一个线程都提供了一份变量的副本，从而实现同时访问而互不干扰 关注点 多个线程之间访问同一个资源的同步 ··多个线程之间的数据相互隔离 ThreadLocal的数据结构 ThreadLocalMap有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，也就是说每个线程有一个自己的ThreadLocalMap。可以这么理解，ThreadLocalMap的key是ThreadLocal，value是代码中放入的值（实际上key并不是ThreadLocal本身，而是ThreadLocal的一个弱引用）。每个线程在往ThreadLocal里放值的时候，都会往自己的ThreadLocalMap里存，读也是以ThreadLocal作为引用，在自己的map找对应的key，以此实现了线程隔离。ThreadLocalMap有点类似HashMap结构，只是HashMap是由数组+链表实现的，而ThreadLocalMap中并没有链表结构。并且它的Entry，key是ThreadLocal&lt;?&gt; k，继承自WeakReference，也就是弱引用类型。 GC之后key是否为null？由于ThreadLocal的key是弱引用，那么在ThreadLocal.get()的时候，发生在GC之后，key的值是否为null？ Java的四种引用类型 强引用： 强引用是使用最普遍的引用，如果一个对象具有强引用，那么垃圾回收器绝不会回收它。如下： 1Object strongReference =new Object() 当内存空间不足时，Java虚拟机宁愿抛出OutOfMemoryError错误，使得程序抛出异常而终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。如果强引用对象不使用时，需要弱化从而使得GC能够回收，如下所示： 1strongReference=null 由开发者显式地设置strongReference对象为null，或者让其超出对象的生命周期范围，则GC认为该对象不存在引用，这时就可以回收这个对象。当然具体什么时候回收取决所使用的垃圾回收算法。 在一个方法的内部都有一个强引用，这个引用保存在Java栈中，而真正引用的内容(Object对象)保存在Java堆中，当这个方法运行完成后，则会退出方法栈，则引用对象的引用数为0，则这个对象会被回收。但是如果这个strongReference是全局变量时，就需要在不用这个对象时赋值为null，因为强引用不会被垃圾回收。 例如ArrayList的clear方法： 在ArrayList类中定义了一个elementData数组，在调用clear方法清空数组时，每个数组元素被赋值为null。不同于elementData=null，强引用依然存在，为了避免后续调用add()等方法添加元素时进行内存的重新分配。使用clear()方法只是清空了数组中的内容，但是数组的引用依然存在。因此使用如clear()方法清除内存数组中存放的引用类型进行内存释放特别适用，这样就可以及时释放内存。 软引用: 如果一个对象只有软引用，那么内存空间充足时，垃圾回收就不会回收它；如果内存空间不足，那么垃圾回收就会回收它们。因此软引用可以用来实现内存敏感的告诉缓存。 12345// 强引用String strongReference = new String(&quot;abc&quot;);// 软引用String str = new String(&quot;abc&quot;);SoftReference&lt;String&gt; softReference = new SoftReference&lt;String&gt;(str); 软引用可以和一个引用队列(ReferenceQueue)联合使用，如果软引用所引用的对象被垃圾回收，java虚拟机会把这个引用加入到与之关联的引用队列中。 123456789101112ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); String str = new String(&quot;abc&quot;); SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str, referenceQueue); str = null; // Notify GC System.gc(); System.out.println(softReference.get()); // abc Reference&lt;? extends String&gt; reference = referenceQueue.poll(); System.out.println(reference); //null 注意jvm即使扫描到软引用对象也不一定会回收它，软引用对象只有在虚拟机内存不够的时候才会被回收。当内存不足时，JVM首先将软引用中的对象设置为null，然后通知垃圾回收器进行回收。也就是说，垃圾回收器会在虚拟机抛出OOM之前回收软引用对象，而且虚拟机会尽可能优先回收长时间闲置不用的软引用对象。对于那些刚构建的软引用对象或者那些刚刚被使用的软引用对象则尽可能保留，这就是引入引用队列的原因。 应用场景： 浏览器的后退按钮。后退时，这个后退时显示的网页内容是重新进行请求获取还是在缓存中获取。 如果一个网页在浏览结束的时候就进行“垃圾回收”，则按后退查看之前浏览过的网页则需要重新构建；如果将浏览过的网页全部存储在内存中就会造成大量的浪费，甚至会造成内存溢出。这个时候就可以借鉴软引用的思想，将浏览完的网页设置为软引用，在垃圾回收的时候尽量保留那些新打开的页面或者最近被使用的页面。 弱引用： 弱引用和软引用的区别就是只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了弱引用对象的存在，则不管当前的内存是否足够，都会进行回收。不过由于垃圾回收器是一个优先级很低的线程，因此不一定可以很快地发现弱引用对象。垃圾回收器线程一旦发现了弱引用对象，则会将其设置为null，并且通知垃圾回收器进行回收。同样地，弱引用可以和一个引用队列(ReferenceQueue)联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用： 虚引用和其他几种引用都不同，虚引用不会决定对象的生命周期，如果一个对象持有虚引用，那么它就和没有任何引用一样，任何时候都可能被垃圾回收器回收。 应用场景： 虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的区别在于：虚引用必须和引用队列联合使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列之中。在声明一个虚引用的时候需要传入一个引用队列。当虚引用执行完finalize函数的时候就会被加入到队列中。因从可以通过判断引用队列中是否加入了虚引用来判断所引用的对象是否将要被垃圾回收。如果发现某个虚引用已经被加入到引用队列中，那么就可以在其被回收之前完成相应的处理逻辑。 1234String str = new String(&quot;abc&quot;);ReferenceQueue queue = new ReferenceQueue();// 创建虚引用，要求必须与一个引用队列关联PhantomReference pr = new PhantomReference(str, queue); 总结 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会 对象的一般状态 JVM停止运行时终止 软引用 当内存不足时 对象缓存 内存不足时终止 弱引用 正常垃圾回收时 对象缓存 垃圾回收后终止 虚引用 正常垃圾回收时 跟踪对象的垃圾回收 垃圾回收后终止 接下来来看一下GC后ThreadLocal中的数据情况： 1234567891011121314151617181920212223242526272829303132333435363738394041public class ThreadLocalDemo { public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InterruptedException { Thread t = new Thread(()-&gt;test(&quot;abc&quot;,false)); t.start(); t.join(); System.out.println(&quot;--gc后--&quot;); Thread t2 = new Thread(() -&gt; test(&quot;def&quot;, true)); t2.start(); t2.join(); } private static void test(String s,boolean isGC) { try { new ThreadLocal&lt;&gt;().set(s); if (isGC) { System.gc(); } Thread t = Thread.currentThread(); Class&lt;? extends Thread&gt; clz = t.getClass(); Field field = clz.getDeclaredField(&quot;threadLocals&quot;); field.setAccessible(true); Object ThreadLocalMap = field.get(t); Class&lt;?&gt; tlmClass = ThreadLocalMap.getClass(); Field tableField = tlmClass.getDeclaredField(&quot;table&quot;); tableField.setAccessible(true); Object[] arr = (Object[]) tableField.get(ThreadLocalMap); for (Object o : arr) { if (o != null) { Class&lt;?&gt; entryClass = o.getClass(); Field valueField = entryClass.getDeclaredField(&quot;value&quot;); Field referenceField = entryClass.getSuperclass().getSuperclass().getDeclaredField(&quot;referent&quot;); valueField.setAccessible(true); referenceField.setAccessible(true); System.out.println(String.format(&quot;弱引用key:%s,值:%s&quot;, referenceField.get(o), valueField.get(o))); } } } catch (Exception e) { e.printStackTrace(); } }} 输出如下： 1234弱引用key:java.lang.ThreadLocal@3100959c,值:abc弱引用key:java.lang.ThreadLocal@76292830,值:java.lang.ref.SoftReference@6c848e0f--gc后--弱引用key:null,值:def 如图所示，这里创建的ThreadLocal并没有指向任何值，也就是没有引用： 1new ThreadLocal&lt;&gt;().set(s); 所以这里在GC之后，key就会被垃圾回收器回收，但是如果用一个对象保存ThreadLocal的引用，那么可以看到如下图所示的结果： key并不是null，按照上面介绍的弱引用，垃圾回收，那么在这个时候key得是null。但是没有被回收，就说明存在强引用。如果不存在强引用，那么key就会被回收，而value不会被回收，于是就导致了key被回收，value永远存在的情况，这样就会出现内存泄漏。如下图所示，ThreadLocal的强引用依然存在： 每个Thread内部都维护着一个ThreadLocalMap的数据结构，map的Key值为ThreadLocal，那么当某个ThreadLocal对象不再使用（没有被引用时），每个已经关联了此ThreadLocal的线程，由于ThreadLocalMap内部存储实体结构Entry&lt;ThreadLocal,T&gt;继承自java.lang.ref.WeakReference，这样当ThreadLocal不再被引用时，因为弱引用机制的原因，会进行垃圾回收，也就是其线程内部的ThreadLocalMap会释放对ThreadLocal的引用从而让jvm回收ThreadLocal对象。但是不会回收线程变量中的值T对象，所以会内存泄露，但是ThreadLocal会在调用get()和set()方法时都会定期回收无效的Entry。 看一下源码在哪里使用了弱引用： 12345678910111213141516/** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a ThreadLocal object). * Note that null keys (i.e. entry.get() == null) mean that the key is no longer referenced, * so the entry can be expunged from table. * Such entries are referred to as &quot;stale entries&quot; in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } } Entry中的key是弱引用，key弱指向ThreadLocal&lt;?&gt;对象，并且key只是只是ThreadLocal强引用的副本，value是实际对应的对象。当显示地将key所指向的对象设置为null的时候，就只有剩下了key这一个弱引用，GC时会回收掉ThreadLocal&lt;?&gt;对象。为什么上面的例子中弱引用和GC都没有导致key作为虚引用被回收，因为它本身被当前线程的Map强引用，只有当不存在线程的强引用之后，这个weakreference才会被垃圾回收。 ThreadLocal.set()方法源码详解 ThreadLocal中set方法的原理如上图所示，整个过程主要就是判断ThreadLocal是否存在，然后使用ThreadLocal中的set方法进行数据处理。其源码如下： 12345678910111213141516public void set(T value) { // 得到当前线程 Thread t = Thread.currentThread(); // 得到当前线程的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) // 如果map不为null，直接设置值 map.set(this, value); else // 如果map为空，那么就创建map并且设置值 createMap(t, value);}void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} ThreadLocalMap的Hash算法源代码如下： 123Entry[] tab = table;int len = tab.length;int i = key.threadLocalHashCode &amp; (len-1); ThreadLocalMap中hash算法很简单，这里的i就是当前key在散列表中对应的数组下标位置。 这里关键的就是ThreadLocalHashCode值的计算，ThreadLocal中有一个属性为HASH_INCREMENT = 0x61c88647 12345678910111213141516171819202122public class ThreadLocal&lt;T&gt; { private final int threadLocalHashCode = nextHashCode(); private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT); } static class ThreadLocalMap { ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } }} 每次创建一个ThreadLocal对象，这个ThreadLocal.nextHashCode这个值就会增长0x61c88647。这个数称为斐波那契数。使用斐波那契数作为hash增量，会使得hash分布非常均匀。如下图所示，分布均匀： ThreadLocalMap解决Hash冲突 下面的示例图中，绿色块Entry代表正常数据，灰色快代表Entry的key为null，已被垃圾回收。白色块代表Entry为null。 我们知道HashMap中解决冲突的方法是在数组上构造一个链表结构，冲突的数据会继续接到链表上，如果超过一定的数量则会将链表结构转化为红黑树。 而ThreadLocalMap并不存在链表结构，所以其处理hash冲突的方式与HashMap并不一样。如下图所示： 此时需要插入一个值为27的数据，通过哈希计算之后应该放在下标为4的位置，但是下标为4的位置已经有数据了，ThreadLocalMap的处理方式是继续向后寻找，一直找到Entry为null的位置才会停止查找并且将数据放入该位置中。当然在线性查找的过程中，如果遇到了Entry不为null且key值或者Entry中值为null的情况都会有不同的处理。 上图中有一个Entry的key为null的数据，原因就是前面所提到的因为key的类型是弱引用类型，所以会有这种数据的存在，但是在set的过程中，会对这些数据进行清理。 ThreadLocalMap.set()详解在往ThreadLocalMap中set数据的时候大概会遇到下面的几种情况： 要set数据的位置对应的Entry为空，这个时候只需要直接放入数据即可。 要set数据的位置存在数据，这个时候又要分几种情况： 该位置的key值与当前ThreadLocal通过hash计算获取的key值一致，这个时候直接更新该位置的数据。 在往后遍历的过程中，在找到Entry为null的位置之前，没有遇到key过期的Entry，那么就直接将数据放入Entry为null的位置。 在往后遍历的过程中，在找到key值相等的数据之前，没有遇到key过期的Entry，那么直接更新当前位置的数据。 在往后遍历的过程中，在找到Entry为null的位置之前，遇到key过期的Entry，如下图所示，在往后遍历的过程中，在index=7位置的Entry的key为null： index=7位置Entry的key已经被垃圾回收，那么就需要进行处理，避免内存泄漏。此时会执行replaceStaleEntry()方法，该方法的含义是替换过期数据，以index=7为起点开始扫描，进行探测式数据清理工作。 初始化探测式清理过期数据扫描的开始位置为：slotToExpunge = staleSlot = 7，以当前staleSlot开始向前迭代查找，找其他过期的数据，然后更新过期数据起始扫描下标slotToExpunge。for循环迭代，直到碰到Entry为null结束。如果找到了过期的数据，继续向前迭代，直到遇到Entry=null的槽位才停止迭代，如下图所示，slotToExpunge 被更新为 0： 上面向前迭代的操作是为了更新探测清理过期数据的起始下标slotToExpunge的值，这个值是用来判断当前过期槽位staleSlot之前是否还有过期元素。 接下来以staleSlot位置（index=7）向后迭代查找，如果找到了相同key值的Entry数据，如下图所示： 则会更新Entry的值并交换slateSlot元素的位置(slaleSlot位置为过期元素)，更新Entry数据，然后开始进行过期Entry的清理工作（从slotToExpunge=0的位置向后检查过期数据并且清理），如下图所示： 向后遍历的过程中，如果没有找到相同key值的Entry数据： 从当前节点staleSlot向后查找key值相等的Entry元素，直到Entry为null则停止寻找。通过上图可知，此时table中没有key值相同的Entry。 创建新的Entry，替换table[stableSlot]位置： 替换完成后也是进行过期元素清理工作，清理工作主要是有两个方法：expungeStaleEntry()和cleanSomeSlots()，这两个方法在后面会讲到。 ThreadLocalMap.set()源码详解123456789101112131415161718192021222324252627private void set(ThreadLocal&lt;?&gt; key, Object value) { // 通过key来计算在散列表中对应的位置，然后以当前key对应的桶的位置向后查找，找到可以使用的桶。 Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal&lt;?&gt; k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();} 什么样的桶可以被使用？ 要set的key和Entry中的key相等，需要替换，可以使用 碰到一个过期的桶，执行替换逻辑，占用过期桶 查找过程中，碰到桶中Entry=null的情况，直接使用 for循环中向前向后查找的逻辑是靠nextIndex()和prevIndex()方法实现，其源码如下： 1234567private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0);}private static int prevIndex(int i, int len) { return ((i - 1 &gt;= 0) ? i - 1 : len - 1);} 接着看剩下for循环中的逻辑： 遍历当前key值对应的桶中Entry数据为空，这说明散列数组这里没有数据冲突，跳出for循环，直接set数据到对应的桶中； 如果key值对应的桶中Entry数据不为空：2.1 如果k = key，说明当前set操作是一个替换操作，做替换逻辑后返回；2.2 如果key = null，说明当前桶位置的Entry是过期数据，执行replaceStaleEntry()方法(核心方法)，然后返回； for循环执行完毕，继续往下执行说明上面两种情况都不成立，向后迭代的过程中直到找到entry为null的情况：3.1 在Entry为null的桶中创建一个新的Entry对象3.2 执行++size操作 调用cleanSomeSlots()做一次启发式清理工作，清理散列数组中Entry的key过期的数据4.1 如果清理工作完成后，未清理到任何数据，且size超过了阈值(数组长度的 2/3)，进行rehash()操作4.2 rehash()中会先进行一轮探测式清理，清理过期key，清理完成后如果size &gt;= threshold - threshold / 4，就会执行真正的扩容逻辑(扩容逻辑往后看)。 接着重点看下replaceStaleEntry()方法，replaceStaleEntry()方法提供替换过期数据的功能，其源代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) { Entry[] tab = table; int len = tab.length; Entry e; int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); if (k == key) { e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; } if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; } tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);} slotToExpunge表示开始探测式清理过期数据的开始下标，默认从当前的staleSlot开始。以当前的staleSlot开始，向前迭代查找，找到没有过期的数据，for循环一直碰到Entry为null才会结束。如果向前找到了过期数据，更新探测清理过期数据的开始下标为 i，即slotToExpunge=i，其代码逻辑如下代码块： 12345678for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)){ if (e.get() == null){ slotToExpunge = i; }} 接着开始从staleSlot向后查找，也是碰到Entry为null的桶结束（其实这两个下标就相当于给了一个清理的区间）。 如果迭代过程中，碰到 k == key，这说明这里是替换逻辑，替换新数据并且交换当前staleSlot位置。如果slotToExpunge == staleSlot，这说明replaceStaleEntry()一开始向前查找过期数据时并未找到过期的Entry数据，接着向后查找过程中也未发现过期数据，修改开始探测式清理过期数据的下标为当前循环的 index，即slotToExpunge = i。最后调用cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);进行启发式过期数据清理。 123456789101112if (k == key) { e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 表明一开始向前查找数据并未找到过期的Entry，于是更新slotToExpunge为当前位置 if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return;} cleanSomeSlots()和expungeStaleEntry()方法后面都会细讲，这两个是和清理相关的方法，一个是过期key相关Entry的启发式清理(Heuristically scan)，另一个是过期key相关Entry的探测式清理。 123// 往后迭代的过程中如果没有找到k == key的数据，且碰到Entry为null的数据，则结束当前的迭代操作。此时说明这里是一个添加的逻辑，将新的数据添加到table[staleSlot] 对应的slot中。tab[staleSlot].value = null;tab[staleSlot] = new Entry(key, value); 最后判断除了staleSlot以外，还发现了其他过期的slot数据，就要开启清理数据的逻辑： 12if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); ThreadLocalMap过期 key 的探测式清理流程ThreadLocalMap对过期key的清理方式有两种：探测式清理和启发式清理。 探测式清理探测式清理执行expungeStaleEntry方法，遍历散列数组，从开始位置向后清理过期的数据，将过期数据的Entry设置为null，沿途中碰到为过期的数据则将此数据rehash后重新在table中定位，如果定位的位置已经存在数据，则会将未过期的数据放到靠近此位置的Entry为null的桶中，使得rehash之后的数据的Entry位置距离正确的桶的位置更近一些。具体如下图所示： set(27)经过哈希计算之后应该放在index=4的位置，由于index=4的位置已经有数据，所以需要向后遍历最终将数据放在index=7的位置，放入一段时间后index=5中的Entry中数据key为null。 如果此时有其他数据需要放入到map中，则会出发探测式清理操作。如上图所示，执行探测式清理后，index=5的数据被清理掉，继续往后迭代，到了index=7的位置时，经过rehash操作发现该元素正确的位置应该为index=4，但是这个位置已经存在数据，向后查找离index=4最近的Entry=null的节点（刚刚被清理掉index=5），于是就将index=7的数据移动到index=5的位置中。 经过一轮探测式清理后，key过期的数据会被清理掉，没过期的数据经过rehash重定位后所处的桶位置理论上更接近i= key.hashCode &amp; (tab.len - 1)的位置。这种优化会提高整个散列表查询性能。 接着看下expungeStaleEntry()具体流程，先通过原理图来介绍其大致流程，假设expungeStaleEntry(3) 来调用此方法，如下图所示，可以看到ThreadLocalMap中table的数据情况，接着执行清理操作： 第一步是清空当前staleSlot位置的数据，index=3位置的Entry变成了null。然后接着往后探测： 执行完第二步后，如性爱图所示，index=4 的元素挪到index=3的槽位中。 继续往后迭代检查，碰到正常数据，计算该数据位置是否偏移，如果被偏移，则重新计算slot位置，目的是让正常数据尽可能存放在正确位置或离正确位置更近的位置。 在往后迭代的过程中碰到空的槽位，终止探测，这样一轮探测式清理工作就完成了，其具体实现源代码如下： 1234567891011121314151617181920212223242526272829303132333435private int expungeStaleEntry(int staleSlot) { Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?&gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } else { int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } 这里还是以staleSlot=3 来做示例说明，首先是将tab[staleSlot]槽位的数据清空，然后设置size-- 接着以staleSlot位置往后迭代，如果遇到k==null的过期数据，也是清空该槽位数据，然后size-- 123456ThreadLocal&lt;?&gt; k = e.get();if (k == null) { e.value = null; tab[i] = null; size--;} 如果key没有过期，重新计算当前key的下标位置是不是当前槽位下标位置，如果不是，那么说明产生了hash冲突，此时以新计算出来正确的槽位位置往后迭代，找到最近一个可以存放entry的位置。 12345678910// 计算hashcode 判断其是否是当前位置int h = k.threadLocalHashCode &amp; (len - 1);if (h != i) { tab[i] = null; // 找到离h最近的位置存放entry while (tab[h] != null) h = nextIndex(h, len); tab[h] = e;} 这里是处理正常的产生Hash冲突的数据，经过迭代后，有过Hash冲突数据的Entry位置会更靠近正确位置，这样可以提高查询时候的效率。 ThreadLocalMap扩容机制在ThreadLocalMap.set()方法的最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中Entry的数量已经达到了列表的扩容阈值(len*2/3)，就开始执行rehash()逻辑： 12if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); 以下是rehash()的具体实现： 12345678910111213141516private void rehash() { expungeStaleEntries(); if (size &gt;= threshold - threshold / 4) resize();}private void expungeStaleEntries() { Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) { Entry e = tab[j]; if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); }} 这里首先会执行探测式清理操作，从table的起始位置向后遍历进行清理。清理完成之后，再来通过判断size &gt;= threshold - threshold / 4来决定是否进行扩容操作。 而上文讲到的rehash()操作是在size&gt;=threshold，也就是先判断size&gt;=threshold以此来决定是否执行rehash操作，rehash()操作会继续探测式清理工作，清理完成之后再判断size &gt;= threshold - threshold / 4以此来觉得是否进行resize()操作，如下图所示： 接下来看一下resize()方法，其源码如下： 扩容后的tab的大小为oldLen*2，然后会遍历旧的散列表，重新哈希计算元素的位置，然后将其放到新的tab数组中，如果出现hash冲突则会往后寻找最近的entry为null的位置，遍历完成之后，oldTab中所有entry数据都已经放到newTab中。重新计算下次扩容的阈值setThreshold(newLen)。 123456789101112131415161718192021222324252627private void resize() { Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) { Entry e = oldTab[j]; if (e != null) { ThreadLocal&lt;?&gt; k = e.get(); if (k == null) { e.value = null; } else { int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; } } } setThreshold(newLen); size = count; table = newTab;} ThreadLocalMap.get()详解首先通过图来展示get()方法的流程，大致分为两种情况： 通过查找key值计算出其在散列表中的位置，然后如果该位置中的Entry的key和查找的key一致，那么直接将value返回 通过查找key值计算出其在散列表中的位置，但是该位置中的Entry的key和查找的key不一致，如下图所示： 以get(ThreadLocal1)为例，通过hash计算后，正确的slot位置应该是 4，而index=4的槽位已经有了数据，且key值不等于ThreadLocal1，所以需要继续往后迭代查找。 迭代到index=5的数据时，此时Entry的key=null，触发一次探测式数据回收操作，执行expungeStaleEntry()方法，执行完后，index 5,8的数据都会被回收，而index 6,7的数据都会前移，此时继续往后迭代，到index = 6的时候即找到了key值相等的Entry数据，如下图所示： 其源码如下： 12345678910111213141516171819202122232425private Entry getEntry(ThreadLocal&lt;?&gt; key) { int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);}private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null;} ThreadLocalMap过期key的启发式清理流程上面介绍的都是ThreadLocalMap过期key的探测式清理，接下来介绍启发式清理流程（Heuristically scan some cells looking for stale entries.）如下图所示： 其源码如下： 123456789101112131415private boolean cleanSomeSlots(int i, int n) { boolean removed = false; Entry[] tab = table; int len = tab.length; do { i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) { n = len; removed = true; i = expungeStaleEntry(i); } } while ( (n &gt;&gt;&gt;= 1) != 0); return removed;} InheritableThreadLocal使用ThreadLocal的时候，在异步场景下是无法给子线程共享父线程中创建的线程副本数据的。为了解决这个问题，JDK 中还有一个InheritableThreadLocal类： 12345678910111213141516public class InheritableThreadLocalDemo { public static void main(String[] args) { ThreadLocal&lt;String&gt; ThreadLocal = new ThreadLocal&lt;&gt;(); ThreadLocal&lt;String&gt; inheritableThreadLocal = new InheritableThreadLocal&lt;&gt;(); ThreadLocal.set(&quot;父类数据:threadLocal&quot;); inheritableThreadLocal.set(&quot;父类数据:inheritableThreadLocal&quot;); new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;子线程获取父类ThreadLocal数据：&quot; + ThreadLocal.get()); System.out.println(&quot;子线程获取父类inheritableThreadLocal数据：&quot; + inheritableThreadLocal.get()); } }).start(); }} 输出如下： 12子线程获取父类ThreadLocal数据：null子线程获取父类inheritableThreadLocal数据：父类数据:inheritableThreadLocal 实现原理是子线程是通过在父线程中通过调用new Thread()方法来创建子线程，Thread#init方法在Thread的构造方法中被调用。在init方法中拷贝父线程数据到子线程中： 12345678910111213private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(&quot;name cannot be null&quot;); } if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); this.stackSize = stackSize; tid = nextThreadID();} 但InheritableThreadLocal仍然有缺陷，一般我们做异步化处理都是使用的线程池，而InheritableThreadLocal是在new Thread中的init()方法给赋值的，而线程池是线程复用的逻辑，所以这里会存在问题。阿里巴巴开源了一个TransmittableThreadLocal组件就可以解决这个问题。 ThreadLocal项目中使用实战ThreadLocal使用场景我们现在项目中日志记录用的是ELK+Logstash，最后在Kibana中进行展示和检索。 现在都是分布式系统统一对外提供服务，项目间调用的关系可以通过 traceId 来关联，但是不同项目之间如何传递 traceId 呢？ 这里我们使用 org.slf4j.MDC 来实现此功能，内部就是通过 ThreadLocal 来实现的，具体实现如下： 当前端发送请求到服务 A时，服务 A会生成一个类似UUID的traceId字符串，将此字符串放入当前线程的ThreadLocal中，在调用服务 B的时候，将traceId写入到请求的Header中，服务 B在接收请求时会先判断请求的Header中是否有traceId，如果存在则写入自己线程的ThreadLocal中。 图中的requestId即为我们各个系统链路关联的traceId，系统间互相调用，通过这个requestId即可找到对应链路，这里还有会有一些其他场景： 针对于这些场景，我们都可以有相应的解决方案，如下所示 Feign远程调用解决方案服务发送请求： 123456789101112@Component@Slf4jpublic class FeignInvokeInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate template) { String requestId = MDC.get(&quot;requestId&quot;); if (StringUtils.isNotBlank(requestId)) { template.header(&quot;requestId&quot;, requestId); } }} 服务接收请求： 123456789101112131415161718192021222324@Slf4j@Componentpublic class LogInterceptor extends HandlerInterceptorAdapter { @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) { MDC.remove(&quot;requestId&quot;); } @Override public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) { } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String requestId = request.getHeader(BaseConstant.REQUEST_ID_KEY); if (StringUtils.isBlank(requestId)) { requestId = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;); } MDC.put(&quot;requestId&quot;, requestId); return true; }} 线程池异步调用，requestId 传递因为MDC是基于ThreadLocal去实现的，异步过程中，子线程并没有办法获取到父线程ThreadLocal存储的数据，所以这里可以自定义线程池执行器，修改其中的run()方法： 1234567891011121314151617181920public class MyThreadPoolTaskExecutor extends ThreadPoolTaskExecutor { @Override public void execute(Runnable runnable) { Map&lt;String, String&gt; context = MDC.getCopyOfContextMap(); super.execute(() -&gt; run(runnable, context)); } @Override private void run(Runnable runnable, Map&lt;String, String&gt; context) { if (context != null) { MDC.setContextMap(context); } try { runnable.run(); } finally { MDC.remove(); } }} 使用 MQ 发送消息给第三方系统在 MQ 发送的消息体中自定义属性requestId，接收方消费消息后，自己解析requestId使用即可。","link":"/Java/threadlocal%E8%AF%A6%E8%A7%A3/"},{"title":"从ReentrantLock的角度分析AQS的原理以及应用","text":"从ReentrantLock的角度分析AQS的原理以及应用 本文转载自美团技术团队从ReentrantLock的实现看AQS的原理及应用 前言Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。AQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。本文会从应用层逐渐深入到原理层，并通过ReentrantLock的基本特性和ReentrantLock与AQS的关联，来深入解读AQS相关独占锁的知识点，同时采取问答的模式来帮助大家理解AQS。由于篇幅原因，本篇文章主要阐述AQS中独占锁的逻辑和Sync Queue，不讲述包含共享锁和Condition Queue的部分（本篇文章核心为AQS原理剖析，只是简单介绍了ReentrantLock，感兴趣同学可以阅读一下ReentrantLock的源码）。 下面列出本篇文章的大纲和思路，以便于大家更好地理解： 1 ReentrantLock1.1 ReentrantLock特性概览ReentrantLock意思为可重入锁，指的是一个线程能够对一个临界资源重复加锁。为了帮助大家更好地理解ReentrantLock的特性，我们先将ReentrantLock跟常用的Synchronized进行比较，其特性如下（蓝色部分为本篇文章主要剖析的点）： 下面通过伪代码，进行更加直观的比较： 1234567891011121314151617181920212223242526272829// **************************Synchronized的使用方式**************************// 1.用于代码块synchronized (this) {}// 2.用于对象synchronized (object) {}// 3.用于方法public synchronized void test () {}// 4.可重入for (int i = 0; i &lt; 100; i++) { synchronized (this) {}}// **************************ReentrantLock的使用方式**************************public void test () throw Exception { // 1.初始化选择公平锁、非公平锁 ReentrantLock lock = new ReentrantLock(true); // 2.可用于代码块 lock.lock(); try { try { // 3.支持多种加锁方式，比较灵活; 具有可重入特性 if(lock.tryLock(100, TimeUnit.MILLISECONDS)){ } } finally { // 4.手动释放锁 lock.unlock() } } finally { lock.unlock(); }} 1.2 ReentrantLock与AQS的关联通过上文我们已经了解，ReentrantLock支持公平锁和非公平锁（关于公平锁和非公平锁的原理分析，可参考《不可不说的Java“锁”事》），并且ReentrantLock的底层就是由AQS来实现的。那么ReentrantLock是如何通过公平锁和非公平锁与AQS关联起来呢？ 我们着重从这两者的加锁过程来理解一下它们与AQS之间的关系（加锁过程中与AQS的关联比较明显，解锁流程后续会介绍）。 非公平锁源码中的加锁流程如下： 12345678910111213// java.util.concurrent.locks.ReentrantLock#NonfairSync// 非公平锁static final class NonfairSync extends Sync { ... final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } ...} 这块代码的含义为： 若通过CAS设置变量State（同步状态）成功，也就是获取锁成功，则将当前线程设置为独占线程。 若通过CAS设置变量State（同步状态）失败，也就是获取锁失败，则进入Acquire方法进行后续处理。 第一步很好理解，但第二步获取锁失败后，后续的处理策略是怎么样的呢？这块可能会有以下思考： 某个线程获取锁失败的后续流程是什么呢？有以下两种可能： (1) 将当前线程获锁结果设置为失败，获取锁流程结束。这种设计会极大降低系统的并发度，并不满足我们实际的需求。所以就需要下面这种流程，也就是AQS框架的处理流程。 (2) 存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。 对于问题1的第二种情况，既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ 处于排队等候机制中的线程，什么时候可以有机会获取锁呢？ 如果处于排队等候机制中的线程一直无法获取锁，还是需要一直等待吗，还是有别的策略来解决这一问题？ 带着非公平锁的这些问题，再看下公平锁源码中获锁的方式： 123456789// java.util.concurrent.locks.ReentrantLock#FairSyncstatic final class FairSync extends Sync { ... final void lock() { acquire(1); } ...} 看到这块代码，我们可能会存在这种疑问：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？ 结合公平锁和非公平锁的加锁流程，虽然流程上有一定的不同，但是都调用了Acquire方法，而Acquire方法是FairSync和UnfairSync的父类AQS中的核心方法。 对于上边提到的问题，其实在ReentrantLock类源码中都无法解答，而这些问题的答案，都是位于Acquire方法所在的类AbstractQueuedSynchronizer中，也就是本文的核心——AQS。下面我们会对AQS以及ReentrantLock和AQS的关联做详细介绍（相关问题答案会在2.3.5小节中解答）。 2 AQS首先，我们通过下面的架构图来整体了解一下AQS框架： 上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 下面我们会从整体到细节，从流程到方法逐一剖析AQS框架，主要分析过程如下： 2.1 原理概览AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 主要原理图如下： AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 2.1.1 AQS数据结构先来看下AQS中最基本的数据结构——Node，Node即为上面CLH变体队列中的节点。 解释一下几个方法和属性值的含义： 方法和属性值 含义 waitStatus 当前节点在队列中的状态 thread 表示处于该节点的线程 prev 前驱指针 predecessor 返回前驱节点，没有的话抛出npe nextWaiter 指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍） next 后继指针 线程两种锁的模式： 模式 含义 SHARED 表示线程以共享的模式等待锁 EXCLUSIVE 表示线程正在以独占的方式等待锁 waitStatus有下面几个枚举值： 枚举 含义 0 当一个Node被初始化的时候的默认值 CANCELLED 为1，表示线程获取锁的请求已经取消了 CONDITION 为-2，表示节点在等待队列中，节点线程等待唤醒 PROPAGATE 为-3，当前线程处在SHARED情况下，该字段才会使用 SIGNAL 为-1，表示线程已经准备好了，就等资源释放了 2.1.2 同步状态State在了解数据结构后，接下来了解一下AQS的同步状态——State。AQS中维护了一个名为state的字段，意为同步状态，是由Volatile修饰的，用于展示当前临界资源的获锁情况。 123// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate volatile int state; 下面提供了几个访问这个字段的方法： 方法名 描述 protected final int getState() 获取State的值 protected final void setState(int newState) 设置State的值 protected final boolean compareAndSetState(int expect, int update) 使用CAS方式更新State 这几个方法都是Final修饰的，说明子类中无法重写它们。我们可以通过修改State字段表示的同步状态来实现多线程的独占模式和共享模式（加锁过程）。 对于我们自定义的同步工具，需要自定义获取同步状态和释放状态的方式，也就是AQS架构图中的第一层：API层。 2.2 AQS重要方法与ReentrantLock的关联从架构图中可以得知，AQS提供了大量用于自定义同步器实现的Protected方法。自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（ReentrantLock需要实现的方法如下，并不是全部）： 方法名 描述 protected boolean isHeldExclusively() 该线程是否正在独占资源。只有用到Condition才需要去实现它。 protected boolean tryAcquire(int arg) 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 protected boolean tryRelease(int arg) 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 protected int tryAcquireShared(int arg) 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 protected boolean tryReleaseShared(int arg) 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。 以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。 为了帮助大家理解ReentrantLock和AQS之间方法的交互过程，以非公平锁为例，我们将加锁和解锁的交互流程单独拎出来强调一下，以便于对后续内容的理解。 加锁： 通过ReentrantLock的加锁方法Lock进行加锁操作。 会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。 AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。 tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。 解锁： 通过ReentrantLock的解锁方法Unlock进行解锁。 Unlock会调用内部类Sync的Release方法，该方法继承于AQS。 Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。 释放成功后，所有处理由AQS框架完成，与自定义同步器无关。 通过上面的描述，大概可以总结出ReentrantLock加锁解锁时API层核心方法的映射关系。 2.3 通过ReentrantLock理解AQSReentrantLock中公平锁和非公平锁在底层是相同的，这里以非公平锁为例进行分析。 在非公平锁中，有一段这样的代码： 123456789101112// java.util.concurrent.locks.ReentrantLockstatic final class NonfairSync extends Sync { ... final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } ...} 看一下这个Acquire是怎么写的： 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 再看一下tryAcquire方法： 12345// java.util.concurrent.locks.AbstractQueuedSynchronizerprotected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();} 可以看出，这里只是AQS的简单实现，具体获取锁的实现方法是由各自的公平锁和非公平锁单独实现的（以ReentrantLock为例）。如果该方法返回了True，则说明当前线程获取锁成功，就不用往后执行了；如果获取失败，就需要加入到等待队列中。下面会详细解释线程是何时以及怎样被加入进等待队列中的。 2.3.1 线程加入等待队列2.3.1.1 加入队列的时机当执行Acquire(1)时，会通过tryAcquire获取锁。在这种情况下，如果获取锁失败，就会调用addWaiter加入到等待队列中去。 2.3.1.2 如何加入队列获取锁失败后，会执行addWaiter(Node.EXCLUSIVE)加入等待队列，具体实现方法如下： 12345678910111213141516171819// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node;}private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update);} 主要的流程如下： 通过当前的线程和锁模式新建一个节点。 Pred指针指向尾节点Tail。 将New中Node的Prev指针指向Pred。 通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。 12345678910111213// java.util.concurrent.locks.AbstractQueuedSynchronizerstatic { try { stateOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(&quot;state&quot;)); headOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(&quot;head&quot;)); tailOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(&quot;tail&quot;)); waitStatusOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(&quot;waitStatus&quot;)); nextOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(&quot;next&quot;)); } catch (Exception ex) { throw new Error(ex); }} 从AQS的静态代码块可以看出，都是获取一个对象的属性相对于该对象在内存当中的偏移量，这样我们就可以根据这个偏移量在对象内存当中找到这个属性。tailOffset指的是tail对应的偏移量，所以这个时候会将new出来的Node置为当前队列的尾节点。同时，由于是双向链表，也需要将前一个节点指向尾节点。 如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。 1234567891011121314151617// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} 如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。 总结一下，线程获取锁的时候，过程大体如下： 当没有线程获取到锁时，线程1获取锁成功。 线程2申请锁，但是锁被线程1占有。 如果再有线程要获取锁，依次在队列中往后排队即可。 回到上边的代码，hasQueuedPredecessors是公平锁加锁时判断等待队列中是否存在有效节点的方法。如果返回False，说明当前线程可以争取共享资源；如果返回True，说明队列中存在有效节点，当前线程必须加入到等待队列中。 1234567891011// java.util.concurrent.locks.ReentrantLockpublic final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());} 看到这里，我们理解一下h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());为什么要判断的头结点的下一个节点？第一个节点储存的数据是什么？ 双向链表中，第一个节点为虚节点，其实并不存储任何信息，只是占位。真正的第一个有数据的节点，是在第二个节点开始的。当h != t时： 如果(s = h.next) == null，等待队列正在有线程进行初始化，但只是进行到了Tail指向Head，没有将Head指向Tail，此时队列中有元素，需要返回True（这块具体见下边代码分析）。 如果(s = h.next) != null，说明此时队列中至少有一个有效节点。如果此时s.thread == Thread.currentThread()，说明等待队列的第一个有效节点中的线程与当前线程相同，那么当前线程是可以获取资源的；如果s.thread != Thread.currentThread()，说明等待队列的第一个有效节点线程与当前线程不同，当前线程必须加入进等待队列。 123456789101112// java.util.concurrent.locks.AbstractQueuedSynchronizer#enqif (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head;} else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; }} 节点入队不是原子操作，所以会出现短暂的head != tail，此时Tail指向最后一个节点，而且Tail指向Head。如果Head没有指向Tail（可见5、6、7行），这种情况下也需要将相关线程加入队列中。所以这块代码是为了解决极端情况下的并发问题。 2.3.1.3 等待队列中线程出队列时机回到最初的源码： 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 上文解释了addWaiter方法，这个方法其实就是把对应的线程以Node的数据结构形式加入到双端队列里，返回的是一个包含该线程的Node。而这个Node会作为参数，进入到acquireQueued方法中。acquireQueued方法可以对排队中的线程进行“获锁”操作。 总的来说，一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取锁，直到获取成功或者不再需要获取（中断）。 下面我们从“何时出队列？”和“如何出队列？”两个方向来分析一下acquireQueued源码： 1234567891011121314151617181920212223242526272829// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) { // 标记是否成功拿到资源 boolean failed = true; try { // 标记等待过程中是否中断过 boolean interrupted = false; // 开始自旋，要么获取锁，要么中断 for (;;) { // 获取当前节点的前驱节点 final Node p = node.predecessor(); // 如果p是头结点，说明当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点） if (p == head &amp;&amp; tryAcquire(arg)) { // 获取锁成功，头指针移动到当前node setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。具体两个方法下面细细分析 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 注：setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。 123456789101112131415161718192021222324252627282930// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void setHead(Node node) { head = node; node.thread = null; node.prev = null;}// java.util.concurrent.locks.AbstractQueuedSynchronizer// 靠前驱节点判断当前线程是否应该被阻塞private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 获取头结点的节点状态 int ws = pred.waitStatus; // 说明头结点处于唤醒状态 if (ws == Node.SIGNAL) return true; // 通过枚举值我们知道waitStatus&gt;0是取消状态 if (ws &gt; 0) { do { // 循环向前查找取消节点，把取消节点从队列中剔除 node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 设置前任节点等待状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false;} parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted();} 上述方法的流程图如下： 从上图可以看出，跳出当前循环的条件是当“前置节点是头结点，且当前线程获取锁成功”。为了防止因死循环导致CPU资源被浪费，我们会判断前置节点的状态来决定是否要将当前线程挂起，具体挂起流程用流程图表示如下（shouldParkAfterFailedAcquire流程）： 从队列中释放节点的疑虑打消了，那么又有新问题了： shouldParkAfterFailedAcquire中取消节点是怎么生成的呢？什么时候会把一个节点的waitStatus设置为-1？ 是在什么时间释放节点通知到被挂起的线程呢？ 2.3.2 CANCELLED状态节点生成acquireQueued方法中的Finally代码： 12345678910111213141516171819// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { ... for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { ... failed = false; ... } ... } finally { if (failed) cancelAcquire(node); }} 通过cancelAcquire方法，将Node的状态标记为CANCELLED。接下来，我们逐行来分析这个方法的原理： 123456789101112131415161718192021222324252627282930313233343536// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void cancelAcquire(Node node) { // 将无效节点过滤 if (node == null) return; // 设置该节点不关联任何线程，也就是虚节点 node.thread = null; Node pred = node.prev; // 通过前驱节点，跳过取消状态的node while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 获取过滤后的前驱节点的后继节点 Node predNext = pred.next; // 把当前node的状态设置为CANCELLED node.waitStatus = Node.CANCELLED; // 如果当前节点是尾节点，将从后往前的第一个非取消状态的节点设置为尾节点 // 更新失败的话，则进入else，如果更新成功，将tail的后继节点设置为null if (node == tail &amp;&amp; compareAndSetTail(node, pred)) { compareAndSetNext(pred, predNext, null); } else { int ws; // 如果当前节点不是head的后继节点，1:判断当前节点前驱节点的是否为SIGNAL，2:如果不是，则把前驱节点设置为SINGAL看是否成功 // 如果1和2中有一个为true，再判断当前节点的线程是否为null // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) { Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); } else { // 如果当前节点是head的后继节点，或者上述条件不满足，那就唤醒当前节点的后继节点 unparkSuccessor(node); } node.next = node; // help GC }} 当前的流程： 获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus &lt;= 0的节点，将找到的Pred节点和当前Node关联，将当前Node设置为CANCELLED。 根据当前节点的位置，考虑以下三种情况： (1) 当前节点是尾节点。 (2) 当前节点是Head的后继节点。 (3) 当前节点不是Head的后继节点，也不是尾节点。 根据上述第二条，我们来分析每一种情况的流程。 当前节点是尾节点。 当前节点是Head的后继节点。 当前节点不是Head的后继节点，也不是尾节点。 通过上面的流程，我们对于CANCELLED节点状态的产生和变化已经有了大致的了解，但是为什么所有的变化都是对Next指针进行了操作，而没有对Prev指针进行操作呢？什么情况下会对Prev指针进行操作？ 执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了（已经执行过Try代码块中的shouldParkAfterFailedAcquire方法了），如果此时修改Prev指针，有可能会导致Prev指向另一个已经移除队列的Node，因此这块变化Prev指针不安全。 shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理Prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会出现变化，因此这个时候变更Prev指针比较安全。 123do { node.prev = pred = pred.prev;}while (pred.waitStatus &gt; 0); 2.3.3 如何解锁我们已经剖析了加锁过程中的基本流程，接下来再对解锁的基本流程进行分析。由于ReentrantLock在解锁的时候，并不区分公平锁和非公平锁，所以我们直接看解锁的源码： 12345// java.util.concurrent.locks.ReentrantLockpublic void unlock() { sync.release(1);} 可以看到，本质释放锁的地方，是通过框架来完成的。 1234567891011// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。 123456789101112131415161718// java.util.concurrent.locks.ReentrantLock.Sync// 方法返回当前锁是不是没有被线程持有protected final boolean tryRelease(int releases) { // 减少可重入次数 int c = getState() - releases; // 当前线程不是持有锁的线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 我们来解释下述源码： 1234567891011121314// java.util.concurrent.locks.AbstractQueuedSynchronizerpublic final boolean release(int arg) { // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有 if (tryRelease(arg)) { // 获取头结点 Node h = head; // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 这里的判断条件为什么是h != null &amp;&amp; h.waitStatus != 0？ h == null Head还没初始化。初始情况下，head == null，第一个节点入队，Head会被初始化一个虚拟节点。所以说，这里如果还没来得及入队，就会出现head == null 的情况。 h != null &amp;&amp; waitStatus == 0 表明后继节点对应的线程仍在运行中，不需要唤醒。 h != null &amp;&amp; waitStatus &lt; 0 表明后继节点可能被阻塞了，需要唤醒。 再看一下unparkSuccessor方法： 123456789101112131415161718192021// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate void unparkSuccessor(Node node) { // 获取头结点waitStatus int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 获取当前节点的下一个节点 Node s = node.next; // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点 if (s == null || s.waitStatus &gt; 0) { s = null; // 就从尾部节点开始找，到队首，找到队列第一个waitStatus&lt;0的节点。 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } // 如果当前节点的下个节点不为空，而且状态&lt;=0，就把当前节点unpark if (s != null) LockSupport.unpark(s.thread);} 为什么要从后往前找第一个非Cancelled的节点呢？原因如下。 之前的addWaiter方法： 12345678910111213141516// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node;} 我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev = pred; compareAndSetTail(pred, node) 这两个地方可以看作Tail入队的原子操作，但是此时pred.next = node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。 综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？ 2.3.4 中断恢复后的执行流程唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。 123456// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted();} 再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。 12345678910111213141516171819202122// java.util.concurrent.locks.AbstractQueuedSynchronizerfinal boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 如果acquireQueued为True，就会执行selfInterrupt方法。 12345// java.util.concurrent.locks.AbstractQueuedSynchronizerstatic void selfInterrupt() { Thread.currentThread().interrupt();} 该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下： 当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。 线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。 这里的处理方式主要是运用线程池中基本运作单元Worder中的runWorker，通过Thread.interrupted()进行额外的判断处理，感兴趣的同学可以看下ThreadPoolExecutor源码。 2.3.5 小结我们在1.3小节中提出了一些问题，现在来回答一下。 Q：某个线程获取锁失败的后续流程是什么呢？ A：存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。 Q：既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ A：是CLH变体的FIFO双端队列。 Q：处于排队等候机制中的线程，什么时候可以有机会获取锁呢？ A：可以详细看下2.3.1.3小节。 Q：如果处于排队等候机制中的线程一直无法获取锁，需要一直等待么？还是有别的策略来解决这一问题？ A：线程所在节点的状态会变成取消状态，取消状态的节点会从队列中释放，具体可见2.3.2小节。 Q：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？ A：AQS的Acquire会调用tryAcquire方法，tryAcquire由各个自定义同步器实现，通过tryAcquire完成加锁过程。 3 AQS应用3.1 ReentrantLock的可重入应用ReentrantLock的可重入性是AQS很好的应用之一，在了解完上述知识点以后，我们很容易得知ReentrantLock实现可重入的方法。在ReentrantLock里面，不管是公平锁还是非公平锁，都有一段逻辑。 公平锁： 123456789101112131415// java.util.concurrent.locks.ReentrantLock.FairSync#tryAcquireif (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; }}else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true;} 非公平锁： 123456789101112131415// java.util.concurrent.locks.ReentrantLock.Sync#nonfairTryAcquireif (c == 0) { if (compareAndSetState(0, acquires)){ setExclusiveOwnerThread(current); return true; }}else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true;} 从上面这两段都可以看到，有一个同步状态State来控制整体可重入的情况。State是Volatile修饰的，用于保证一定的可见性和有序性。 123// java.util.concurrent.locks.AbstractQueuedSynchronizerprivate volatile int state; 接下来看State这个字段主要的过程： State初始化的时候为0，表示没有任何线程持有锁。 当有线程持有该锁时，值就会在原来的基础上+1，同一个线程多次获得锁是，就会多次+1，这里就是可重入的概念。 解锁也是对这个字段-1，一直到0，此线程对锁释放。 3.2 JUC中的应用场景除了上边ReentrantLock的可重入性的应用，AQS作为并发编程的框架，为很多其他同步工具提供了良好的解决方案。下面列出了JUC中的几种同步工具，大体介绍一下AQS的应用场景： 同步工具 同步工具与AQS的关联 ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 3.3 自定义同步工具了解AQS基本原理以后，按照上面所说的AQS知识点，自己实现一个同步工具。 123456789101112131415161718192021222324252627282930public class LeeLock { private static class Sync extends AbstractQueuedSynchronizer { @Override protected boolean tryAcquire (int arg) { return compareAndSetState(0, 1); } @Override protected boolean tryRelease (int arg) { setState(0); return true; } @Override protected boolean isHeldExclusively () { return getState() == 1; } } private Sync sync = new Sync(); public void lock () { sync.acquire(1); } public void unlock () { sync.release(1); }} 通过我们自己定义的Lock完成一定的同步功能。 1234567891011121314151617181920212223242526272829303132public class LeeMain { static int count = 0; static LeeLock leeLock = new LeeLock(); public static void main (String[] args) throws InterruptedException { Runnable runnable = new Runnable() { @Override public void run () { try { leeLock.lock(); for (int i = 0; i &lt; 10000; i++) { count++; } } catch (Exception e) { e.printStackTrace(); } finally { leeLock.unlock(); } } }; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(count); }} 上述代码每次运行结果都会是20000。通过简单的几行代码就能实现同步功能，这就是AQS的强大之处。 总结我们日常开发中使用并发的场景太多，但是对并发内部的基本框架原理了解的人却不多。由于篇幅原因，本文仅介绍了可重入锁ReentrantLock的原理和AQS原理，希望能够成为大家了解AQS和ReentrantLock等同步器的“敲门砖”。 参考资料 Lea D. The java. util. concurrent synchronizer framework[J]. Science of Computer Programming, 2005, 58(3): 293-309. 《Java并发编程实战》 不可不说的Java“锁”事","link":"/Java/%E4%BB%8Ereentrantlock%E7%9A%84%E8%A7%92%E5%BA%A6%E5%88%86%E6%9E%90aqs%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8/"},{"title":"Java线程池介绍","text":"线程池为什么要使用线程池？ 池化技术 (Pool) 是一种很常见的编程技巧，在请求量大时能明显优化应用性能，降低系统频繁建连的资源开销。我们日常工作中常见的有数据库连接池、线程池、对象池等，它们的特点都是将 “昂贵的”、“费时的” 的资源维护在一个特定的 “池子” 中，规定其最小连接数、最大连接数、阻塞队列等配置，方便进行统一管理和复用，通常还会附带一些探活机制、强制回收、监控一类的配套功能。 普通情况下，我们需要使用线程的时候就直接去创建一个线程，这样子操作的方式十分简单，但是在高并发的情况下就会产生问题： 并发的线程数量过多，而每个线程完成其任务后便会被销毁，往往其执行的时间很短，这样频繁地创建线程就会大大降低系统的效率，因为频繁创建和销毁线程时间的开销很大。 线程池提供了一种限制和管理资源的Pool。每个线程池还会维护一些基本信息，例如已经完成任务的数量。线程池可以使得线程可以复用，就是执行完一个任务但不被销毁，而是可以继续执行其他的任务。 《Java 并发编程的艺术》中关于使用线程池的优点： 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 实现Runnable接口和Callable接口的区别两者最大的区别，实现Callable接口的任务线程能返回执行结果，而实现Runnable接口的任务线程不能返回执行结果。Runnable自Java 1.0以来就一直存在，而Callable在Java 1.5后才加入，目的就是为了处理Runnable不支持的场景。 工具类 Executors 可以实现将 Runnable 对象转换成 Callable 对象。（Executors.callable(Runnable task) 或 Executors.callable(Runnable task, Object result)） Runnable.java 1234567@FunctionalInterfacepublic interface Runnable { /** * 被线程执行，没有返回值也无法抛出异常 */ public abstract void run();} Callable.java 123456789@FunctionalInterfacepublic interface Callable&lt;V&gt; { /** * 计算结果，或在无法这样做时抛出异常。 * @return 计算得出的结果 * @throws 如果无法计算结果，则抛出异常 */ V call() throws Exception;} 执行execute()方法和submit()方法的区别 execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。 submit()方法用于提交需要返回值的任务。线程池会返回一个Future类型的对象。通过这个Future对象可以判断任务是否执行成功，并且可以通过Future对象的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get(long timeout,TimeUnit unit)方法则会阻塞当前线程一段时间后直接返回，这时候有可能任务还没有执行完。 接下来看一下AbstractExecutorService 接口下的sumbit方法： 123456public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } 上面的方法中调用了newTaskFor方法并且返回了一个FutureTask对象： 123protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { return new FutureTask&lt;T&gt;(runnable, value);} 而excute()方法没有返回值： 123public void execute(Runnable command) { ...} 示例一：使用get()方法获取返回值 1234567891011121314ExecutorService executorService = Executors.newFixedThreadPool(3);Future&lt;String&gt; submit = executorService.submit(() -&gt; { try { Thread.sleep(5000L); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;abc&quot;;});String s = submit.get();System.out.println(s);executorService.shutdown(); 输出： 1abc 示例2：使用get(long timeout,TimeUnit unit)方法获取返回值 1234567891011121314ExecutorService executorService = Executors.newFixedThreadPool(3);Future&lt;String&gt; submit = executorService.submit(() -&gt; { try { Thread.sleep(5000L); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;abc&quot;;});String s = submit.get(3, TimeUnit.SECONDS);System.out.println(s);executorService.shutdown(); 输出： 123Exception in thread &quot;main&quot; java.util.concurrent.TimeoutException at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204) at Test.main(Test.java:42) 如何创建线程池方法一：通过构造方法 ThreadPoolExecutor 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么），这里就不贴代码讲了，比较简单。 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;} ThreadPoolExecutor 3 个最重要的参数： corePoolSize : 核心线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数: keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 ThreadPoolExecutor 饱和策略定义: 简单来说，在执行execute()方法时如果状态一直是RUNNING时，的执行过程如下： 如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务；如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中；如果workerCount &gt;= corePoolSize 并且 workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务；如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy： 抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy： 由调用线程处理该任务 ，也就是直接由调用execute方法的线程去执行被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。 举个例子： Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略的话来配置线程池的时候默认使用的是 ThreadPoolExecutor.AbortPolicy。在默认情况下，ThreadPoolExecutor 将抛出 RejectedExecutionException 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 ThreadPoolExecutor.CallerRunsPolicy。当最大池被填满时，此策略为我们提供可伸缩队列。 方式二：通过 Executor 框架的工具类 Executors 来实现 我们可以创建三种类型的 ThreadPoolExecutor： FixedThreadPool ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 **SingleThreadExecutor**： 该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 **CachedThreadPool**： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 对应Executors工具类中的方法如图所示： ​ 这些new*()方法内部其实还是调用了ThreadPoolExecutor的构造方法。例如newSingleThreadExecutor(ThreadFactory threadFactory)方法。 《阿里巴巴Java开发手册》中强制线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式可以更加明确线程池的运行规则，从而降低资源耗尽的风险。 阿里巴巴为什么不允许使用Executors去创建线程池？ 缓存队列LinkedBlockingQueue没有设置固定容量大小 1.1 Executors.newFixedThreadPool() 123456// 创建固定大小的线程池public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} ThreadPoolExecutor 部分参数： corePoolSize ：线程池中核心线程数的最大值。此处为 nThreads个。 maximumPoolSize ：线程池中能拥有最多线程数 。此处为 nThreads 个。 LinkedBlockingQueue ： 用于缓存任务的阻塞队列 。 此处没有设置容量大小，默认是 Integer.MAX_VALUE，可以认为是无界的。 综上源码可以得出，虽然newFixedThreadPool()中可以给定核心线程数和最大线程数，并且固定为nThreads个，但是当线程数超过nThreads时，多余的线程会加入到LinkedBlockingQueue中，而LinkedBlockingQueue相当于时无界的，会导致其无限增大，最终导致内存溢出。 1.2 Executors.newSingleThreadExecutor() 1234567// 创建只有单个线程的线程池public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));} 优点： 创建一个单线程的线程池，保证线程的顺序执行；缺点： 与 newFixedThreadPool() 相同。 总结：newFixedThreadPool()、newSingleThreadExecutor() 底层代码 中 LinkedBlockingQueue 没有设置容量大小，默认是 Integer.MAX_VALUE， 可以认为是无界的。线程池中 多余的线程会被缓存到 LinkedBlockingQueue中，最终会导致内存溢出。 最大线程数量是Integer.MAX_VALUE 2.1 Executors.newCachedThreadPool() 缓存线程池，线程池的数量可能不固定，可以根据需求自动更改数量。 12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());} ThreadPoolExecutor 部分参数： corePoolSize ：线程池中核心线程数的最大值。此处为 0 个。 maximumPoolSize ：线程池中能拥有最多线程数。此处为 Integer.MAX_VALUE 。可以认为是无限大。 CachedThreadPool 的corePoolSize 被设置为空（0），maximumPoolSize被设置为 Integer.MAX.VALUE，即它是无界的，这也就意味着如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时，CachedThreadPool 会不断创建新的线程。极端情况下，这样会导致耗尽 cpu 和内存资源。 CachedThreadPool()的excute()方法执行示意图： 上图说明： 首先执行 SynchronousQueue.offer(Runnable task) 提交任务到任务队列。如果当前 maximumPool 中有空闲线程则执行 SynchronousQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)，那么主线程执行 offer 操作与空闲线程执行的 poll 操作配对成功，主线程把任务交给空闲线程执行，execute()方法执行完成，否则执行下面的步骤 2； 当初始 maximumPool 为空，或者 maximumPool 中没有空闲线程时，将没有线程执行 SynchronousQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS)。这种情况下，步骤 1 将失败，此时 CachedThreadPool 会创建新线程执行任务，execute 方法执行完成； 2.2 Executors.newScheduledThreadPool() 创建固定大小的线程，可以延迟或者定时地执行任务。下面介绍一下ScheduledThreadPoolExecutor： 12345678public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize);}public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) { return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);} ScheduledThreadPoolExecutor 使用的任务队列 DelayQueue 封装了一个 PriorityQueue，PriorityQueue 会对队列中的任务进行排序，执行所需时间短的放在前面先被执行(ScheduledFutureTask 的 time 变量小的先执行)，如果执行所需时间相同则先提交的任务将被先执行(ScheduledFutureTask 的 squenceNumber 变量小的先执行)。 ScheduledThreadPoolExecutor 和 Timer 的比较： Timer 对系统时钟的变化敏感，ScheduledThreadPoolExecutor不是； Timer 只有一个执行线程，因此长时间运行的任务可以延迟其他任务。 ScheduledThreadPoolExecutor 可以配置任意数量的线程。 此外，如果你想（通过提供 ThreadFactory），你可以完全控制创建的线程; 在TimerTask 中抛出的运行时异常会杀死一个线程，从而导致 Timer 死机：即计划任务将不再运行。ScheduledThreadExecutor 不仅捕获运行时异常，还允许您在需要时处理它们（通过重写 afterExecute 方法ThreadPoolExecutor）。抛出异常的任务将被取消，但其他任务将继续运行。 ScheduledThreadPoolExecutor运行机制如图所示： ScheduledThreadPoolExecutor 的执行主要分为两大部分： 当调用 ScheduledThreadPoolExecutor 的 scheduleAtFixedRate() 方法或者 scheduleWithFixedDelay() 方法时，会向 ScheduledThreadPoolExecutor 的 DelayQueue 添加一个实现了 RunnableScheduledFuture 接口的 ScheduledFutureTask 。 线程池中的线程从 DelayQueue 中获取 ScheduledFutureTask，然后执行任务。 ScheduledThreadPoolExecutor 为了实现周期性的执行任务，对 ThreadPoolExecutor做了如下修改： 使用 DelayQueue 作为任务队列； 获取任务的方不同 执行周期任务后，增加了额外的处理 优点： 创建一个固定大小线程池，可以定时或周期性的执行任务 ；缺点： 与 newCachedThreadPool() 相同。 总结：newCachedThreadPool()、newScheduledThreadPool() 的底层代码中的最大线程数maximumPoolSize是Integer.MAX_VALUE，可以认为是无限大，如果线程池中，执行中的线程没有及时结束，并且不断地有线程加入并执行，最终会导致内存溢出。 饱和策略不能自定义 Executors 底层其实是使用的 ThreadPoolExecutor 的方式创建的，但是使用的是 ThreadPoolExecutor 的默认策略，即 AbortPolicy。 12345678910111213//默认策略 private static final RejectedExecutionHandler defaultHandler = new AbortPolicy();//构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);} 示例代码1：Runnable+ThreadPoolExecutor 首先创建一个 Runnable 接口的实现类（也可以是 Callable 接口） MyRunnable.java 12345678910111213141516171819202122232425262728293031323334import java.util.Date;/** * 这是一个简单的Runnable类，需要大约5秒钟来执行其任务。 * @author shuang.kou */public class MyRunnable implements Runnable { private String command; public MyRunnable(String s) { this.command = s; } @Override public void run() { System.out.println(Thread.currentThread().getName() + &quot; Start. Time = &quot; + new Date()); processCommand(); System.out.println(Thread.currentThread().getName() + &quot; End. Time = &quot; + new Date()); } private void processCommand() { try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } } @Override public String toString() { return this.command; }} 编写测试程序，这里使用阿里巴巴推荐的方式 ThreadPoolExecutor 构造函数自定义参数的方式来创建线程池。 ThreadPoolExecutorDemo.java 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class ThreadPoolExecutorDemo { // 核心线程数 private static final int CORE_POOL_SIZE = 5; // 最大线程数 private static final int MAX_POOL_SIZE = 10; // 阻塞队列的容量 private static final int QUEUE_CAPACITY = 100; // 生存时间 private static final Long KEEP_ALIVE_TIME = 1L; public static void main(String[] args) { //使用阿里巴巴推荐的创建线程池的方式 //通过ThreadPoolExecutor构造函数自定义参数创建 ThreadPoolExecutor executor = new ThreadPoolExecutor( CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 10; i++) { //创建WorkerThread对象（WorkerThread类实现了Runnable 接口） Runnable worker = new MyRunnable(&quot;&quot; + i); //执行Runnable executor.execute(worker); } //终止线程池 executor.shutdown(); while (!executor.isTerminated()) { } System.out.println(&quot;Finished all threads&quot;); }} 可以看到我们上面的代码指定了： corePoolSize: 核心线程数为 5。 maximumPoolSize ：最大线程数 10。 keepAliveTime : 等待时间为 1L。 unit: 等待时间的单位为 TimeUnit.SECONDS。 workQueue：任务队列为 ArrayBlockingQueue，并且容量为 100。 handler:饱和策略为 CallerRunsPolicy。 Output： 1234567891011121314151617181920pool-1-thread-3 Start. Time = Sun Apr 12 11:14:37 CST 2020pool-1-thread-5 Start. Time = Sun Apr 12 11:14:37 CST 2020pool-1-thread-2 Start. Time = Sun Apr 12 11:14:37 CST 2020pool-1-thread-1 Start. Time = Sun Apr 12 11:14:37 CST 2020pool-1-thread-4 Start. Time = Sun Apr 12 11:14:37 CST 2020pool-1-thread-3 End. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-4 End. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-1 End. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-5 End. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-1 Start. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-2 End. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-5 Start. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-4 Start. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-3 Start. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-2 Start. Time = Sun Apr 12 11:14:42 CST 2020pool-1-thread-1 End. Time = Sun Apr 12 11:14:47 CST 2020pool-1-thread-4 End. Time = Sun Apr 12 11:14:47 CST 2020pool-1-thread-5 End. Time = Sun Apr 12 11:14:47 CST 2020pool-1-thread-3 End. Time = Sun Apr 12 11:14:47 CST 2020pool-1-thread-2 End. Time = Sun Apr 12 11:14:47 CST 2020 示例代码2：Callable+ThreadPoolExecutorMyCallable.java 12345678910import java.util.concurrent.Callable;public class MyCallable implements Callable&lt;String&gt; { @Override public String call() throws Exception { Thread.sleep(1000); //返回执行当前 Callable 的线程名字 return Thread.currentThread().getName(); }} CallableDemo.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class CallableDemo { private static final int CORE_POOL_SIZE = 5; private static final int MAX_POOL_SIZE = 10; private static final int QUEUE_CAPACITY = 100; private static final Long KEEP_ALIVE_TIME = 1L; public static void main(String[] args) { //使用阿里巴巴推荐的创建线程池的方式 //通过ThreadPoolExecutor构造函数自定义参数创建 ThreadPoolExecutor executor = new ThreadPoolExecutor( CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY), new ThreadPoolExecutor.CallerRunsPolicy()); List&lt;Future&lt;String&gt;&gt; futureList = new ArrayList&lt;&gt;(); Callable&lt;String&gt; callable = new MyCallable(); for (int i = 0; i &lt; 10; i++) { //提交任务到线程池 Future&lt;String&gt; future = executor.submit(callable); //将返回值 future 添加到 list，我们可以通过 future 获得 执行 Callable 得到的返回值 futureList.add(future); } for (Future&lt;String&gt; fut : futureList) { try { System.out.println(new Date() + &quot;::&quot; + fut.get()); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } } //关闭线程池 executor.shutdown(); }} 输出： 12345678910Wed Nov 13 22:40:41 CST 2021::pool-1-thread-1Wed Nov 13 22:40:42 CST 2021::pool-1-thread-2Wed Nov 13 22:40:42 CST 2021::pool-1-thread-3Wed Nov 13 22:40:42 CST 2021::pool-1-thread-4Wed Nov 13 22:40:42 CST 2021::pool-1-thread-5Wed Nov 13 22:40:42 CST 2021::pool-1-thread-3Wed Nov 13 22:40:43 CST 2021::pool-1-thread-2Wed Nov 13 22:40:43 CST 2021::pool-1-thread-1Wed Nov 13 22:40:43 CST 2021::pool-1-thread-4Wed Nov 13 22:40:43 CST 2021::pool-1-thread-5 线程池原理分析通过上面代码的输出结果可以看出：线程池首先会先执行 5 个任务，然后这些任务有任务被执行完的话，就会去拿新的任务执行。 现在，通过分析上面的输出内容来简单分析一下线程池原理。 为了理解线程池的原理，需要首先分析一下 execute方法。 在上述的Demo 中使用 了executor.execute(worker)来提交一个任务到线程池中去，这个方法非常重要，下面来看源码： 123456789101112131415161718192021222324252627282930313233343536373839404142// 在未来的某个时间执行给定的任务。该任务可以在新线程或现有池线程中执行。如果任务无法提交执行，要么是因为这个执行器已经关闭， 要么是因为它的容量已经达到，任务由当前的 RejectedExecutionHandler处理。// 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount) private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static int workerCountOf(int c) { return c &amp; COUNT_MASK; } //任务队列 private final BlockingQueue&lt;Runnable&gt; workQueue; public void execute(Runnable command) { // 如果任务为null，则抛出异常。 if (command == null) throw new NullPointerException(); // ctl 中保存的线程池当前的一些状态信息 int c = ctl.get(); // 下面会涉及到3步操作 // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } // 2.如果当前执行的任务数量大于等于 corePoolSize的时候就会走到这里 // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态并且队列可以加入任务，该任务才会被加入进去 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果当前线程池为空就新创建一个线程并执行。 else if (workerCountOf(recheck) == 0) addWorker(null, false); } //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。 //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。 //这种情况就是核心线程池已满，等待队列已满但是还没有达到maximumPoolSize（即线程池还没有满），那就创建一个新的线程去执行该任务。 else if (!addWorker(command, false)) reject(command); } 下图展示了任务提交的处理流程： addWorker 这个方法主要用来创建新的工作线程，如果返回 true 说明创建和启动工作线程成功，否则返回 false。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899 // 全局锁（RenntrantLock：可重入锁） private final ReentrantLock mainLock = new ReentrantLock(); // 跟踪线程池的最大大小，只有在持有全局锁mainLock的前提下才能访问 private int largestPoolSize; // 工作线程集合，存放线程池中所有的（活跃的）工作线程，只有在持有全局锁mainLock的前提下才能访问此集合 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;(); //获取线程池状态 private static int runStateOf(int c) { return c &amp; ~CAPACITY; } //判断线程池的状态是否为 Running private static boolean isRunning(int c) { return c &lt; SHUTDOWN; } /** * 添加新的工作线程到线程池 * @param firstTask 要执行 * @param core参数为true的话表示使用线程池的基本大小，为false使用线程池最大大小 * @return 添加成功就返回true否则返回false */private boolean addWorker(Runnable firstTask, boolean core) { retry: for (int c = ctl.get();;) { // Check if queue empty only if necessary. // SHUTDOWN=0 // 首先判断线程池是否是非RUNNING状态，不是RUNNING状态那么继续判断线程池是不是STOP状态，是STOP状态直接返回false,不是STOP状态继续判断firstTask是否为null,如果firstTask为null，那么直接返回false,如果firstTask不为null，那么继续判断工作队列是否为空，如果为空，那么返回false，否则往下执行。 if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; for (;;) { //获取线程池中线程的数量 int wc = workerCountOf(c); // core参数为true的话表明队列也满了，线程池大小变为 maximumPoolSize if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //原子操作将workcount的数量加1 if (compareAndIncrementWorkerCount(c)) break retry; // 如果线程的状态改变了就再次执行上述操作 c = ctl.get(); // Re-read ctl if (runStateAtLeast(c, SHUTDOWN)) continue retry; // else CAS failed due to workerCount change; retry inner loop } } // 标记工作线程是否启动成功 boolean workerStarted = false; // 标记工作线程是否创建成功 boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { // 加锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { //获取线程池状态 int c = ctl.get(); //isRunning(c) 如果线程池状态依然为RUNNING,并且线程的状态是存活的话，就会将工作线程添加到工作线程集合中 //(runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) 如果线程池状态小于STOP，同时传入的任务实例firstTask为null，则需要添加到工作线程集合和启动新的Worker // firstTask == null证明只新建线程而不执行任务 if (isRunning(c) || (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) { //如果这个线程不是未启动状态，会抛出异常 //Thread.State.NEW: Thread state for a thread which has not yet started. if (t.getState() != Thread.State.NEW) throw new IllegalThreadStateException(); workers.add(w); // 工作线程启动成功 workerAdded = true; //更新当前工作线程的最大容量 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; } } finally { // 释放锁 mainLock.unlock(); } //// 如果成功添加工作线程，则调用Worker内部的线程实例t的Thread#start()方法启动真实的线程实例 if (workerAdded) { t.start(); /// 标记线程启动成功 workerStarted = true; } } } finally { // 线程启动失败，需要从工作线程中移除对应的Worker if (! workerStarted) addWorkerFailed(w); } return workerStarted; } addWorker执行流程如下： 关于线程池源码分析更多的内容参考以下文章： JUC 线程池 ThreadPoolExecutor 源码分析 (opens new window) Java线程池实现原理及其在美团业务中的实践 如何设置线程池参数？美团给出了一个让面试官虎躯一震的回答 Demo代码中模拟了 10 个任务，配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的 5 个任务中如果有任务被执行完了，线程池就会去拿新的任务执行。","link":"/Java/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%8B%E7%BB%8D/"},{"title":"device-sdk-go源码分析","text":"device-sdk-go源码分析device-sdk-go项目目录结构1234567891011121314151617181920212223242526272829303132333435363738├─.github│ └─ISSUE_TEMPLATE├─bin├─example│ ├─cmd│ │ └─device-simple│ │ └─res│ │ ├─devices│ │ └─profiles│ ├─config│ └─driver├─internal│ ├─application│ ├─autodiscovery│ ├─autoevent│ ├─cache│ ├─clients│ ├─common│ ├─config│ ├─container│ ├─controller│ │ └─http│ │ └─correlation│ ├─messaging│ ├─provision│ ├─telemetry│ └─transformer├─openapi│ └─v2├─pkg│ ├─models│ │ └─mocks│ ├─service│ └─startup└─snap ├─hooks └─local 接下来以官方提供的example项目包为例，分析device-sdk-go的项目结构和相关功能。 目录结构如下： 12345678├─cmd│ └─device-simple│ └─res│ ├─devices│ └─profiles├─config└─driver cmd文件夹main.go 1234567891011121314151617181920212223242526// -*- Mode: Go; indent-tabs-mode: t -*-//// Copyright (C) 2017-2018 Canonical Ltd// Copyright (C) 2018-2019 IOTech Ltd//// SPDX-License-Identifier: Apache-2.0// This package provides a simple example of a device service.package main//导入包import ( &quot;github.com/edgexfoundry/device-sdk-go/v2&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/example/driver&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/pkg/startup&quot;)//定义常量 服务名称const ( serviceName string = &quot;device-simple&quot;)func main() { sd := driver.SimpleDriver{} //初始化SimpleDriver结构体 startup.Bootstrap(serviceName, device.Version, &amp;sd) //通过引导程序启动设备服务} configuration.toml 项目配置文件 描述当前device-service的ip，port以及所依赖的各个EdgeX微服务的配置信息等 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106[Writable]LogLevel = &quot;INFO&quot; # 非安全模式下的配置 # Example InsecureSecrets configuration that simulates SecretStore for when EDGEX_SECURITY_SECRET_STORE=false # InsecureSecrets are required for when Redis is used for message bus [Writable.InsecureSecrets] [Writable.InsecureSecrets.DB] path = &quot;redisdb&quot; [Writable.InsecureSecrets.DB.Secrets] username = &quot;&quot; password = &quot;&quot;[Service]HealthCheckInterval = &quot;10s&quot; #健康健康间隔Host = &quot;localhost&quot; Port = 59999 # Device serivce are assigned the 599xx rangeServerBindAddr = &quot;&quot; # blank value defaults to Service.Host valueStartupMsg = &quot;device simple started&quot;# MaxRequestSize limit the request body size in byte of put commandMaxRequestSize = 0 # value 0 unlimit the request size.RequestTimeout = &quot;20s&quot; [Service.CORSConfiguration] EnableCORS = false CORSAllowCredentials = false CORSAllowedOrigin = &quot;https://localhost&quot; CORSAllowedMethods = &quot;GET, POST, PUT, PATCH, DELETE&quot; CORSAllowedHeaders = &quot;Authorization, Accept, Accept-Language, Content-Language, Content-Type, X-Correlation-ID&quot; CORSExposeHeaders = &quot;Cache-Control, Content-Language, Content-Length, Content-Type, Expires, Last-Modified, Pragma, X-Correlation-ID&quot; CORSMaxAge = 3600[Registry]Host = &quot;localhost&quot;Port = 8500Type = &quot;consul&quot;[Clients] [Clients.core-data] Protocol = &quot;http&quot; Host = &quot;localhost&quot; Port = 59880 [Clients.core-metadata] Protocol = &quot;http&quot; Host = &quot;localhost&quot; Port = 59881[MessageQueue]Protocol = &quot;redis&quot;Host = &quot;localhost&quot;Port = 6379Type = &quot;redis&quot;AuthMode = &quot;usernamepassword&quot; # required for redis messagebus (secure or insecure).SecretName = &quot;redisdb&quot;PublishTopicPrefix = &quot;edgex/events/device&quot; # /&lt;device-profile-name&gt;/&lt;device-name&gt;/&lt;source-name&gt; will be added to this Publish Topic prefix [MessageQueue.Optional] # Default MQTT Specific options that need to be here to enable environment variable overrides of them # Client Identifiers ClientId = &quot;device-simple&quot; # Connection information Qos = &quot;0&quot; # Quality of Sevice values are 0 (At most once), 1 (At least once) or 2 (Exactly once) KeepAlive = &quot;10&quot; # Seconds (must be 2 or greater) Retained = &quot;false&quot; AutoReconnect = &quot;true&quot; ConnectTimeout = &quot;5&quot; # Seconds SkipCertVerify = &quot;false&quot; # Only used if Cert/Key file or Cert/Key PEMblock are specified# Example SecretStore configuration.# Only used when EDGEX_SECURITY_SECRET_STORE=true# Must also add `ADD_SECRETSTORE_TOKENS: &quot;device-simple&quot;` to vault-worker environment so it generates# the token and secret store in vault for &quot;device-simple&quot;[SecretStore]Type = &quot;vault&quot;Host = &quot;localhost&quot;Port = 8200Path = &quot;device-simple/&quot;Protocol = &quot;http&quot;RootCaCertPath = &quot;&quot;ServerName = &quot;&quot;SecretsFile = &quot;&quot;DisableScrubSecretsFile = falseTokenFile = &quot;/tmp/edgex/secrets/device-simple/secrets-token.json&quot; [SecretStore.Authentication] AuthType = &quot;X-Vault-Token&quot;[Device] DataTransform = true MaxCmdOps = 128 MaxCmdValueLen = 256 ProfilesDir = &quot;./res/profiles&quot; DevicesDir = &quot;./res/devices&quot; UpdateLastConnected = false AsyncBufferSize = 1 EnableAsyncReadings = true Labels = [] UseMessageBus = true [Device.Discovery] Enabled = false Interval = &quot;30s&quot;# Example structured custom configuration[SimpleCustom]OnImageLocation = &quot;./res/on.png&quot;OffImageLocation = &quot;./res/off.jpg&quot; [SimpleCustom.Writable] DiscoverSleepDurationSecs = 10 config文件夹configuration.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package configimport ( &quot;errors&quot;)//此文件包含了可以从服务的configuration.toml加载的配置示例//或者是配置提供程序，又名consul// 如果要在configuration.toml中使用自定义配置类型//那么在configuration.toml的顶级配置名须是本文件中最外部结构名//比如这个示例的 SimpleCustomtype ServiceConfig struct { SimpleCustom SimpleCustomConfig}type SimpleCustomConfig struct { OffImageLocation string OnImageLocation string Writable SimpleWritable}type SimpleWritable struct { DiscoverSleepDurationSecs int64}// 从接受到的原始数据更新服务的完整配置func (sw *ServiceConfig) UpdateFromRaw(rawConfig interface{}) bool { configuration, ok := rawConfig.(*ServiceConfig) if !ok { return false //errors.New(&quot;unable to cast raw config to type 'ServiceConfig'&quot;) } *sw = *configuration return true}// 确保自定义配置都有正确的值func (scc *SimpleCustomConfig) Validate() error { if len(scc.OnImageLocation) == 0 { return errors.New(&quot;SimpleCustom.OnImageLocation configuration setting can not be blank&quot;) } if len(scc.OffImageLocation) == 0 { return errors.New(&quot;SimpleCustom.OffImageLocation configuration setting can not be blank&quot;) } if scc.Writable.DiscoverSleepDurationSecs &lt; 10 { return errors.New(&quot;SimpleCustom.Writable.DiscoverSleepDurationSecs configuration setting must be 10 or greater&quot;) } return nil} driver文件夹 simpledriver.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297//这个包提供了协议驱动接口的简单实现示例package driver//导入包import ( &quot;bytes&quot; &quot;fmt&quot; &quot;image&quot; &quot;image/jpeg&quot; &quot;image/png&quot; &quot;os&quot; &quot;reflect&quot; &quot;time&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/clients/logger&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/common&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/models&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/example/config&quot; sdkModels &quot;github.com/edgexfoundry/device-sdk-go/v2/pkg/models&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/pkg/service&quot;)//简单驱动结构type SimpleDriver struct { lc logger.LoggingClient //日志客户端 asyncCh chan&lt;- *sdkModels.AsyncValues //用于通过 ProtocolDrivers 异步发送设备读数的结构 deviceCh chan&lt;- []sdkModels.DiscoveredDevice //定义找到一个设备所需的信息 switchButton bool //开关按钮 xRotation int32 //x轴旋转速度 yRotation int32 //y轴旋转速度 zRotation int32 //z轴旋转速度 counter interface{} //计数器 serviceConfig *config.ServiceConfig //自定义配置}//获取图片func getImageBytes(imgFile string, buf *bytes.Buffer) error { // 从文件中读取图片 img, err := os.Open(imgFile) if err != nil { return err } defer img.Close() // 解码，判断图片类型 imageData, imageType, err := image.Decode(img) if err != nil { return err } // 当前文件任务结束，重置文件pointer img.Seek(0, 0) if imageType == &quot;jpeg&quot; { err = jpeg.Encode(buf, imageData, nil) if err != nil { return err } } else if imageType == &quot;png&quot; { err = png.Encode(buf, imageData) if err != nil { return err } } return nil}// 为设备服务执行特定于协议的初始化func (s *SimpleDriver) Initialize(lc logger.LoggingClient, asyncCh chan&lt;- *sdkModels.AsyncValues, deviceCh chan&lt;- []sdkModels.DiscoveredDevice) error { //为每个成员赋值 s.lc = lc s.asyncCh = asyncCh s.deviceCh = deviceCh //自定义服务配置 s.serviceConfig = &amp;config.ServiceConfig{} //计数器内容为map结构 key类型为string value类型为interface{} s.counter = map[string]interface{}{ &quot;f1&quot;: &quot;ABC&quot;, &quot;f2&quot;: 123, } //service.RunningService() 返回设备服务 //在&quot;github.com/edgexfoundry/device-sdk-go/v2/pkg/service&quot;中 //定义了 var( // ds *DeviceService // ) ds := service.RunningService() //加载自定义服务配置 if err := ds.LoadCustomConfig(s.serviceConfig, &quot;SimpleCustom&quot;); err != nil { return fmt.Errorf(&quot;unable to load 'SimpleCustom' custom configuration: %s&quot;, err.Error()) } //输出当前自定义配置 lc.Infof(&quot;Custom config is: %v&quot;, s.serviceConfig.SimpleCustom) //确保自定义配置具有正确的值 if err := s.serviceConfig.SimpleCustom.Validate(); err != nil { return fmt.Errorf(&quot;'SimpleCustom' custom configuration validation failed: %s&quot;, err.Error()) } //启用go-mod-bootstrap中的配置处理器监听对自定义配置部分的更改 //注意LoadCustomConfig必须在此方法前调用，因为在LoadCustomConfig方法内生成了configProcessor实例 //所需传入的三个参数分别为需要监听的配置内容(可写的),名称,回调函数 if err := ds.ListenForCustomConfigChanges( &amp;s.serviceConfig.SimpleCustom.Writable, &quot;SimpleCustom/Writable&quot;, s.ProcessCustomConfigChanges); err != nil { return fmt.Errorf(&quot;unable to listen for changes for 'SimpleCustom.Writable' custom configuration: %s&quot;, err.Error()) } return nil}// 处理自定义配置更改func (s *SimpleDriver) ProcessCustomConfigChanges(rawWritableConfig interface{}) { //类型断言 updated, ok := rawWritableConfig.(*config.SimpleWritable) if !ok { s.lc.Error(&quot;unable to process custom config updates: Can not cast raw config to type 'SimpleWritable'&quot;) return } s.lc.Info(&quot;Received configuration updates for 'SimpleCustom.Writable' section&quot;) previous := s.serviceConfig.SimpleCustom.Writable s.serviceConfig.SimpleCustom.Writable = *updated //判断是否有改动 if reflect.DeepEqual(previous, *updated) { s.lc.Info(&quot;No changes detected&quot;) return } // 检查发生了什么变化,以下只是一个示例，并不适合于所有情况 if previous.DiscoverSleepDurationSecs != updated.DiscoverSleepDurationSecs { s.lc.Infof(&quot;DiscoverSleepDurationSecs changed to: %d&quot;, updated.DiscoverSleepDurationSecs) }}// HandleReadCommands triggers a protocol Read operation for the specified device.// 触发指定设备的协议读取操作// 所需传入的三个参数分别为: 设备名称、设备连接信息、请求的命令内容、命令参数值func (s *SimpleDriver) HandleReadCommands(deviceName string, protocols map[string]models.ProtocolProperties, reqs []sdkModels.CommandRequest) (res []*sdkModels.CommandValue, err error) { s.lc.Debugf(&quot;SimpleDriver.HandleReadCommands: protocols: %v resource: %v attributes: %v&quot;, protocols, reqs[0].DeviceResourceName, reqs[0].Attributes) if len(reqs) == 1 { res = make([]*sdkModels.CommandValue, 1) if reqs[0].DeviceResourceName == &quot;SwitchButton&quot; { // 根据valueType创建相关命令 cv, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeBool, s.switchButton) res[0] = cv } else if reqs[0].DeviceResourceName == &quot;Xrotation&quot; { cv, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeInt32, s.xRotation) res[0] = cv } else if reqs[0].DeviceResourceName == &quot;Yrotation&quot; { cv, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeInt32, s.yRotation) res[0] = cv } else if reqs[0].DeviceResourceName == &quot;Zrotation&quot; { cv, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeInt32, s.zRotation) res[0] = cv } else if reqs[0].DeviceResourceName == &quot;Image&quot; { // 显示开关的二进制图像表示 buf := new(bytes.Buffer) if s.switchButton == true { err = getImageBytes(s.serviceConfig.SimpleCustom.OnImageLocation, buf) } else { err = getImageBytes(s.serviceConfig.SimpleCustom.OffImageLocation, buf) } cvb, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeBinary, buf.Bytes()) res[0] = cvb } else if reqs[0].DeviceResourceName == &quot;Uint8Array&quot; { cv, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeUint8Array, []uint8{0, 1, 2}) res[0] = cv } else if reqs[0].DeviceResourceName == &quot;Counter&quot; { cv, _ := sdkModels.NewCommandValue(reqs[0].DeviceResourceName, common.ValueTypeObject, s.counter) res[0] = cv } } else if len(reqs) == 3 { res = make([]*sdkModels.CommandValue, 3) for i, r := range reqs { var cv *sdkModels.CommandValue switch r.DeviceResourceName { case &quot;Xrotation&quot;: cv, _ = sdkModels.NewCommandValue(r.DeviceResourceName, common.ValueTypeInt32, s.xRotation) case &quot;Yrotation&quot;: cv, _ = sdkModels.NewCommandValue(r.DeviceResourceName, common.ValueTypeInt32, s.yRotation) case &quot;Zrotation&quot;: cv, _ = sdkModels.NewCommandValue(r.DeviceResourceName, common.ValueTypeInt32, s.zRotation) } res[i] = cv } } return}// 传递一个CommandRequest结构的切片,每个切片代表对特定设备资源的操作。由于这些命令是驱动命令,参数为单个命令提供参数// 所需传入的三个参数分别为: 设备名称、设备连接信息、请求的命令内容func (s *SimpleDriver) HandleWriteCommands(deviceName string, protocols map[string]models.ProtocolProperties, reqs []sdkModels.CommandRequest, params []*sdkModels.CommandValue) error { var err error for i, r := range reqs { s.lc.Debugf(&quot;SimpleDriver.HandleWriteCommands: protocols: %v, resource: %v, parameters: %v, attributes: %v&quot;, protocols, reqs[i].DeviceResourceName, params[i], reqs[i].Attributes) switch r.DeviceResourceName { case &quot;SwitchButton&quot;: if s.switchButton, err = params[i].BoolValue(); err != nil { err := fmt.Errorf(&quot;SimpleDriver.HandleWriteCommands; the data type of parameter should be Boolean, parameter: %s&quot;, params[0].String()) return err } case &quot;Xrotation&quot;: if s.xRotation, err = params[i].Int32Value(); err != nil { err := fmt.Errorf(&quot;SimpleDriver.HandleWriteCommands; the data type of parameter should be Int32, parameter: %s&quot;, params[i].String()) return err } case &quot;Yrotation&quot;: if s.yRotation, err = params[i].Int32Value(); err != nil { err := fmt.Errorf(&quot;SimpleDriver.HandleWriteCommands; the data type of parameter should be Int32, parameter: %s&quot;, params[i].String()) return err } case &quot;Zrotation&quot;: if s.zRotation, err = params[i].Int32Value(); err != nil { err := fmt.Errorf(&quot;SimpleDriver.HandleWriteCommands; the data type of parameter should be Int32, parameter: %s&quot;, params[i].String()) return err } case &quot;Uint8Array&quot;: v, err := params[i].Uint8ArrayValue() if err == nil { s.lc.Debugf(&quot;Uint8 array value from write command: &quot;, v) } else { return err } case &quot;Counter&quot;: if s.counter, err = params[i].ObjectValue(); err != nil { err := fmt.Errorf(&quot;SimpleDriver.HandleWriteCommands; the data type of parameter should be Object, parameter: %s&quot;, params[i].String()) return err } } } return nil}// 协议特定的设备服务代码将正常关闭，或者如果force参数为“true”，则立即关闭。// 驱动程序负责关闭任何正在使用的通道，包括用于发送异步读数的通道(如果支持)。func (s *SimpleDriver) Stop(force bool) error { // Then Logging Client might not be initialized if s.lc != nil { s.lc.Debugf(&quot;SimpleDriver.Stop called: force=%v&quot;, force) } return nil}// AddDevice是一个回调函数，在添加与此设备服务关联的新设备时调用.func (s *SimpleDriver) AddDevice(deviceName string, protocols map[string]models.ProtocolProperties, adminState models.AdminState) error { s.lc.Debugf(&quot;a new Device is added: %s&quot;, deviceName) return nil}// UpdateDevice是一个回调函数，在更新与此设备服务关联的设备时调用func (s *SimpleDriver) UpdateDevice(deviceName string, protocols map[string]models.ProtocolProperties, adminState models.AdminState) error { s.lc.Debugf(&quot;Device %s is updated&quot;, deviceName) return nil}// RemoveDevice是一个回调函数，在删除与此设备服务关联的设备时调用func (s *SimpleDriver) RemoveDevice(deviceName string, protocols map[string]models.ProtocolProperties) error { s.lc.Debugf(&quot;Device %s is removed&quot;, deviceName) return nil}// 用于发现特定协议的设备，这是一种异步操作// 在发现过程中如果找到设备将写入设备操作 func (s *SimpleDriver) Discover() { proto := make(map[string]models.ProtocolProperties) proto[&quot;other&quot;] = map[string]string{&quot;Address&quot;: &quot;simple02&quot;, &quot;Port&quot;: &quot;301&quot;} device2 := sdkModels.DiscoveredDevice{ Name: &quot;Simple-Device02&quot;, Protocols: proto, Description: &quot;found by discovery&quot;, Labels: []string{&quot;auto-discovery&quot;}, } proto = make(map[string]models.ProtocolProperties) proto[&quot;other&quot;] = map[string]string{&quot;Address&quot;: &quot;simple03&quot;, &quot;Port&quot;: &quot;399&quot;} device3 := sdkModels.DiscoveredDevice{ Name: &quot;Simple-Device03&quot;, Protocols: proto, Description: &quot;found by discovery&quot;, Labels: []string{&quot;auto-discovery&quot;}, } res := []sdkModels.DiscoveredDevice{device2, device3} time.Sleep(time.Duration(s.serviceConfig.SimpleCustom.Writable.DiscoverSleepDurationSecs) * time.Second) s.deviceCh &lt;- res} container.go 采用了控制反转的设计模式(IOC)，实现了一个简单的依赖注入容器。为什么要这么做？ ●控制：传统的面向对象程序设计，如果我们需要控制对象，可以直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IOC则是专门有一个容器去创建这些对象，即通过IOC容器来控制对象的创建。所以这边就不是原本的程序控制了对象，而是IOC容器控制了对象；控制了什么？控制了程序的外部资源获取，也就是说现在应用程序需要获取外部资源，那么就需要通过容器来进行操作，显然这降低了程序间的耦合性。 ●反转：在没有容器的时候，我们需要一个对象的时候，我们必须自己new一个对象，这时候主动权在自己手上，我们可以称之为正转，而现在我们将控制权交给了容器。所以控制反转IOC就是说将创建对象的控制权进行转移，之前创建对象的主动权和创建时机是由自己把控的，而现在这种权力转移到第三方，这边是容器，它就是一个专门用来创建对象的工厂，你要什么对象，它就给你什么对象，有了 IOC容器，此时的依赖关系就变了，原先可能A依赖B，B依赖C，但是现在他们都是依赖IOC容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package diimport &quot;sync&quot;// 定义一个函数类型type Get func(serviceName string) interface{}// 定义一个函数类型type ServiceConstructor func(get Get) interface{}// ServiceConstructorMap maps a service name to a function/closure to create that service.type ServiceConstructorMap map[string]ServiceConstructor// service is an internal structure used to track a specific service's constructor and constructed instance.type service struct { constructor ServiceConstructor instance interface{}}// Container is a receiver that maintains a list of services, their constructors, and their constructed instances in a// thread-safe manner.type Container struct { serviceMap map[string]service mutex sync.RWMutex}// NewContainer是一个工厂方法，返回初始化的容器接收器func NewContainer(serviceConstructors ServiceConstructorMap) *Container { c := Container{ serviceMap: map[string]service{}, mutex: sync.RWMutex{}, } if serviceConstructors != nil { c.Update(serviceConstructors) } return &amp;c}// 使用提供的ServiceConstructorMap的内容更新serviceMap。func (c *Container) Update(serviceConstructors ServiceConstructorMap) { c.mutex.Lock() defer c.mutex.Unlock() for serviceName, constructor := range serviceConstructors { c.serviceMap[serviceName] = service{ constructor: constructor, instance: nil, } }}// get查找请求的serviceName，如果它存在，则返回一个构造的实例。如果请求的服务不存在，则返回nil。// Get 获取单个实例中的实例构造，实现如果一个实例已经被构造，将被重用并返回给所有后续的get（serviceName）调用。func (c *Container) get(serviceName string) interface{} { service, ok := c.serviceMap[serviceName] if !ok { return nil } if service.instance == nil { service.instance = service.constructor(c.get) c.serviceMap[serviceName] = service } return service.instance}// 这边实现了container的Get方法，为什么要这么做，主要就是为了用单例模式来保证线程安全。func (c *Container) Get(serviceName string) interface{} { c.mutex.Lock() defer c.mutex.Unlock() return c.get(serviceName)} ​ SDK中提供了这么一个简单的示例用法: ​ 首先定义了两种结构体，并且给出了相应的初始化方法，在main函数中，直接讲 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( &quot;fmt&quot; &quot;github.com/edgexfoundry/go-mod-bootstrap/v2/di&quot;)type foo struct { FooMessage string}func NewFoo(m string) *foo { return &amp;foo{ FooMessage: m, }}type bar struct { BarMessage string Foo *foo}func NewBar(m string, foo *foo) *bar { return &amp;bar{ BarMessage: m, Foo: foo, }}func main() { container := di.NewContainer( di.ServiceConstructorMap{ // 这边传入的函数get没有用到，这边直接返回了一个实例 &quot;foo&quot;: func(get di.Get) interface{} { return NewFoo(&quot;fooMessage&quot;) }, &quot;bar&quot;: func(get di.Get) interface{} { return NewBar(&quot;barMessage&quot;, get(&quot;foo&quot;).(*foo)) }, }) b := container.Get(&quot;bar&quot;).(*bar) fmt.Println(b.BarMessage) fmt.Println(b.Foo.FooMessage)} 1234567891011lc := container.LoggingClientFrom(dic.Get)// 这个函数方法也是ServiceConstructor类型的func LoggingClientFrom(get di.Get) logger.LoggingClient { loggingClient, ok := get(LoggingClientInterfaceName).(logger.LoggingClient) if !ok { return nil } return loggingClient} command struct 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768type CommandProcessor struct { device models.Device sourceName string correlationID string setParamsMap map[string]interface{} attributes string dic *di.Container}type profileCache struct { deviceProfileMap map[string]*models.DeviceProfile // key is DeviceProfile name deviceResourceMap map[string]map[string]models.DeviceResource deviceCommandMap map[string]map[string]models.DeviceCommand mutex sync.RWMutex}type DeviceResource struct { Description string Name string IsHidden bool Tag string Properties ResourceProperties Attributes map[string]interface{}}type DeviceCommand struct { Name string IsHidden bool ReadWrite string ResourceOperations []ResourceOperation}type ResourceOperation struct { DeviceResource string DefaultValue string Mappings map[string]string}type CommandRequest struct { // DeviceResourceName is the name of Device Resource for this command DeviceResourceName string // Attributes is a key/value map to represent the attributes of the Device Resource Attributes map[string]interface{} // Type is the data type of the Device Resource Type string}// CommandValue is the struct to represent the reading value of a Get command coming// from ProtocolDrivers or the parameter of a Put command sending to ProtocolDrivers.type CommandValue struct { // DeviceResourceName is the name of Device Resource for this command DeviceResourceName string // Type indicates what type of value was returned from the ProtocolDriver instance in // response to HandleCommand being called to handle a single ResourceOperation. Type string // Value holds value returned by a ProtocolDriver instance. // The value can be converted to its native type by referring to ValueType. Value interface{} // Origin is an int64 value which indicates the time the reading // contained in the CommandValue was read by the ProtocolDriver // instance. Origin int64 // Tags allows device service to add custom information to the Event in order to // help identify its origin or otherwise label it before it is send to north side. Tags map[string]string} command.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681// -*- Mode: Go; indent-tabs-mode: t -*-//// Copyright (C) 2020-2021 IOTech Ltd//// SPDX-License-Identifier: Apache-2.0package applicationimport ( &quot;bytes&quot; &quot;encoding/base64&quot; &quot;encoding/binary&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;math&quot; &quot;strconv&quot; &quot;strings&quot; bootstrapContainer &quot;github.com/edgexfoundry/go-mod-bootstrap/v2/bootstrap/container&quot; &quot;github.com/edgexfoundry/go-mod-bootstrap/v2/di&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/common&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/dtos&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/errors&quot; &quot;github.com/edgexfoundry/go-mod-core-contracts/v2/models&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/internal/cache&quot; sdkCommon &quot;github.com/edgexfoundry/device-sdk-go/v2/internal/common&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/internal/container&quot; &quot;github.com/edgexfoundry/device-sdk-go/v2/internal/transformer&quot; sdkModels &quot;github.com/edgexfoundry/device-sdk-go/v2/pkg/models&quot;)type CommandProcessor struct { device models.Device sourceName string correlationID string setParamsMap map[string]interface{} attributes string dic *di.Container}func NewCommandProcessor(device models.Device, sourceName string, correlationID string, setParamsMap map[string]interface{}, attributes string, dic *di.Container) *CommandProcessor { if setParamsMap == nil { setParamsMap = make(map[string]interface{}) } return &amp;CommandProcessor{ device: device, sourceName: sourceName, correlationID: correlationID, setParamsMap: setParamsMap, attributes: attributes, dic: dic, }}// CommandHandler 命令处理func CommandHandler(isRead bool, sendEvent bool, correlationID string, vars map[string]string, setParamsMap map[string]interface{}, attributes string, dic *di.Container) (res *dtos.Event, err errors.EdgeX) { // check device service AdminState // 检查设备服务管理状态 ds := container.DeviceServiceFrom(dic.Get) // 锁定状态 if ds.AdminState == models.Locked { return res, errors.NewCommonEdgeX(errors.KindServiceLocked, &quot;service locked&quot;, nil) } // check provided device exists // 检查设备是否存在 deviceKey := vars[common.Name] device, ok := cache.Devices().ForName(deviceKey) if !ok { return res, errors.NewCommonEdgeX(errors.KindEntityDoesNotExist, fmt.Sprintf(&quot;device %s not found&quot;, deviceKey), nil) } // check device's AdminState // 检查设备管理状态 if device.AdminState == models.Locked { return res, errors.NewCommonEdgeX(errors.KindServiceLocked, fmt.Sprintf(&quot;device %s locked&quot;, device.Name), nil) } // check device's OperatingState // 检查设备操作状态 if device.OperatingState == models.Down { return res, errors.NewCommonEdgeX(errors.KindServiceLocked, fmt.Sprintf(&quot;device %s OperatingState is DOWN&quot;, device.Name), nil) } // the device service will perform some operations(e.g. update LastConnected timestamp, // push returning event to core-data) after a device is successfully interacted with if // it has been configured to do so, and those operation apply to every protocol and // need to be finished in the end of application layer before returning to protocol layer. // 设备服务将在与设备成功交互后执行一些操作 // 例如更新LastConnected timestamp(最后一次连接时间戳)、将返回事件推送到核心数据 // 如果设备已被配置为执行这些操作，则这些操作将应用于每个协议，并且需要在应用层末尾完成，然后再返回到协议层。 defer func() { if err != nil { return } config := container.ConfigurationFrom(dic.Get) // 更新最后一次连接时间戳 if config.Device.UpdateLastConnected { go sdkCommon.UpdateLastConnected(device.Name, bootstrapContainer.LoggingClientFrom(dic.Get), bootstrapContainer.MetadataDeviceClientFrom(dic.Get)) } // 将返回时间推送到核心数据 if res != nil &amp;&amp; sendEvent { go sdkCommon.SendEvent(res, correlationID, dic) } }() cmd := vars[common.Command] // 创建命令处理器对象 helper := NewCommandProcessor(device, cmd, correlationID, setParamsMap, attributes, dic) // 判断命令是否存在 _, cmdExist := cache.Profiles().DeviceCommand(device.ProfileName, cmd) if cmdExist { // 如果只读,返回读设备命令 if isRead { return helper.ReadDeviceCommand() } else { return res, helper.WriteDeviceCommand() } } else { if isRead { return helper.ReadDeviceResource() } else { return res, helper.WriteDeviceResource() } }}func (c *CommandProcessor) ReadDeviceResource() (res *dtos.Event, e errors.EdgeX) { dr, ok := cache.Profiles().DeviceResource(c.device.ProfileName, c.sourceName) if !ok { errMsg := fmt.Sprintf(&quot;deviceResource %s not found&quot;, c.sourceName) return res, errors.NewCommonEdgeX(errors.KindEntityDoesNotExist, errMsg, nil) } // check deviceResource is not write-only if dr.Properties.ReadWrite == common.ReadWrite_W { errMsg := fmt.Sprintf(&quot;deviceResource %s is marked as write-only&quot;, dr.Name) return res, errors.NewCommonEdgeX(errors.KindNotAllowed, errMsg, nil) } lc := bootstrapContainer.LoggingClientFrom(c.dic.Get) lc.Debugf(&quot;Application - readDeviceResource: reading deviceResource: %s; %s: %s&quot;, dr.Name, common.CorrelationHeader, c.correlationID) var req sdkModels.CommandRequest var reqs []sdkModels.CommandRequest // prepare CommandRequest req.DeviceResourceName = dr.Name req.Attributes = dr.Attributes if c.attributes != &quot;&quot; { if len(req.Attributes) &lt;= 0 { req.Attributes = make(map[string]interface{}) } req.Attributes[sdkCommon.URLRawQuery] = c.attributes } req.Type = dr.Properties.ValueType reqs = append(reqs, req) // execute protocol-specific read operation driver := container.ProtocolDriverFrom(c.dic.Get) results, err := driver.HandleReadCommands(c.device.Name, c.device.Protocols, reqs) if err != nil { errMsg := fmt.Sprintf(&quot;error reading DeviceResourece %s for %s&quot;, dr.Name, c.device.Name) return res, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } // convert CommandValue to Event res, e = transformer.CommandValuesToEventDTO(results, c.device.Name, dr.Name, c.dic) if e != nil { return res, errors.NewCommonEdgeX(errors.KindServerError, &quot;failed to convert CommandValue to Event&quot;, e) } return}func (c *CommandProcessor) ReadDeviceCommand() (res *dtos.Event, e errors.EdgeX) { // 通过给定的profileName和sourceName返回设备命令实例并且检查该设备命令是否存在 DeviceCommand见profiles.go dc, ok := cache.Profiles().DeviceCommand(c.device.ProfileName, c.sourceName) // 不存在 if !ok { errMsg := fmt.Sprintf(&quot;deviceCommand %s not found&quot;, c.sourceName) return res, errors.NewCommonEdgeX(errors.KindEntityDoesNotExist, errMsg, nil) } // check deviceCommand is not write-only // 检查设备命令是否为只写 if dc.ReadWrite == common.ReadWrite_W { errMsg := fmt.Sprintf(&quot;deviceCommand %s is marked as write-only&quot;, dc.Name) return res, errors.NewCommonEdgeX(errors.KindNotAllowed, errMsg, nil) } // check ResourceOperation count does not exceed MaxCmdOps defined in configuration // 检查资源操作计数是否超过配置中定义的MaxCmdOps,如果超过,返回错误 configuration := container.ConfigurationFrom(c.dic.Get) if len(dc.ResourceOperations) &gt; configuration.Device.MaxCmdOps { errMsg := fmt.Sprintf(&quot;GET command %s exceed device %s MaxCmdOps (%d)&quot;, dc.Name, c.device.Name, configuration.Device.MaxCmdOps) return res, errors.NewCommonEdgeX(errors.KindServerError, errMsg, nil) } lc := bootstrapContainer.LoggingClientFrom(c.dic.Get) lc.Debugf(&quot;Application - readCmd: reading cmd: %s; %s: %s&quot;, dc.Name, common.CorrelationHeader, c.correlationID) // prepare CommandRequests // 准备命令请求 reqs := make([]sdkModels.CommandRequest, len(dc.ResourceOperations)) // 遍历资源操作切片 for i, op := range dc.ResourceOperations { // 设备资源名 drName := op.DeviceResource // check the deviceResource in ResourceOperation actually exist // 检查该设备资源在资源操作map中是否真实存在(也就是判断这个设备资源是否可以执行给定操作)，返回设备资源实例 dr, ok := cache.Profiles().DeviceResource(c.device.ProfileName, drName) if !ok { errMsg := fmt.Sprintf(&quot;deviceResource %s in GET commnd %s for %s not defined&quot;, drName, dc.Name, c.device.Name) return res, errors.NewCommonEdgeX(errors.KindServerError, errMsg, nil) } // 保存设备请求 reqs[i].DeviceResourceName = dr.Name reqs[i].Attributes = dr.Attributes if c.attributes != &quot;&quot; { if len(reqs[i].Attributes) &lt;= 0 { reqs[i].Attributes = make(map[string]interface{}) } reqs[i].Attributes[sdkCommon.URLRawQuery] = c.attributes } reqs[i].Type = dr.Properties.ValueType } // execute protocol-specific read operation // 执行特定协议的读取操作 // 获取特定协议的驱动实例 driver := container.ProtocolDriverFrom(c.dic.Get) // 处理读命令请求，返回结果 // HandleReadCommands在 simpledriver.go 中实现 results, err := driver.HandleReadCommands(c.device.Name, c.device.Protocols, reqs) if err != nil { errMsg := fmt.Sprintf(&quot;error reading DeviceCommand %s for %s&quot;, dc.Name, c.device.Name) return res, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } // convert CommandValue to Event // 将命令数据转为事件 res, e = transformer.CommandValuesToEventDTO(results, c.device.Name, dc.Name, c.dic) if e != nil { return res, errors.NewCommonEdgeX(errors.KindServerError, &quot;failed to transform CommandValue to Event&quot;, e) } return}// WriteDeviceResource 写设备资源func (c *CommandProcessor) WriteDeviceResource() (e errors.EdgeX) { // 通过给定的profileName和sourceName返回设备资源实例并且检查该设备命令是否存在 DeviceCommand见profiles.go dr, ok := cache.Profiles().DeviceResource(c.device.ProfileName, c.sourceName) if !ok { errMsg := fmt.Sprintf(&quot;deviceResource %s not found&quot;, c.sourceName) return errors.NewCommonEdgeX(errors.KindEntityDoesNotExist, errMsg, nil) } // check deviceResource is not read-only // 检查设备命令是否为只读 if dr.Properties.ReadWrite == common.ReadWrite_R { errMsg := fmt.Sprintf(&quot;deviceResource %s is marked as read-only&quot;, dr.Name) return errors.NewCommonEdgeX(errors.KindNotAllowed, errMsg, nil) } lc := bootstrapContainer.LoggingClientFrom(c.dic.Get) lc.Debugf(&quot;Application - writeDeviceResource: writing deviceResource: %s; %s: %s&quot;, dr.Name, common.CorrelationHeader, c.correlationID) // check request body contains provided deviceResource // 检查请求体包含给定的设备资源 v, ok := c.setParamsMap[dr.Name] if !ok { if dr.Properties.DefaultValue != &quot;&quot; { v = dr.Properties.DefaultValue } else { errMsg := fmt.Sprintf(&quot;deviceResource %s not found in request body and no default value defined&quot;, dr.Name) return errors.NewCommonEdgeX(errors.KindServerError, errMsg, nil) } } // create CommandValue // 创建命令数据结构 cv, e := createCommandValueFromDeviceResource(dr, v) if e != nil { return errors.NewCommonEdgeX(errors.KindServerError, &quot;failed to create CommandValue&quot;, e) } // prepare CommandRequest // 准备命令请求 reqs := make([]sdkModels.CommandRequest, 1) reqs[0].DeviceResourceName = cv.DeviceResourceName reqs[0].Attributes = dr.Attributes // 如果命令处理实例的参数不为空，则存入reqs[0].Attributes[sdkCommon.URLRawQuery] if c.attributes != &quot;&quot; { if len(reqs[0].Attributes) &lt;= 0 { reqs[0].Attributes = make(map[string]interface{}) } reqs[0].Attributes[sdkCommon.URLRawQuery] = c.attributes } reqs[0].Type = cv.Type // transform write value // 执行写入操作 configuration := container.ConfigurationFrom(c.dic.Get) if configuration.Device.DataTransform { e = transformer.TransformWriteParameter(cv, dr.Properties) if e != nil { return errors.NewCommonEdgeX(errors.KindContractInvalid, &quot;failed to transform set parameter&quot;, e) } } // execute protocol-specific write operation driver := container.ProtocolDriverFrom(c.dic.Get) err := driver.HandleWriteCommands(c.device.Name, c.device.Protocols, reqs, []*sdkModels.CommandValue{cv}) if err != nil { errMsg := fmt.Sprintf(&quot;error writing DeviceResourece %s for %s&quot;, dr.Name, c.device.Name) return errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } return nil}func (c *CommandProcessor) WriteDeviceCommand() errors.EdgeX { dc, ok := cache.Profiles().DeviceCommand(c.device.ProfileName, c.sourceName) if !ok { errMsg := fmt.Sprintf(&quot;deviceCommand %s not found&quot;, c.sourceName) return errors.NewCommonEdgeX(errors.KindEntityDoesNotExist, errMsg, nil) } // check deviceCommand is not read-only if dc.ReadWrite == common.ReadWrite_R { errMsg := fmt.Sprintf(&quot;deviceCommand %s is marked as read-only&quot;, dc.Name) return errors.NewCommonEdgeX(errors.KindNotAllowed, errMsg, nil) } // check ResourceOperation count does not exceed MaxCmdOps defined in configuration configuration := container.ConfigurationFrom(c.dic.Get) if len(dc.ResourceOperations) &gt; configuration.Device.MaxCmdOps { errMsg := fmt.Sprintf(&quot;SET command %s exceed device %s MaxCmdOps (%d)&quot;, dc.Name, c.device.Name, configuration.Device.MaxCmdOps) return errors.NewCommonEdgeX(errors.KindServerError, errMsg, nil) } lc := bootstrapContainer.LoggingClientFrom(c.dic.Get) lc.Debugf(&quot;Application - writeCmd: writing command: %s; %s: %s&quot;, dc.Name, common.CorrelationHeader, c.correlationID) // create CommandValues cvs := make([]*sdkModels.CommandValue, 0, len(c.setParamsMap)) for _, ro := range dc.ResourceOperations { drName := ro.DeviceResource // check the deviceResource in ResourceOperation actually exist dr, ok := cache.Profiles().DeviceResource(c.device.ProfileName, drName) if !ok { errMsg := fmt.Sprintf(&quot;deviceResource %s in SET commnd %s for %s not defined&quot;, drName, dc.Name, c.device.Name) return errors.NewCommonEdgeX(errors.KindServerError, errMsg, nil) } // check request body contains the deviceResource value, ok := c.setParamsMap[ro.DeviceResource] if !ok { if ro.DefaultValue != &quot;&quot; { value = ro.DefaultValue } else if dr.Properties.DefaultValue != &quot;&quot; { value = dr.Properties.DefaultValue } else { errMsg := fmt.Sprintf(&quot;deviceResource %s not found in request body and no default value defined&quot;, dr.Name) return errors.NewCommonEdgeX(errors.KindServerError, errMsg, nil) } } // ResourceOperation mapping, notice that the order is opposite to get command mapping // i.e. the mapping value is actually the key for set command. if len(ro.Mappings) &gt; 0 { for k, v := range ro.Mappings { if v == value { value = k break } } } // create CommandValue cv, err := createCommandValueFromDeviceResource(dr, value) if err == nil { cvs = append(cvs, cv) } else { return errors.NewCommonEdgeX(errors.KindServerError, &quot;failed to create CommandValue&quot;, err) } } // prepare CommandRequests reqs := make([]sdkModels.CommandRequest, len(cvs)) for i, cv := range cvs { dr, _ := cache.Profiles().DeviceResource(c.device.ProfileName, cv.DeviceResourceName) reqs[i].DeviceResourceName = cv.DeviceResourceName reqs[i].Attributes = dr.Attributes if c.attributes != &quot;&quot; { if len(reqs[i].Attributes) &lt;= 0 { reqs[i].Attributes = make(map[string]interface{}) } reqs[i].Attributes[sdkCommon.URLRawQuery] = c.attributes } reqs[i].Type = cv.Type // transform write value if configuration.Device.DataTransform { err := transformer.TransformWriteParameter(cv, dr.Properties) if err != nil { return errors.NewCommonEdgeX(errors.KindContractInvalid, &quot;failed to transform set parameter&quot;, err) } } } // execute protocol-specific write operation driver := container.ProtocolDriverFrom(c.dic.Get) err := driver.HandleWriteCommands(c.device.Name, c.device.Protocols, reqs, cvs) if err != nil { errMsg := fmt.Sprintf(&quot;error writing DeviceCommand %s for %s&quot;, dc.Name, c.device.Name) return errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } return nil}func createCommandValueFromDeviceResource(dr models.DeviceResource, value interface{}) (*sdkModels.CommandValue, errors.EdgeX) { var err error var result *sdkModels.CommandValue v := fmt.Sprint(value) // 根据设备资源属性值的类型创建命令参数结构 switch dr.Properties.ValueType { case common.ValueTypeString: result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeString, v) case common.ValueTypeBool: var value bool // 将value转化为bool类型 value, err = strconv.ParseBool(v) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeBool, value) case common.ValueTypeBoolArray: var arr []bool // 解析json数据存入布尔型arr切片 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeBoolArray, arr) case common.ValueTypeUint8: var n uint64 n, err = strconv.ParseUint(v, 10, 8) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint8, uint8(n)) case common.ValueTypeUint8Array: var arr []uint8 strArr := strings.Split(strings.Trim(v, &quot;[]&quot;), &quot;,&quot;) for _, u := range strArr { n, err := strconv.ParseUint(strings.Trim(u, &quot; &quot;), 10, 8) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } arr = append(arr, uint8(n)) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint8Array, arr) case common.ValueTypeUint16: var n uint64 n, err = strconv.ParseUint(v, 10, 16) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint16, uint16(n)) case common.ValueTypeUint16Array: var arr []uint16 strArr := strings.Split(strings.Trim(v, &quot;[]&quot;), &quot;,&quot;) for _, u := range strArr { n, err := strconv.ParseUint(strings.Trim(u, &quot; &quot;), 10, 16) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } arr = append(arr, uint16(n)) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint16Array, arr) case common.ValueTypeUint32: var n uint64 n, err = strconv.ParseUint(v, 10, 32) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint32, uint32(n)) case common.ValueTypeUint32Array: var arr []uint32 strArr := strings.Split(strings.Trim(v, &quot;[]&quot;), &quot;,&quot;) for _, u := range strArr { n, err := strconv.ParseUint(strings.Trim(u, &quot; &quot;), 10, 32) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } arr = append(arr, uint32(n)) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint32Array, arr) case common.ValueTypeUint64: var n uint64 n, err = strconv.ParseUint(v, 10, 64) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint64, n) case common.ValueTypeUint64Array: var arr []uint64 strArr := strings.Split(strings.Trim(v, &quot;[]&quot;), &quot;,&quot;) for _, u := range strArr { n, err := strconv.ParseUint(strings.Trim(u, &quot; &quot;), 10, 64) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } arr = append(arr, n) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeUint64Array, arr) case common.ValueTypeInt8: var n int64 n, err = strconv.ParseInt(v, 10, 8) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt8, int8(n)) case common.ValueTypeInt8Array: var arr []int8 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt8Array, arr) case common.ValueTypeInt16: var n int64 n, err = strconv.ParseInt(v, 10, 16) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt16, int16(n)) case common.ValueTypeInt16Array: var arr []int16 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt16Array, arr) case common.ValueTypeInt32: var n int64 n, err = strconv.ParseInt(v, 10, 32) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt32, int32(n)) case common.ValueTypeInt32Array: var arr []int32 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt32Array, arr) case common.ValueTypeInt64: var n int64 n, err = strconv.ParseInt(v, 10, 64) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt64, n) case common.ValueTypeInt64Array: var arr []int64 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeInt64Array, arr) case common.ValueTypeFloat32: var val float64 val, err = strconv.ParseFloat(v, 32) if err == nil { result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeFloat32, float32(val)) break } if numError, ok := err.(*strconv.NumError); ok { if numError.Err == strconv.ErrRange { err = errors.NewCommonEdgeX(errors.KindServerError, &quot;NumError&quot;, err) break } } var decodedToBytes []byte decodedToBytes, err = base64.StdEncoding.DecodeString(v) if err == nil { var val float32 val, err = float32FromBytes(decodedToBytes) if err != nil { break } else if math.IsNaN(float64(val)) { err = fmt.Errorf(&quot;fail to parse %v to float32, unexpected result %v&quot;, v, val) } else { result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeFloat32, val) } } case common.ValueTypeFloat32Array: var arr []float32 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeFloat32Array, arr) case common.ValueTypeFloat64: var val float64 val, err = strconv.ParseFloat(v, 64) if err == nil { result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeFloat64, val) break } if numError, ok := err.(*strconv.NumError); ok { if numError.Err == strconv.ErrRange { err = errors.NewCommonEdgeX(errors.KindServerError, &quot;NumError&quot;, err) break } } var decodedToBytes []byte decodedToBytes, err = base64.StdEncoding.DecodeString(v) if err == nil { val, err = float64FromBytes(decodedToBytes) if err != nil { break } else if math.IsNaN(val) { err = fmt.Errorf(&quot;fail to parse %v to float64, unexpected result %v&quot;, v, val) } else { result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeFloat64, val) } } case common.ValueTypeFloat64Array: var arr []float64 err = json.Unmarshal([]byte(v), &amp;arr) if err != nil { errMsg := fmt.Sprintf(&quot;failed to convert set parameter %s to ValueType %s&quot;, v, dr.Properties.ValueType) return result, errors.NewCommonEdgeX(errors.KindServerError, errMsg, err) } result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeFloat64Array, arr) case common.ValueTypeObject: result, err = sdkModels.NewCommandValue(dr.Name, common.ValueTypeObject, value) default: err = errors.NewCommonEdgeX(errors.KindServerError, &quot;unrecognized value type&quot;, nil) } if err != nil { return nil, errors.NewCommonEdgeXWrapper(err) } return result, nil}func float32FromBytes(numericValue []byte) (res float32, err error) { reader := bytes.NewReader(numericValue) err = binary.Read(reader, binary.BigEndian, &amp;res) return}func float64FromBytes(numericValue []byte) (res float64, err error) { reader := bytes.NewReader(numericValue) err = binary.Read(reader, binary.BigEndian, &amp;res) return} device-sdk-go流程梳理1.生成初始Driver，调用Bootstrap:传入服务名称，设备版本，以及初始Driver2.进入Bootstrap:生成当前context以及cancel，调用Main，Main传入的参数有:服务名称，服务版本，初始驱动，context,cancel，以及Router3.进入Main流程：1）生成定时器（根据服务名称获取系统配置的超时时间以及interval的配置，如果不存在则使用默认值）2）解析命令行参数3）设置服务名 服务名为name+os.Getenv(“EDGEX_INSTANCE_NAME”)4）生成初始设备服务实例(空)5）初始化设备服务实例(用户必须提供服务名，其他内容由sdk内部提供)123456s.ServiceName = serviceName //由用户指定sdkCommon.ServiceVersion = serviceVersion //由makefile指定s.driver = driver //此处断言成sdk内部提供的ProtocolDriver接口 只需要用户实现接口中的所有方法即可断言成功s.discovery = discovery //可以没有s.deviceService = &amp;models.DeviceService{} //初始化models.DeviceService （注意对应s.deviceService）s.config = &amp;config.ConfigurationStruct{} //初始化ConfigurationStruct 6）保存命令行参数1ds.flags=sdkFlags 7）初始化容器（关键就是存入ServiceConstructorMap）12345678910111213141516171819//注意：比如container.ConfigurationName//var ConfigurationName = di.TypeInstanceToName(config.ConfigurationStruct{})//其name是PkgPath.interfaceName or PkgPath.non-interfaceName组成//当第一次调用比如//ct:=container.TConfigurationFrom(dic.Get) 会通过构造器初始化ConfigurationStruct实例并存储ds.dic = di.NewContainer(di.ServiceConstructorMap{ container.ConfigurationName: func(get di.Get) interface{} { return ds.config }, container.DeviceServiceName: func(get di.Get) interface{} { return ds.deviceService }, container.ProtocolDriverName: func(get di.Get) interface{} { return ds.driver }, container.ProtocolDiscoveryName: func(get di.Get) interface{} { return ds.discovery }, }) 8）初始化httpServer1httpServer := handlers.NewHttpServer(router, true) 9）调用bootstrap.Run，传入参数如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162bootstrap.Run( ctx, cancel, sdkFlags, ds.ServiceName, common.ConfigStemDevice, ds.config, startupTimer, ds.dic, true, []interfaces.BootstrapHandler{ httpServer.BootstrapHandler, messaging.BootstrapHandler, clients.BootstrapHandler, autoevent.BootstrapHandler, NewBootstrap(router).BootstrapHandler, autodiscovery.BootstrapHandler, handlers.NewStartMessage(serviceName, serviceVersion).BootstrapHandler, })func Run( ctx context.Context, cancel context.CancelFunc, commonFlags flags.Common, serviceKey string, configStem string, serviceConfig interfaces.Configuration, startupTimer startup.Timer, dic *di.Container, useSecretProvider bool, handlers []interfaces.BootstrapHandler) { wg, deferred, _ := RunAndReturnWaitGroup( ctx, cancel, commonFlags, serviceKey, configStem, serviceConfig, nil, startupTimer, dic, useSecretProvider, handlers, ) defer deferred() // wait for go routines to stop executing. wg.Wait()}//RunAndReturnWaitGroup引导应用程序。//它加载配置并调用提供的处理程序列表。任何长时间运行的进程都应该作为go例程在处理程序中生成。//处理程序应立即返回。调用所有处理程序后，此函数将返回同步。//对调用方的WaitGroup引用。//调用者在对返回的引用调用Wait（）之前采取任何有意义的附加操作，以等待应用程序停止（以及在各种处理程序中生成的相应goroutine完全停止）。func RunAndReturnWaitGroup( ctx context.Context, cancel context.CancelFunc, commonFlags flags.Common, serviceKey string, configStem string, serviceConfig interfaces.Configuration, configUpdated config.UpdatedStream, startupTimer startup.Timer, dic *di.Container, useSecretProvider bool, handlers []interfaces.BootstrapHandler) (*sync.WaitGroup, Deferred, bool) { var err error var wg sync.WaitGroup deferred := func() {} // 检查该设备服务是否提供了初始化的日志客户端，如果没有就创建一个新的，并且将其存入容器 lc := container.LoggingClientFrom(dic.Get) // 这边设备服务启动的时候 容器返回的lc是给空的loggingClient实例，通过服务名和日志等级将其进行初始化，并且通过 // Update方法这个初始化的Log客户端存入容器中 if lc == nil { lc = logger.NewClient(serviceKey, models.InfoLog) dic.Update(di.ServiceConstructorMap{ container.LoggingClientInterfaceName: func(get di.Get) interface{} { return lc }, }) } // TranslateInterruptoCancel生成一个go例程，将接收到的系统SIGTERM信号转换为取消引导上下文的cancel的调用。 // 关键函数 signal.Notify(signalStream, os.Interrupt, syscall.SIGTERM) 监控系统中断信号 translateInterruptToCancel(ctx, &amp;wg, cancel) // 读出系统环境变量 并且传入初始化的logClient envVars := environment.NewVariables(lc) // SecretProvider 被初始化并作为处理配置的一部分放置在容器中，因为需要使用它来获取配置提供程序的访问令牌 // 并且必须等到从文件加载配置后才能对其进行初始化。 // commonFlags 即传入的sdkFlags // envVars 系统环境变量 // startupTimer启动计时器 // context // sync.WaitGroup // configUpdated config.UpdatedStream 定义接收配置更新时由 ListenForChanges 通知的流类型 此处为nil // dic 容器 configProcessor := config.NewProcessor(commonFlags, envVars, startupTimer, ctx, &amp;wg, configUpdated, dic) // servicekey serviceName // configStem ConfigStemDevice = &quot;edgex/devices/&quot; // serviceConfig *config.ConfigurationStruct if err := configProcessor.Process(serviceKey, configStem, serviceConfig, useSecretProvider); err != nil{ fatalError(err, lc) } var registryClient registry.Client envUseRegistry, wasOverridden := envVars.UseRegistry() if envUseRegistry || (commonFlags.UseRegistry() &amp;&amp; !wasOverridden) { registryClient, err = registration.RegisterWithRegistry( ctx, startupTimer, serviceConfig, lc, serviceKey, dic) if err != nil { fatalError(err, lc) } deferred = func() { lc.Info(&quot;Un-Registering service from the Registry&quot;) err := registryClient.Unregister() if err != nil { lc.Error(&quot;Unable to Un-Register service from the Registry&quot;, &quot;error&quot;, err.Error()) } } } dic.Update(di.ServiceConstructorMap{ container.ConfigurationInterfaceName: func(get di.Get) interface{} { return serviceConfig }, container.RegistryClientInterfaceName: func(get di.Get) interface{} { return registryClient }, container.CancelFuncName: func(get di.Get) interface{} { return cancel }, }) // call individual bootstrap handlers. startedSuccessfully := true for i := range handlers { if handlers[i](ctx, &amp;wg, startupTimer, dic) == false { cancel() startedSuccessfully = false break } } return &amp;wg, deferred, startedSuccessfully} Process123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106func (cp *Processor) Process( serviceKey string, configStem string, serviceConfig interfaces.Configuration, //serviceConfig 实现了interfaces.Configuration的所有方法 useSecretProvider bool) error { // Create some shorthand for frequently used items envVars := cp.envVars cp.overwriteConfig = cp.flags.OverwriteConfig() // 如果需要注册表配置信息或者需要将其推送到配置提供程序，则必须首先加载本地配置。 if err := cp.loadFromFile(serviceConfig, &quot;service&quot;); err != nil { return err } // 使用 envVars 变量覆盖基于文件的配置。 // 变量覆盖优先于所有其他变量，因此请确保在使用 config 之前之前应用它们。 overrideCount, err := envVars.OverrideConfiguration(serviceConfig) if err != nil { return err } // 现在配置已经从文件加载并应用了覆盖，可以初始化秘密提供者并将其添加到 DIC，但前提是它被配置为使用。 var secretProvider interfaces.SecretProvider if useSecretProvider { secretProvider, err = secret.NewSecretProvider(serviceConfig, cp.ctx, cp.startupTimer, cp.dic) if err != nil { return fmt.Errorf(&quot;failed to create SecretProvider: %s&quot;, err.Error()) } } configProviderUrl := cp.flags.ConfigProviderUrl() // Create new ProviderInfo and initialize it from command-line flag or Variables configProviderInfo, err := NewProviderInfo(cp.envVars, configProviderUrl) if err != nil { return err } switch configProviderInfo.UseProvider() { case true: var accessToken string var getAccessToken types.GetAccessTokenCallback // secretProvider will be nil if not configured to be used. In that case, no access token required. if secretProvider != nil { // Define the callback function to retrieve the Access Token getAccessToken = func() (string, error) { accessToken, err = secretProvider.GetAccessToken(configProviderInfo.serviceConfig.Type, serviceKey) if err != nil { return &quot;&quot;, fmt.Errorf( &quot;failed to get Configuration Provider (%s) access token: %s&quot;, configProviderInfo.serviceConfig.Type, err.Error()) } cp.lc.Infof(&quot;Using Configuration Provider access token of length %d&quot;, len(accessToken)) return accessToken, nil } } else { cp.lc.Info(&quot;Not configured to use Config Provider access token&quot;) } configClient, err := cp.createProviderClient(serviceKey, configStem, getAccessToken, configProviderInfo.ServiceConfig()) if err != nil { return fmt.Errorf(&quot;failed to create Configuration Provider client: %s&quot;, err.Error()) } for cp.startupTimer.HasNotElapsed() { if err := cp.processWithProvider( configClient, serviceConfig, overrideCount, ); err != nil { cp.lc.Error(err.Error()) select { case &lt;-cp.ctx.Done(): return errors.New(&quot;aborted Updating to/from Configuration Provider&quot;) default: cp.startupTimer.SleepForInterval() continue } } break } cp.listenForChanges(serviceConfig, configClient) cp.dic.Update(di.ServiceConstructorMap{ container.ConfigClientInterfaceName: func(get di.Get) interface{} { return configClient }, }) case false: cp.logConfigInfo(&quot;Using local configuration from file&quot;, overrideCount) } // Now that configuration has been loaded and overrides applied the log level can be set as configured. err = cp.lc.SetLogLevel(serviceConfig.GetLogLevel()) return err}","link":"/EdgeX/device-sdk-go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"}],"tags":[{"name":"EdgeX构建","slug":"EdgeX构建","link":"/tags/EdgeX%E6%9E%84%E5%BB%BA/"},{"name":"EdgeX机器学习以及推理","slug":"EdgeX机器学习以及推理","link":"/tags/EdgeX%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E6%8E%A8%E7%90%86/"},{"name":"EdgeX概念","slug":"EdgeX概念","link":"/tags/EdgeX%E6%A6%82%E5%BF%B5/"},{"name":"EdgeX部署","slug":"EdgeX部署","link":"/tags/EdgeX%E9%83%A8%E7%BD%B2/"},{"name":"EdgeX平台构建","slug":"EdgeX平台构建","link":"/tags/EdgeX%E5%B9%B3%E5%8F%B0%E6%9E%84%E5%BB%BA/"},{"name":"docker部署","slug":"docker部署","link":"/tags/docker%E9%83%A8%E7%BD%B2/"},{"name":"Golang圣经","slug":"Golang圣经","link":"/tags/Golang%E5%9C%A3%E7%BB%8F/"},{"name":"Linux知识点","slug":"Linux知识点","link":"/tags/Linux%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"Java知识点","slug":"Java知识点","link":"/tags/Java%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"kubeedge example","slug":"kubeedge-example","link":"/tags/kubeedge-example/"},{"name":"kubeedge","slug":"kubeedge","link":"/tags/kubeedge/"},{"name":"高性能矩阵乘法剖析","slug":"高性能矩阵乘法剖析","link":"/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E5%89%96%E6%9E%90/"},{"name":"粗粒度可重构体系结构与Plasticine","slug":"粗粒度可重构体系结构与Plasticine","link":"/tags/%E7%B2%97%E7%B2%92%E5%BA%A6%E5%8F%AF%E9%87%8D%E6%9E%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B8%8EPlasticine/"},{"name":"暗硅","slug":"暗硅","link":"/tags/%E6%9A%97%E7%A1%85/"},{"name":"CS217 Lecture","slug":"CS217-Lecture","link":"/tags/CS217-Lecture/"},{"name":"智能计算系统学习","slug":"智能计算系统学习","link":"/tags/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0/"},{"name":"好看的PowerShell","slug":"好看的PowerShell","link":"/tags/%E5%A5%BD%E7%9C%8B%E7%9A%84PowerShell/"},{"name":"快速傅里叶变换","slug":"快速傅里叶变换","link":"/tags/%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"},{"name":"硬件加速背景以及卷积神经网络优化","slug":"硬件加速背景以及卷积神经网络优化","link":"/tags/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E8%83%8C%E6%99%AF%E4%BB%A5%E5%8F%8A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/"},{"name":"轻量级神经网络加速","slug":"轻量级神经网络加速","link":"/tags/%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8A%A0%E9%80%9F/"},{"name":"神经网络与深度学习","slug":"神经网络与深度学习","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"计算机组成与体系结构","slug":"计算机组成与体系结构","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Java并发编程","slug":"Java并发编程","link":"/tags/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"Git使用指南","slug":"Git使用指南","link":"/tags/Git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"}],"categories":[{"name":"EdgeX","slug":"EdgeX","link":"/categories/EdgeX/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"kubeedge","slug":"kubeedge","link":"/categories/kubeedge/"},{"name":"CS217","slug":"CS217","link":"/categories/CS217/"},{"name":"智能计算系统","slug":"智能计算系统","link":"/categories/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/"},{"name":"杂七杂八","slug":"杂七杂八","link":"/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"name":"硬件神经网络加速","slug":"硬件神经网络加速","link":"/categories/%E7%A1%AC%E4%BB%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8A%A0%E9%80%9F/"},{"name":"神经网络与深度学习","slug":"神经网络与深度学习","link":"/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"计算机组成与体系结构","slug":"计算机组成与体系结构","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"},{"name":"Git","slug":"Git","link":"/categories/Git/"}]}